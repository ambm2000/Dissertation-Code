topic,platform,filename,summary
-1_content_report_community_account,Bumble,Bumble_When_Should_I_Use_Block_and_report.txt,"1. **Summary**: The Bumble safety policy document outlines the operational framework and user guidance for the ""Block & Report"" feature, emphasizing its role in safeguarding users from discomfort or unsafe situations. The policy aims to empower users to take proactive measures against harmful behaviors, both online and in-person, through accessible reporting mechanisms. It delineates the procedural steps for reporting, ensuring user anonymity and outlining potential consequences for offenders in alignment with community guidelines. The document underscores the platform's commitment to addressing discrimination, identity-based hate, and other harmful behaviors, thereby fostering a safer digital environment.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and empowering. This is evidenced by the repeated emphasis on user empowerment and safety, encouraging users to utilize the ""Block & Report"" feature whenever they feel uncomfortable or unsafe, and ensuring anonymity in the reporting process to protect users from potential repercussions.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, identity-based, and reputational harms. It highlights issues such as discrimination, sexism, racism, fetishization, and behaviors that advocate hatred or incite violence, all of which can have profound psychological and reputational impacts on users.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and recognizes their potential vulnerability to harmful behaviors. It presupposes that users can identify and report inappropriate conduct, thereby participating actively in maintaining a safe community. Additionally, it implies a responsibility on the part of users to contribute to the platform's safety by utilizing the reporting tools provided."
-1_content_report_community_account,Quora,Quora_Platform_Policies.txt,"1. **Summary**: The Quora platform safety policy document delineates a regulatory framework aimed at fostering a secure and genuine user experience by prohibiting specific harmful behaviors and content. The policy primarily targets spam, harassment, and bullying, outlining clear prohibitions against activities such as selling illegal goods, promoting scams, and engaging in coordinated inauthentic activities. It seeks to mitigate risks to user interaction, trust, and engagement by enforcing guidelines against deceptive practices and harassment. The document underscores the platformâ€™s commitment to maintaining a trustworthy environment conducive to knowledge sharing.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the prescriptive language used to delineate prohibited behaviors and the clear, directive nature of the rules, which convey a sense of control and enforcement over user conduct to ensure compliance and safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (through harassment and bullying), reputational harm (via spam and coordinated inauthentic activity), economic harm (through scams and fraudulent activities), and privacy harm (via deceptive links and unauthorized account recovery services).

4. **User Assumptions**: The document assumes that users may engage in or be susceptible to behaviors that compromise platform integrity, such as spamming or harassment. It presupposes a need for external regulation to guide user conduct, indicating an assumption of limited self-regulation capacity among users. Additionally, there is an implicit expectation that users are responsible for adhering to community standards to maintain a safe and authentic environment."
-1_content_report_community_account,Discord,Discord_Warning_System.txt,"1. **Summary**: The Discord Warning System policy document outlines a regulatory framework aimed at enhancing user compliance with platform rules through a structured warning system. The primary objective is to provide transparency and educational resources to users who violate rules, thereby encouraging behavioral correction and continued platform engagement. The policy emphasizes a balance between educational interventions and punitive measures, with a focus on preventing repeated or severe violations by implementing account restrictions or permanent bans. This approach underscores Discord's commitment to maintaining a safe online environment by fostering user learning and accountability.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and educational. This is evidenced by the emphasis on transparency, user education, and the opportunity for users to learn from their mistakes, which indicates a focus on proactive harm prevention rather than solely punitive measures.

3. **Types of Harm Addressed**: The policy substantively addresses psychological harm, reputational harm, and privacy concerns. These are implied through the focus on rule violations that could impact user interactions and the platform's overall safety.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and learning, as it provides educational resources and opportunities for behavioral correction. It also presumes a level of vulnerability among users, necessitating protective measures against repeated or severe violations. Additionally, there is an implicit expectation that users are responsible for understanding and adhering to platform rules to maintain their account standing."
-1_content_report_community_account,Bumble,Bumble_catfishing.txt,"1. **Summary**: The policy document aims to educate users on identifying and recovering from catfishing, a deceptive practice where individuals misrepresent themselves online for personal gain. It provides specific indicators to help users recognize potential catfish and emphasizes the importance of profile verification as a preventative measure. The document also offers guidance on emotional recovery, underscoring the importance of self-forgiveness and learning from the experience. The regulatory scope is thus both preventative and rehabilitative, focusing on user awareness and psychological resilience.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the emphasis on user empowerment through education and emotional recovery, as well as the reassurance that being a victim of catfishing is not the user's fault. The language used is empathetic and aims to foster a sense of personal growth and resilience.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it discusses the emotional impact of catfishing and the importance of self-forgiveness. It also implicitly touches on economic harm, given the mention of catfishers potentially seeking money from victims.

4. **User Assumptions**: The policy assumes that users may lack awareness of the signs of catfishing but have the capacity for self-regulation once informed. It presupposes a vulnerability to deception but also an inherent resilience, suggesting that users can learn and grow from negative experiences. Additionally, it implies a responsibility on the part of users to verify profiles and trust their instincts."
-1_content_report_community_account,Facebook Messenger,Facebook_Messenger_How_do_I_report_something_on_Facebook_if_I_dont_have_an_accout.txt,"1. **Summary**: The policy document outlines procedures for reporting content that contravenes Facebook's Community Standards, specifically addressing scenarios where users lack direct access to the platform. It emphasizes the necessity for users without accounts, or those unable to view specific content, to enlist the aid of friends with accounts to initiate reports. The document underscores the importance of detailed reporting, including links and screenshots, to facilitate effective content moderation. This approach aims to uphold community guidelines by leveraging collective user engagement in the absence of direct access.

2. **Tone**: The dominant rhetorical tone of the policy is procedural and supportive. This classification is justified by the document's focus on providing clear, step-by-step instructions to users, emphasizing collaboration and detailed reporting to ensure effective moderation.

3. **Types of Harm Addressed**: The policy implicitly addresses psychological, reputational, and privacy harms. These are inferred from the emphasis on reporting content that violates community standards, which typically encompass issues like harassment, defamation, and unauthorized sharing of personal information.

4. **User Assumptions**: The document assumes that users possess a basic understanding of the platform's reporting mechanisms and the capacity to collaborate with others to address content violations. It also presupposes a level of responsibility among users to provide comprehensive details in their reports, indicating an expectation of proactive engagement in maintaining community standards."
-1_content_report_community_account,Telegram,Telegram_Ads.txt,"1. **Summary**: The document delineates the regulatory framework governing advertisements on the Telegram Ad Platform, emphasizing compliance with established guidelines and overarching terms of service. It primarily aims to ensure that ad content adheres to specific editorial standards, including clarity, style, and appropriate language use. The policy outlines permissible ad formats and link structures, thereby guiding advertisers in creating content that aligns with Telegram's community standards. This regulatory scope is intended to mitigate potential harms associated with misleading or inappropriate advertising content.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the prescriptive nature of the guidelines, which clearly delineate acceptable and unacceptable ad content, thereby asserting control over the advertising environment on the platform.

3. **Types of Harm Addressed**: The policy substantively addresses psychological harm by prohibiting profanity and vulgarity, which could distress users. It also implicitly addresses reputational harm by ensuring ads are clear and not misleading, thereby protecting users from deceptive content.

4. **User Assumptions**: The policy assumes that advertisers possess the capacity for self-regulation and are responsible for ensuring their ads comply with the guidelines. It also presupposes that users are vulnerable to misleading or offensive content, necessitating strict editorial standards to safeguard their experience on the platform."
-1_content_report_community_account,Facebook,Facebook_reporting_guide.txt,"1. **Summary**: The policy document primarily aims to guide users in reporting content that contravenes Facebook's Community Standards, such as nudity, hate speech, and violence, thereby enhancing user safety and platform integrity. It delineates procedural steps for reporting inappropriate content, including options for users without accounts or those unable to view the content directly. The document emphasizes user empowerment through self-regulatory tools to manage their experience, while also advising engagement with local law enforcement when personal threats are perceived. The regulatory scope is thus both preventative and responsive, focusing on user intervention and platform compliance with community guidelines.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as evidenced by the empathetic acknowledgment of users' negative experiences and the provision of clear, actionable steps to address these issues. The language is designed to reassure users of the platform's commitment to their safety while encouraging proactive engagement with its reporting mechanisms.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., discomfort from threatening messages), reputational harm (e.g., hate speech), and privacy concerns (e.g., blocking unwanted contact).

4. **User Assumptions**: The document assumes that users possess a basic capacity for self-regulation and are responsible for managing their own safety by utilizing the platform's tools. It presupposes users' awareness of their vulnerability to harmful content and their willingness to report violations. Additionally, it implies that users have the capability to discern when to escalate issues to law enforcement, indicating an expectation of user judgment and initiative in safeguarding their online interactions."
-1_content_report_community_account,TikTok,TikTok_comments_live.txt,"1. **Summary**: The policy document outlines TikTok's regulatory framework aimed at ensuring user safety and enhancing platform governance through structured content management and community interaction guidelines. It emphasizes user interventions in content creation, personalization, and community engagement, with a focus on maintaining a safe and inclusive digital environment. The document delineates specific procedures for account management, content moderation, and user interaction, thereby aiming to mitigate potential harms associated with digital communication. The policy seeks to balance user autonomy with protective measures, fostering a community that supports both creative expression and responsible usage.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This classification is justified by the document's structured guidelines and procedural instructions designed to preemptively address potential risks and regulate user behavior. The authoritative tone is further reflected in the explicit directives for content management and community interaction, underscoring the platform's commitment to maintaining a safe digital space.

3. **Types of Harm Addressed**: The policy substantively addresses psychological, reputational, and privacy harms. Psychological harm is implied through the emphasis on safe community interactions and content moderation. Reputational harm is considered in the context of account management and content sharing, while privacy harm is addressed through guidelines on personalization and data management.

4. **User Assumptions**: The policy assumes that users possess a basic capacity for self-regulation and are responsible for adhering to community standards and content guidelines. It presupposes a level of digital literacy necessary for navigating account settings and content creation tools. Additionally, the document implies a vulnerability to digital harms, necessitating protective measures and user education to mitigate risks."
-1_content_report_community_account,Badoo,Badoo_Block_and_Report.txt,"1. **Summary**: The Badoo safety policy document outlines the functionality and objectives of its Block & Report feature, emphasizing user empowerment and protection in situations of discomfort or perceived threat. The policy aims to provide a transparent and straightforward process for users to report abusive or disrespectful behaviour, ensuring their identity remains protected. This feature is accessible through various in-app interactions, allowing users to report inappropriate conduct efficiently. The document underscores the platform's commitment to maintaining a safe environment by reviewing reports and enforcing community guidelines, which may result in warnings or bans for offenders.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the repeated emphasis on user empowerment and protection. The language used, such as ""empowered to use"" and ""transparent, simple, and safe process,"" suggests a focus on reassuring users that their safety and comfort are prioritized.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on user discomfort and safety in response to abusive or disrespectful behaviour. It also implicitly touches on reputational harm, given the potential consequences for offenders, and privacy concerns, as it assures users of identity protection during the reporting process.

4. **User Assumptions**: The document assumes that users may experience situations of discomfort or threat, indicating an understanding of their vulnerability to psychological harm. It presupposes users' capacity for self-regulation by encouraging them to report inappropriate behaviour proactively. Additionally, it implies a responsibility on the part of users to contribute to the platform's safety by utilizing the Block & Report feature when necessary."
-1_content_report_community_account,Quora,Quora_moderator_guide.txt,"1. **Summary**: The policy document from Quora outlines the regulatory framework for managing Spaces, emphasizing the importance of maintaining content quality and adherence to community norms to enhance user engagement. It provides guidelines for Space administrators to define and communicate specific standards, allowing for some flexibility within the overarching platform policies. The document aims to empower users to create environments that reflect their interests while safeguarding against content that could diminish the Space's integrity. It seeks to balance personal expression with community expectations, thereby fostering a respectful and engaging digital environment.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on empowering users to establish their own standards within Spaces, while also providing guidance to prevent potential declines in engagement due to content misalignment with user expectations.

3. **Types of Harm Addressed**: The policy substantively addresses reputational and psychological harm. It implicitly acknowledges reputational harm by stressing the importance of content quality and norms, which can affect the Space's and its administrators' reputations. Psychological harm is considered through the focus on preventing potentially offensive content and ensuring respectful interactions.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation and are motivated to maintain high standards of content quality and interaction. It presumes a level of responsibility among Space administrators to define and uphold norms, suggesting an expectation of proactive engagement in community governance. Additionally, it implies that users are capable of discerning and aligning with the expectations set within each Space."
0_safety_community_information_user,Hinge,Hinge_Member_Principles.txt,"**Summary**: The policy document from Hinge outlines a framework designed to transform dating culture by fostering a safe and respectful community environment. Its regulatory scope emphasizes the dual responsibility of both the platform and its users in maintaining safety, with the platform committing to proactive safety measures and users expected to engage with openness and respect. The document aims to implement user interventions through intuitive safety tools and responsive action to reports, thereby ensuring user protection and empowerment. The overarching objective is to create a trustworthy space where meaningful relationships can be pursued without compromising personal safety.

**Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its emphasis on community-building, user empowerment, and the proactive provision of safety resources. The language used underscores a commitment to fostering a positive and secure environment, rather than imposing punitive measures.

**Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and privacy harms. It emphasizes the need for users to feel safe in expressing their identities and making connections, while also highlighting the importance of protecting users from known and unknown threats.

**User Assumptions**: The document assumes that users are inherently capable of self-regulation and are motivated by the desire for meaningful relationships. It presumes users understand and value the importance of consent and boundaries, and it expects them to engage honestly and respectfully with others. The policy also implies a level of user vulnerability, necessitating the platform's proactive stance in safety measures."
0_safety_community_information_user,Tinder,Tinder_safety_and_policy_center.txt,"1. **Summary**: The policy document articulates the platform's commitment to user safety by implementing comprehensive safety measures and fostering a respectful environment for social interaction. It outlines the regulatory scope involving automated and manual moderation tools designed to detect and mitigate inappropriate behaviors, such as harassment and impersonation. The document emphasizes the platform's proactive approach to preventing criminal activities, despite their low incidence, by continuously updating safety protocols and forming strategic partnerships. The primary objective is to ensure a uniformly safe and positive user experience across diverse geographical locations.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on proactive measures, such as continuous updates and partnerships to enhance safety, as well as the encouragement for community reporting, reflecting a commitment to user protection and empowerment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (harassment), reputational harm (impersonation), and privacy violations (monitoring and blocking identifiers associated with bad actors).

4. **User Assumptions**: The document assumes users have a degree of vulnerability to misconduct and criminal behavior, necessitating robust safety measures. It also presumes users have the capacity and responsibility to participate in self-regulation by reporting inappropriate behavior, indicating an expectation of active user engagement in maintaining community standards."
0_safety_community_information_user,Discord,Discord_privacy_policy.txt,"1. **Summary**: The Discord Privacy Policy document articulates the platform's commitment to safeguarding user privacy by detailing the collection, usage, storage, and sharing of personal information. It establishes the regulatory framework by identifying Discord Netherlands BV and Discord Inc. as data controllers, depending on the user's location, and emphasizes the platform's business model, which excludes the sale of personal data. The policy aims to foster a secure and enjoyable online environment by prioritizing user privacy and providing mechanisms for users to manage their data. The document outlines specific interventions, such as data protection measures and user privacy controls, to mitigate potential privacy harms.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its emphasis on user privacy and the creation of safe online spaces. The language used, such as ""We care a lot about privacy"" and ""Respecting user privacy is a key part of that mission,"" underscores a commitment to user welfare and trust.

3. **Types of Harm Addressed**: The policy primarily addresses privacy-related harms, focusing on the protection of personal information from unauthorized access, misuse, or sale.

4. **User Assumptions**: The policy assumes that users are concerned about their privacy and have the capacity to engage with privacy controls. It suggests that users are responsible for understanding and managing their privacy settings, implying a level of digital literacy and self-regulation. Additionally, it presumes that users value a secure environment where personal data is not commodified."
0_safety_community_information_user,Discord,Discord_account_safety.txt,"1. **Summary**: The document serves as a safety policy guide for Discord users, emphasizing the importance of securing user accounts through robust password practices and two-factor authentication. It outlines a regulatory framework that prioritizes user autonomy in managing personal safety settings and encourages proactive measures to mitigate potential risks. The policy's primary objective is to empower users to control their digital interactions by providing clear, actionable steps to enhance account security. This approach reflects a preventative strategy aimed at safeguarding users from various digital harms.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the document's focus on empowering users with practical advice and tools to enhance their account security, as well as its emphasis on user autonomy and proactive risk management.

3. **Types of Harm Addressed**: The policy explicitly addresses privacy and psychological harms. Privacy is a central concern, as the document emphasizes securing account credentials and enabling two-factor authentication. Psychological harm is implicitly addressed through the suggestion to block other users when needed, which aims to prevent unwanted interactions and potential distress.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for actively managing their account security. It presupposes a basic level of digital literacy, as users are expected to understand and implement security measures such as strong passwords and two-factor authentication. Additionally, it assumes users are vulnerable to privacy breaches and psychological distress from unwanted interactions, necessitating the guidance provided."
0_safety_community_information_user,Grindr,Grindr_Holistic_safety_guide.txt,"1. **Summary**: The Grindr Holistic Security Guide aims to enhance user safety by addressing the unique vulnerabilities faced by the LGBTIQ+ community within digital spaces. The policy document outlines Grindr's commitment to developing security features and disseminating critical safety information to mitigate risks associated with online interactions. It emphasizes collaboration with LGBTIQ+ and health activists to create a comprehensive safety framework that supports users in navigating potential threats. The guide adopts a harm reduction approach, focusing on empowering users to maintain their safety while engaging with the platform.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the document's emphasis on collaboration with community organizations and activists, as well as its focus on empowering users through the provision of safety information and resources. The language used is inclusive and reassuring, highlighting a commitment to user well-being and collective security.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, identity-based, and privacy harms. It acknowledges the discrimination and violence faced by the LGBTIQ+ community and the potential risks associated with the platform's features, which may compromise user privacy and identity security.

4. **User Assumptions**: The document assumes that users are part of a resilient and resourceful community but acknowledges their vulnerability to discrimination and violence. It presumes users have a capacity for self-regulation when provided with adequate safety information and resources. Additionally, it suggests that users are active participants in their safety, expected to engage with the provided guidelines to mitigate potential risks."
0_safety_community_information_user,Bumble,Bumble_Safety_IRL.txt,"1. **Summary**: The policy document from Bumble outlines its commitment to user safety by establishing Community Guidelines that promote kindness, respect, and equality within the platform. It emphasizes a collaborative regulatory approach, wherein both the platform and its community members are responsible for maintaining a safe environment. The document provides practical safety tips for users, encouraging them to engage in pre-meeting verifications and preliminary virtual interactions to mitigate potential risks. The overarching objective is to empower users to exercise personal judgment while ensuring that the platform remains a supportive and accountable space.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as it emphasizes the platform's commitment to user safety while encouraging users to take proactive measures. This is evidenced by the language that reassures users of the platform's backing (""we've got your back"") and the provision of practical advice aimed at empowering users to protect themselves.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm by promoting safety measures that reduce anxiety and uncertainty when meeting new people. It also implicitly addresses identity-based harm through the recommendation of user verification to prevent catfishing, which can impact one's sense of identity and trust.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are capable of exercising good judgment when interacting with others. It suggests that users are responsible for taking safety precautions, indicating an expectation of proactive engagement in their own safety. Additionally, there is an implicit assumption of user vulnerability, as the platform provides guidance to mitigate potential risks associated with meeting new individuals."
0_safety_community_information_user,Discord,Discord_Bringing_Policies_to_Life.txt,"1. **Summary**: The Discord safety policy document articulates a comprehensive regulatory framework aimed at fostering a secure online environment by aligning platform rules with societal norms and user-centric values. It emphasizes the importance of rules that extend beyond mere legal compliance to encompass broader social customs, thereby reflecting the platform's commitment to creating inclusive and respectful spaces. The policy specifically targets bullying and harassment, recognizing the psychological and emotional harm such behaviors can inflict on individuals and communities. By prohibiting actions intended to intimidate or distress, the policy seeks to protect users and ensure their safety and well-being within the platform.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on user-centered rule development and the proactive stance against bullying and harassment, aiming to prevent harm and support a positive user experience.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it highlights the emotional and mental distress caused by bullying and harassment. It also implicitly considers reputational harm, given the focus on protecting individuals and groups from targeted intimidation.

4. **User Assumptions**: The document assumes that users are at risk of encountering harmful behaviors such as trolling, which necessitates protective measures. It also presumes a level of vulnerability among users, recognizing that even non-targeted individuals can feel unsafe. Furthermore, there is an implicit expectation that users have a responsibility to adhere to community standards that prevent harm to others."
0_safety_community_information_user,Bumble,Bumble_safety_guide.txt,"**Summary**: The safety policy document from Bumble primarily aims to foster a secure and respectful community environment by emphasizing the importance of kindness, respect, and equality among users. It delineates a regulatory framework that combines community-driven accountability with platform-enforced rules to mitigate potential harms. The document advocates for user empowerment through informed decision-making and precautionary measures, particularly in the context of personal information sharing. The policy underscores the dual responsibility of the platform and its users in maintaining safety, highlighting both supportive and preventative interventions.

**Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the emphasis on community values and the platform's commitment to user safety. This is further reinforced by the language of empowerment and encouragement for users to exercise good judgment, suggesting a collaborative approach to safety rather than a purely authoritative or punitive stance.

**Types of Harm Addressed**: The policy explicitly addresses privacy-related harms by advising users on the cautious sharing of personal information. It also implicitly touches on psychological harm by promoting a respectful and kind community environment, thereby aiming to prevent harassment or emotional distress.

**User Assumptions**: The document assumes that users possess a basic capacity for self-regulation and are capable of exercising good judgment when interacting with others. It also presumes a level of vulnerability, particularly regarding privacy, and expects users to take proactive steps to protect their personal information. Additionally, there is an implicit expectation that users will contribute to community accountability by upholding the platform's values."
0_safety_community_information_user,Snapchat,Snapchat_Safety_Resources.txt,"1. **Summary**: The policy document primarily aims to enhance user safety on the platform by providing access to resources and support for individuals experiencing mental health issues, bullying, and sexual risks. It outlines a collaborative framework with industry experts and non-governmental organizations to deliver localized support through tools like the ""Here For You"" search feature. The document emphasizes the availability of global resources, particularly for children and adolescents, to manage stress and develop resilience. It also highlights the platform's commitment to transparency and user engagement in safety practices.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the language used to describe the provision of resources and support, such as ""help,"" ""support,"" and ""chat,"" which indicates a focus on assistance and empathy rather than enforcement or deterrence.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly in relation to mental health issues such as anxiety, depression, stress, and suicidal thoughts. It also substantively discusses sexual harm and bullying, indicating a broad concern for both psychological and sexual safety.

4. **User Assumptions**: The document assumes that users, particularly younger individuals, may be vulnerable to psychological and sexual harms and may lack the capacity for self-regulation in these areas. It presupposes a need for external support and guidance, suggesting that users are expected to seek help when in distress and that they have a responsibility to engage with the resources provided."
0_safety_community_information_user,TikTok,TikTok_wellbeing.txt,"1. **Summary**: The policy document from TikTok's Safety Centre emphasizes the importance of user well-being, both online and offline, by encouraging users to maintain control over their digital interactions. Its regulatory scope includes the development of educational toolkits in collaboration with experts, aimed at fostering a supportive online community. The document advocates for self-assessment of digital habits to enhance mental and physical health, promoting a balanced relationship with technology. The intended interventions focus on raising user awareness and providing resources to improve digital well-being.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the document's emphasis on user empowerment and collaboration with experts to provide educational resources, suggesting a nurturing approach to user safety and well-being.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and physical harm by focusing on mental and physical health in the context of digital interactions. It implicitly touches on privacy concerns through the encouragement of evaluating online privacy and security.

4. **User Assumptions**: The document assumes users possess the capacity for self-regulation and self-awareness, as it encourages them to reflect on their digital habits and assess their impact on personal well-being. It also presumes a level of vulnerability to digital harm, necessitating the provision of expert-developed resources to aid in maintaining a balanced digital life."
10_information_datum_device_use,Hinge,Hinge_Privacy_Policy.txt,"**Summary**: The primary objective of the Hinge Privacy Policy is to delineate the collection, usage, and sharing of personal data, thereby ensuring transparency and compliance with regional data protection regulations. The policy is structured to guide users through the intricacies of data handling practices, emphasizing user rights and data retention protocols. It aims to foster user trust by detailing cross-border data transfers and the collaborative operations of Match Group companies. Additionally, the policy addresses specific privacy considerations for children and outlines procedures for policy updates and user inquiries.

**Tone**: The rhetorical tone of the policy is predominantly supportive and engaging. This is evidenced by the informal and approachable language used, such as referring to the policy as a ""digital wingmate"" and encouraging users to ""get cozy"" while reading, which suggests an effort to make the document accessible and user-friendly.

**Types of Harm Addressed**: The policy primarily addresses privacy-related harm, with a focus on safeguarding personal data and ensuring compliance with data protection laws to prevent unauthorized data access or misuse.

**User Assumptions**: The policy assumes that users may lack detailed knowledge of data privacy practices, as indicated by the effort to make the policy clear and engaging. It presupposes a level of user responsibility in understanding their rights and the implications of data handling, while also recognizing potential vulnerabilities, particularly for children, in the context of data protection."
10_information_datum_device_use,Grindr,Grindr_privacy_policy.txt,"1. **Summary**: The Grindr Privacy and Cookie Policy delineates the regulatory framework governing the collection, use, sharing, and retention of personal information across its digital properties, including mobile and web platforms. The document's primary objective is to elucidate the mechanisms by which Grindr processes personal data, thereby empowering users with control over their information. It outlines the scope of data handling practices applicable to users, employees, contractors, and job applicants, with particular attention to compliance with regional data protection laws. The policy is designed to ensure transparency and user autonomy in the management of personal information.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it systematically outlines the legal and procedural aspects of data processing, emphasizing compliance and user empowerment. This is evidenced by the formal language and structured presentation of information, which underscores the platform's commitment to regulatory adherence and user rights.

3. **Types of Harm Addressed**: The policy substantively addresses privacy-related harm, focusing on the potential risks associated with the unauthorized access, misuse, or mishandling of personal information.

4. **User Assumptions**: The policy assumes that users possess a fundamental understanding of their privacy rights and the implications of data sharing. It presupposes users' capacity for self-regulation by providing mechanisms for them to control their personal information, while also recognizing their potential vulnerabilities to privacy infringements."
10_information_datum_device_use,Pinterest,Pinterest_Privacy_Policy.txt,"1. **Summary**: The document delineates Pinterest's Privacy Policy, emphasizing transparency in the collection and use of personal data, particularly under the regulatory frameworks of GDPR and California privacy laws. It aims to inform users about the types of personal data collected, the purposes for which it is used, and the options available to users regarding their data. The policy is designed to ensure compliance with international data protection standards while facilitating personalized content delivery. It underscores the platform's commitment to user empowerment through clear communication of data rights and choices.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the emphasis on transparency and user empowerment, as well as the effort to simplify complex technical concepts for user comprehension. The language suggests a collaborative relationship between the platform and its users, focusing on mutual understanding and informed consent.

3. **Types of Harm Addressed**: The policy primarily addresses privacy-related harm. It implicitly acknowledges the potential for misuse or unauthorized sharing of personal data, which could lead to privacy violations.

4. **User Assumptions**: The document assumes that users possess a basic understanding of data privacy concepts and are capable of making informed decisions regarding their personal data. It presupposes a level of user responsibility in managing privacy settings and understanding the implications of data sharing. Additionally, it suggests that users are interested in personalized content, which necessitates data collection and processing."
10_information_datum_device_use,Bumble,Bumble_Privacy_policy.txt,"1. **Summary**: The Bumble Privacy Policy delineates the mechanisms by which the platform collects, stores, protects, and shares user information, emphasizing compliance with international data transfer standards. The document's regulatory scope encompasses both the mobile application and associated websites, collectively referred to as ""Sites,"" and outlines the conditions under which user data may be shared with other users or third parties. The policy aims to safeguard personal data during international transfers, particularly to the United States and the UK, underscoring the importance of user awareness regarding these practices. Additionally, the policy highlights the role of the Bumble Group as the data controller and provides contact information for the Data Protection Officer to address privacy concerns.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as it provides definitive guidelines and procedures regarding data handling and user privacy. This is evidenced by the formal language used to describe data protection measures and the explicit instructions for users to read the policy carefully, particularly concerning international data transfers.

3. **Types of Harm Addressed**: The policy substantively addresses privacy-related harm by detailing the collection, storage, and sharing of personal information, and the measures in place to protect data during international transfers.

4. **User Assumptions**: The policy assumes that users are capable of understanding and complying with privacy guidelines, as it encourages them to read the document in conjunction with the Terms and Conditions. It also presumes a level of vulnerability regarding data privacy, necessitating explicit explanations of data protection measures and the provision of a contact point for privacy-related inquiries."
10_information_datum_device_use,Reddit,Reddit_Privacy_Policy.txt,"1. **Summary**: The Reddit Privacy Policy, effective August 16, 2024, articulates the platform's commitment to user privacy by outlining the minimal data collection practices and emphasizing user autonomy in managing personal information. The policy's regulatory scope encompasses the collection, use, and sharing of user data across Reddit's digital services, with the primary objective of enhancing user experience while safeguarding privacy. Interventions are designed to empower users with informed choices about their data visibility and participation level on the platform. The document underscores Reddit's role as a public platform, where user-generated content is largely accessible to the public, thus encouraging users to exercise discretion in their information sharing.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the emphasis on user empowerment and privacy as a fundamental right. The language used is reassuring and aims to foster trust by highlighting minimal data collection and user control over personal information.

3. **Types of Harm Addressed**: The policy substantively addresses privacy-related harm, focusing on the protection of user identity and personal information from unnecessary exposure or misuse.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are capable of making informed decisions about their privacy settings. It presumes a level of digital literacy, expecting users to understand the implications of participating in a public platform and to manage their information-sharing practices accordingly."
10_information_datum_device_use,Quora,Quora_Privacy_Policy.txt,"1. **Summary**: The Quora Privacy Policy delineates the regulatory framework governing the collection, use, and dissemination of personal information on the Quora Platform. It aims to inform users about the types of data collected, including account details and user-generated content, and the mechanisms of data sharing and disclosure. The policy is designed to ensure transparency and user awareness regarding data handling practices, thereby facilitating informed user participation. The document underscores Quora's role as the data controller, emphasizing its responsibility in safeguarding user privacy.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as it establishes clear guidelines and responsibilities regarding data handling and user privacy. This is evidenced by the formal language and structured presentation of information, which conveys an emphasis on compliance and regulatory adherence.

3. **Types of Harm Addressed**: The policy substantively addresses privacy harm by outlining the collection and sharing of personal information, thereby highlighting potential risks to user privacy if data is mishandled or inadequately protected.

4. **User Assumptions**: The policy assumes that users have a basic understanding of privacy concerns and the implications of sharing personal information online. It presupposes users' capacity to manage their privacy settings and make informed decisions about the information they choose to disclose on their profiles. Additionally, it implies a user responsibility to engage with the platform's privacy settings actively and to understand the potential visibility of their content and activities."
10_information_datum_device_use,Quora,Quora_Partner_Program.txt,"1. **Summary**: The policy document outlines the termination timeline and payment procedures for Quora's Partner Program, emphasizing the cessation of earnings accrual post-March 24, 2023. It provides logistical details on payment mechanisms, specifying the use of Stripe or PayPal based on geographical location, and sets a minimum earnings threshold for payout. The document's regulatory scope is confined to financial transactions and program closure, aiming to ensure clarity and transparency for program participants. User interventions are limited to connecting appropriate payment accounts and understanding the timeline for final payouts.

2. **Tone**: The rhetorical tone of the document is primarily authoritative, as it delivers definitive information regarding the termination of the program and the procedures for final payouts. This tone is evident in the clear deadlines and procedural instructions provided, which aim to guide users through the transition process without ambiguity.

3. **Types of Harm Addressed**: The document implicitly addresses economic harm by ensuring users are informed about the cessation of earnings and the necessary steps to receive final payments, thereby mitigating potential financial confusion or loss.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation in managing their financial accounts and understanding the implications of the program's termination. It presupposes a level of digital literacy necessary to connect payment accounts and comprehend the procedural details outlined. Additionally, it assumes users are responsible for staying informed about program changes through official communications."
10_information_datum_device_use,Tinder,Tinder_Privacy_Policy.txt,"**Summary**: The Tinder Privacy Policy document primarily aims to inform users about the collection, usage, and sharing of personal data, with a focus on transparency and user engagement. It delineates the regulatory framework governing data privacy, specifying regional adaptations for users in California, Washington, Nevada, the European Economic Area, the United Kingdom, Switzerland, and Japan. The policy outlines user rights concerning data retention and cross-border data transfers, emphasizing the company's commitment to safeguarding children's privacy. The document serves as a comprehensive guide to the platform's data practices, encouraging users to understand and exercise their privacy rights.

**Tone**: The dominant rhetorical tone of the policy is supportive and engaging. This is evidenced by the informal and inviting language used to encourage users to read the document, such as referring to the policy as a ""digital wingmate"" and suggesting users ""get cozy"" to explore data practices. This approach aims to demystify privacy policies and foster user trust.

**Types of Harm Addressed**: The policy substantively addresses privacy harm, focusing on the protection of personal data and user rights related to data collection, usage, and sharing.

**User Assumptions**: The policy assumes that users may lack motivation or understanding to engage with privacy policies, as suggested by the effort to make the document clear and engaging. It also presumes a baseline level of user responsibility to be informed about their rights and the data practices of the platform, while acknowledging regional legal variations that might affect user rights and responsibilities."
10_information_datum_device_use,Meta,Meta_Privacy_Policy_ How_Meta_collects_and_uses_user_data.txt,"1. **Summary**: The Privacy Policy document delineates the procedures and principles governing the collection, usage, and dissemination of user information across Meta's platforms, including Facebook, Instagram, Messenger, and Meta Quest. It aims to inform users of their rights regarding data management, retention, and protection, while ensuring compliance with legal standards and harm prevention measures. The policy's regulatory scope encompasses data privacy, emphasizing transparency in data handling and user empowerment through rights to manage or delete personal information. It also outlines the legal bases for data processing and the mechanisms for responding to legal requests, thereby framing user data protection as a collaborative responsibility between the platform and its users.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, characterized by a formal and instructive approach. This is evidenced by the structured presentation of legal obligations, user rights, and procedural guidelines, which collectively underscore Meta's commitment to regulatory compliance and user data protection.

3. **Types of Harm Addressed**: The policy substantively addresses privacy harm, focusing on the protection of personal data from unauthorized access, misuse, or exposure. It implicitly acknowledges potential economic harm by outlining user rights to manage and control their data, which could otherwise be exploited for financial gain.

4. **User Assumptions**: The document assumes that users possess a basic understanding of data privacy principles and the capacity to exercise their rights regarding personal information management. It presupposes a level of user responsibility in engaging with the platform's privacy settings and acknowledges potential vulnerabilities by providing mechanisms for users to protect their data actively."
10_information_datum_device_use,Google Messages,Google_Messages_privacy_policy.txt,"1. **Summary**: The Google Privacy Policy document primarily aims to elucidate the mechanisms by which user information is collected, processed, and managed, emphasizing user autonomy in data governance. It delineates the regulatory scope concerning compliance with European Union and United Kingdom data protection laws, thereby aligning with international legal standards. The policy is structured to empower users through various privacy management tools, such as account settings and private browsing options, to enhance their control over personal data. Ultimately, the document seeks to foster informed user engagement with Google's diverse array of services, ensuring transparency and user-centric data management practices.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as it emphasizes user empowerment and autonomy in managing personal information. This is evidenced by the provision of tools like the Privacy Checkup and detailed guidance on privacy settings, which encourage proactive user involvement in data protection.

3. **Types of Harm Addressed**: The policy substantively addresses privacy-related harm, focusing on the protection of personal information and compliance with data protection laws to mitigate risks associated with unauthorized data access and misuse.

4. **User Assumptions**: The document assumes that users possess a baseline capacity for self-regulation and are capable of engaging with privacy management tools to protect their own data. It presumes a level of digital literacy sufficient to navigate privacy settings and make informed decisions about personal information sharing. Additionally, it implies that users are responsible for actively managing their privacy preferences to safeguard their data."
11_harassment_bullying_individual_target,Bumble,Bumble_bullying_and_abuse.txt,"**Summary**: The policy document seeks to establish a community environment that fosters respectful and kind interactions by explicitly prohibiting behaviors that constitute harassment, bullying, or targeting of individuals or groups. Its regulatory scope encompasses a wide range of abusive behaviors, including emotional manipulation, body shaming, and the release of private information without consent. The policy outlines specific user interventions aimed at preventing and addressing these harmful behaviors, thereby ensuring a safe and supportive platform experience. It emphasizes the prohibition of actions that degrade or dehumanize individuals, particularly those affecting survivors of sexual violence and other vulnerable groups.

**Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the comprehensive list of prohibited behaviors and the clear, directive language used to delineate unacceptable conduct, reflecting a commitment to preemptively mitigate harm and enforce community standards.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, identity-based harm, and privacy violations. These are evidenced through the prohibition of actions such as emotional abuse, defamation, targeting based on victim status, and unauthorized sharing of personal information.

**User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviors and thus require clear guidelines and restrictions to regulate their conduct. It also presupposes a degree of user vulnerability, particularly for survivors of abuse, and expects users to adhere to community standards that prioritize safety and respect."
11_harassment_bullying_individual_target,Snapchat,Snapchat_Harassment_&_Bullying.txt,"1. **Summary**: The policy document articulates a comprehensive framework aimed at mitigating harassment and bullying on the platform, with a particular emphasis on prohibiting sexual harassment and unauthorized sharing of private information. It delineates a regulatory scope that encompasses both policy enforcement and product design interventions, such as default privacy settings, to preemptively curb harmful interactions. The document underscores a commitment to protecting users from demeaning, defamatory, or discriminatory content by integrating dynamic safeguards and resources. It further emphasizes the importance of user compliance with privacy norms, advocating for the removal of content upon request to respect others' privacy rights.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative and preventative. This is evidenced by the firm prohibitions against specific harmful behaviors and the emphasis on preemptive measures through product design, reflecting a proactive stance on user safety and compliance enforcement.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, sexual, and privacy harms. It highlights the prohibition of bullying, harassment, and the unauthorized sharing of private information, as well as the sending of sexually explicit content without consent.

4. **User Assumptions**: The policy assumes that users possess a basic capacity for self-regulation and responsibility, as evidenced by directives to respect privacy rights and remove content upon request. It also presupposes a potential vulnerability to harassment and privacy violations, necessitating protective measures and default privacy settings to safeguard users."
11_harassment_bullying_individual_target,Discord,Discord_Bullying_and_harassment.txt,"1. **Summary**: The policy document delineates Discord's regulatory framework aimed at mitigating bullying, harassment, and threats within its platform. It articulates a zero-tolerance approach towards behaviors that intentionally cause distress or intimidation, emphasizing the creation of a respectful and inclusive digital environment. The policy outlines specific prohibitions, including the dissemination of unwanted sexual content, non-consensual disclosure of personal information, and incitement to self-harm, alongside threats of physical and emotional harm. Enforcement measures include potential escalation to law enforcement to avert imminent harm, underscoring the platform's commitment to user safety.

2. **Tone**: The rhetorical tone of the policy is authoritative and preventative. This is evidenced by the firm language used to describe the platform's stance against harassment and threats, as well as the explicit detailing of prohibited behaviors and potential legal escalation, which underscores a commitment to preemptively addressing harmful conduct.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, sexual, and physical harms. It also implicitly references identity-based harm through the mention of non-consensual disclosure of sexual orientation or gender identity.

4. **User Assumptions**: The document assumes users have the potential to engage in harmful behaviors, necessitating clear guidelines and prohibitions. It presumes a degree of user vulnerability to psychological and reputational harm, highlighting the platform's responsibility to protect users. Additionally, it implies an expectation of users' capacity for self-regulation and respect towards others, as well as a responsibility to adhere to community standards."
11_harassment_bullying_individual_target,LinkedIn,LinkedIn_Harassment_and_abusive_content.txt,"**Summary**: The LinkedIn safety policy document delineates a regulatory framework aimed at maintaining a professional and respectful environment by prohibiting harassment, bullying, and abusive conduct among its users. It outlines specific interventions, such as the removal of content that constitutes personal attacks, intimidation, or uncivil behavior, thereby ensuring a safe space for professional interactions. The policy explicitly prohibits behaviors such as abusive language, personal insults, disparagement of physical attributes, and doxxing, while allowing for constructive criticism and discourse on public matters. This regulatory approach underscores LinkedIn's commitment to fostering a civil digital environment conducive to professional networking.

**Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates prohibited behaviors and the platform's commitment to enforcing these standards. This is evidenced by the definitive language used to describe actions that will be taken against violators, such as content removal, and the explicit listing of unacceptable behaviors.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm through the prohibition of intimidation and shaming, reputational harm through the prevention of disparagement and doxxing, and identity-based harm by disallowing comparisons to extremist groups and calls for exclusion based on beliefs.

**User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are responsible for maintaining civility in their interactions. It also implies a recognition of user vulnerability to psychological and reputational harm, necessitating protective measures against abusive conduct. Furthermore, it presupposes that users can engage in constructive discourse without resorting to personal attacks or uncivil behavior."
11_harassment_bullying_individual_target,Reddit,Reddit_Do_not_threaten_harass_bully.txt,"1. **Summary**: The policy document delineates Reddit's regulatory framework against harassment, threatening, and bullying behaviors, emphasizing a zero-tolerance stance towards such actions within its platform. It aims to preserve open conversation by defining and prohibiting behaviors that intimidate or exclude individuals, thereby safeguarding user participation. The document outlines specific forms of harassment, including unwanted invective, non-consensual sexualization, and persistent following across communities, highlighting the platform's commitment to mitigating these harms. It provides mechanisms for users to report harassment, reinforcing the platform's proactive approach to maintaining a safe digital environment.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the unequivocal language used in phrases such as ""we do not tolerate"" and the clear delineation of unacceptable behaviors, which underscores the platform's commitment to preventing harassment and ensuring user safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and sexual harms. Psychological harm is implied through references to intimidation and abuse, reputational harm through the potential public nature of harassment, and sexual harm through the mention of non-consensual sexualization.

4. **User Assumptions**: The policy assumes that users are capable of identifying and reporting harassment, indicating an expectation of user vigilance and responsibility in maintaining a safe community. It also presupposes that users understand the distinction between acceptable disagreement and harassment, suggesting an assumption of user capacity for self-regulation and discernment in online interactions."
11_harassment_bullying_individual_target,Meta,Meta_Bullying_and_Harassment_Publisher_and_Creator_Guidelines.txt,"1. **Summary**: The policy document delineates guidelines aimed at mitigating bullying and harassment on the platform, specifically targeting content that degrades or shames private individuals. It establishes a regulatory framework that permits open discourse on public figures while protecting private individuals from targeted harassment. The document outlines specific prohibitions, such as altering images to degrade individuals and sharing content that shames victims of physical bullying. The policy seeks to balance freedom of expression with the protection of individual dignity and privacy.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes the removal of harmful content and provides clear guidelines to prevent the creation of such content. This is evidenced by the use of directive language such as ""don't"" and ""remove content,"" which underscores a proactive approach to harm prevention.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, and privacy harm. These are evidenced by the focus on degrading or shaming individuals, which can impact mental well-being and reputation, and the protection of private individuals from unwanted public exposure.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for understanding the distinction between public and private individuals. It also presumes a level of user awareness regarding the potential harm of their actions and content, implying an expectation of responsible content creation and sharing."
11_harassment_bullying_individual_target,Discord,Discord_Defining_and_Addressing_Online_Trolling.txt,"1. **Summary**: The policy document from Discord's Safety Centre articulates the platform's commitment to mitigating harassment and bullying by defining and regulating online trolling behaviors. It emphasizes the complexity of defining trolling, recognizing both its benign and harmful manifestations, and underscores the platform's role in fostering a safe community environment. The policy aims to educate users about the impact of their online actions and to promote understanding and learning from mistakes. By doing so, it seeks to protect users from psychological and reputational harm while maintaining a culture of safety and respect.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and educational. This is evidenced by the emphasis on understanding the effects of online behaviors and crafting policies that aim to educate users, rather than merely punishing them, suggesting a focus on prevention through awareness and learning.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and reputational harm. It acknowledges the impact of trolling behaviors on individuals and communities, highlighting the potential for such actions to affect mental well-being and social standing.

4. **User Assumptions**: The document assumes that users may not fully understand the impact of their online behaviors and that they have the capacity to learn and self-regulate when provided with appropriate guidance. It also implies a vulnerability among users to psychological harm from witnessing or experiencing trolling, as well as a shared responsibility to maintain a safe and respectful community environment."
11_harassment_bullying_individual_target,Badoo,Badoo_bullying_and_abusive_content.txt,"**Summary**: The policy document primarily aims to establish a digital environment that fosters respectful interactions and prohibits behaviors that contribute to harassment, bullying, or targeting of individuals or groups. Its regulatory scope encompasses a wide array of harmful behaviors, including emotional abuse, body shaming, and the dissemination of private information without consent. The document outlines specific prohibitions against actions such as blackmail, intimidation, and the creation of defamatory content, emphasizing the platform's commitment to user safety and dignity. Interventions are designed to prevent and mitigate harm by clearly defining unacceptable behaviors and promoting a culture of kindness and respect.

**Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the clear and direct language used to delineate prohibited behaviors, alongside a firm commitment to fostering a safe community environment. The policy's prescriptive nature underscores an authoritative stance, while its emphasis on creating ""kind connections"" reflects a preventative approach aimed at preempting harmful interactions.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, identity-based harm, and privacy violations. It also implicitly touches upon economic harm through the mention of blackmail and the potential consequences of defamatory content.

**User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviors, necessitating clear guidelines to curb such actions. It presupposes a degree of user vulnerability, particularly regarding privacy and emotional well-being, and expects users to adhere to community standards that prioritize respect and safety. Additionally, there is an implicit expectation for users to exercise self-regulation and responsibility in their interactions, as evidenced by the detailed enumeration of prohibited behaviors."
11_harassment_bullying_individual_target,YouTube,YouTube_Harassment _&_cyberbullying_policies.txt,"1. **Summary**: The YouTube Harassment and Cyberbullying Policy document delineates the platform's commitment to safeguarding its community by prohibiting content that perpetuates harassment or cyberbullying. The policy explicitly forbids content involving prolonged insults or slurs targeting individuals based on physical traits or protected group statuses, such as age, disability, or race, and emphasizes a stricter stance on content affecting minors. It encourages users to actively participate in maintaining a safe environment by reporting violations and provides resources for personal safety and privacy protection. The policy underscores a collaborative approach to community safety, highlighting shared responsibilities among users and the platform.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the clear directives against specific harmful behaviors and the emphasis on user participation in reporting violations, which collectively aim to preemptively mitigate harassment and bullying.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, identity-based, and privacy harms. It highlights the impact of insults, slurs, threats, and doxxing on individuals' mental well-being and social standing, particularly for those in protected groups.

4. **User Assumptions**: The policy assumes users have the capacity for self-regulation and a shared responsibility in maintaining community safety. It presupposes that users are capable of identifying harmful content and are willing to report violations, suggesting an expectation of proactive engagement in upholding the platform's standards."
11_harassment_bullying_individual_target,Instagram,Instagram_hate_accounts.txt,"1. **Summary**: The policy document primarily aims to mitigate instances of harassment and bullying on Instagram by providing users with mechanisms to report such behavior. It delineates the regulatory scope by defining actions that constitute bullying or harassment, such as impersonation or malicious intent in posts and comments. The document encourages user intervention through reporting and blocking features, thereby promoting a self-regulatory approach to maintaining community standards. The overarching objective is to uphold a safe and respectful online environment by empowering users to act against violations of the platform's guidelines.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on user empowerment through reporting tools and guidance on protective actions, such as blocking offenders, which suggests a focus on preemptive measures to curb digital harm.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on bullying and harassment. It also implicitly considers reputational harm, particularly in cases of impersonation, which can damage an individual's public image or personal relationships.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are proactive in safeguarding their online experience. It presupposes a level of digital literacy, expecting users to identify and report violations effectively. Additionally, it implies a shared responsibility among users to contribute to a safe community by utilizing the platform's reporting and blocking features."
12_teen_parent_comment_young,Snapchat,Snapchat_Safeguards_for_Teens_Parentâ€™s_Guide_to_Snapchat.txt,"1. **Summary**: The policy document outlines Snapchat's regulatory framework aimed at creating a secure and enjoyable environment for teen users by implementing specific safeguards. It emphasizes the prevention of unwanted contact and ensures an age-appropriate content experience by restricting communication to known contacts and providing tools for blocking and reporting. The policy's scope includes proactive measures to limit the visibility of teens to strangers and offers in-app warnings to mitigate potential risks. The document also underscores a zero-tolerance stance towards severe violations, reinforcing the platform's commitment to user safety.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on proactive measures to prevent unwanted contact and the provision of tools and resources designed to empower teen users and their guardians in maintaining a safe digital environment.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm by focusing on preventing unwanted contact and ensuring a safe interaction environment. It also implicitly addresses privacy harm by controlling the visibility of teen users to strangers and managing their digital interactions.

4. **User Assumptions**: The policy assumes that teen users are vulnerable to unwanted contact and may lack the capacity for self-regulation in online interactions. It presupposes a need for external safeguards to protect them from potential risks, while also assuming a degree of responsibility on the part of users to utilize the provided safety tools effectively."
12_teen_parent_comment_young,Instagram,Instagram_parent's_guide.txt,"1. **Summary**: The document, ""A Parent and Carerâ€™s Guide to Instagram,"" primarily aims to equip parents and carers with strategies to safeguard their teenage childrenâ€™s online experiences on Instagram. It delineates a regulatory scope that includes privacy management, interaction control, and security measures, thereby fostering a safer digital environment for young users. The guide emphasizes practical interventions such as managing account privacy, controlling message interactions, and limiting advertiser targeting to mitigate potential harms. Through collaborative insights from experts like Lorraine Candy and Parent Zone, the document seeks to empower parents with the knowledge to engage constructively with their teens about online safety.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the documentâ€™s collaborative approach, involving expert voices and providing practical, user-friendly advice aimed at fostering a constructive dialogue between parents and teens, rather than imposing strict or punitive measures.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and privacy harms. It focuses on managing interactions and privacy settings to prevent unwanted contact and exposure, thereby protecting users from potential psychological distress and reputational damage.

4. **User Assumptions**: The document assumes that teenage users may lack the capacity for full self-regulation and are vulnerable to various online risks, necessitating parental guidance. It presupposes that parents and carers are responsible for actively engaging in their childrenâ€™s digital lives and are capable of implementing the recommended safety measures to protect their childrenâ€™s online well-being."
12_teen_parent_comment_young,Discord,Discord_Tip_ for_Parents.txt,"1. **Summary**: The policy document primarily aims to safeguard young users on Discord by delineating acceptable and unacceptable behaviours within the platform, specifically targeting interactions that may occur in private, invite-only groups. It outlines the Community Guidelines, emphasizing the prohibition of bullying, harassment, self-harm promotion, violent threats, and sexualization of minors. The document encourages parental involvement in reviewing these guidelines with their teens and provides mechanisms for reporting violations to maintain a safe user environment. The regulatory scope extends to empowering users with tools to control their experience and ensuring compliance through the Trust & Safety team's oversight.

2. **Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on educating both parents and teens about acceptable behaviours, encouraging proactive engagement with the guidelines, and offering resources to manage and report harmful interactions.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (bullying and harassment), sexual harm (content that sexualizes minors), and identity-based harm (violent threats). It also implicitly references reputational harm through the mention of inappropriate content and privacy concerns by discussing the evasion of bans and blocks.

4. **User Assumptions**: The document assumes that users, particularly teens, may lack full awareness of acceptable online conduct and are potentially vulnerable to harmful interactions. It presumes a need for parental guidance and oversight in navigating the platform's safety features. Additionally, it suggests that users have a responsibility to report violations and utilize available tools to manage their digital environment effectively."
12_teen_parent_comment_young,TikTok,TikTok_teen_privacy_and_safety.txt,"**Summary**: The policy document under review primarily aims to establish a framework for safeguarding teen users on the platform, with a particular emphasis on privacy and safety settings. It outlines the procedural steps for account creation and management, content interaction, and user engagement, thereby delineating the regulatory scope to encompass both preventative and responsive measures. The document seeks to guide users through the platform's functionalities while embedding safety protocols, particularly for younger demographics. The intended interventions include enhancing user awareness and control over personal data, fostering a secure environment for content creation, and promoting responsible social interactions.

**Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes the establishment of safety settings and privacy controls to preemptively mitigate risks associated with online engagement. This is evidenced by the detailed instructions on managing account settings and the emphasis on user empowerment through informed decision-making.

**Types of Harm Addressed**: The policy substantively addresses psychological, reputational, and privacy harms. It focuses on protecting users from potential negative mental health impacts, safeguarding their online reputation, and ensuring the confidentiality of personal information.

**User Assumptions**: The document assumes that users, particularly teens, may lack full awareness of digital risks and therefore require structured guidance to navigate the platform safely. It presupposes a need for external regulation to support users' capacity for self-regulation and implies a vulnerability to privacy breaches and reputational damage, placing a responsibility on both the platform and users to maintain a secure digital environment."
12_teen_parent_comment_young,YouTube,YouTube_age_restricted_content.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework for age-restricting content that, while not violating Community Guidelines, may be inappropriate for users under 18, aligning with the platform's Terms of Service. It aims to safeguard younger audiences by implementing age restrictions on various content forms, including videos and live streams, that feature themes such as child safety, dangerous activities, and sexually suggestive material. The document provides illustrative examples of content that might trigger age restrictions, emphasizing the platform's commitment to preventing exposure to potentially harmful material. This policy underscores YouTube's proactive approach to content moderation, balancing free expression with user protection.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes the platform's efforts to preemptively shield minors from unsuitable content. This is evidenced by the detailed criteria and examples provided to guide content creators and ensure compliance with age-related restrictions.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly concerning content that could mislead or negatively influence minors. It also considers physical harm, as seen in the prohibition of content depicting dangerous activities, and sexual harm, through restrictions on sexually suggestive content.

4. **User Assumptions**: The policy assumes that users, particularly minors, are vulnerable to imitation and influence by harmful content, necessitating protective measures. It also presupposes a degree of responsibility among content creators to understand and adhere to age-restriction guidelines, reflecting an expectation of self-regulation and compliance with platform standards."
12_teen_parent_comment_young,Pinterest,Pinterest_Resources_for_parents_and_caregivers_of_teens.txt,"1. **Summary**: The policy document delineates Pinterest's regulatory framework aimed at safeguarding teenage users, focusing on age requirements and parental involvement in account management. It establishes a minimum age of 13 for account creation, with higher age thresholds in certain jurisdictions, and outlines procedures for account deletion if these criteria are not met. The document emphasizes parental control through a passcode system that restricts certain account settings, thereby enhancing oversight of privacy and social interactions. The policy aims to balance user autonomy with protective measures, ensuring a safe digital environment for younger users.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the language that encourages parental involvement and provides clear guidance on safety measures, reflecting a commitment to fostering a secure online space for teens while empowering caregivers with tools to manage their children's digital interactions.

3. **Types of Harm Addressed**: The policy primarily addresses psychological, privacy, and identity-based harms. It seeks to mitigate risks associated with unauthorized access to personal information and inappropriate social interactions by enforcing age restrictions and enabling parental control over account settings.

4. **User Assumptions**: The document assumes that teenage users may lack full capacity for self-regulation, necessitating parental oversight to ensure safe online behavior. It also presupposes a level of vulnerability among teens to privacy breaches and inappropriate content, thus justifying the implementation of age verification and parental control mechanisms. Additionally, it implies a responsibility on the part of parents and caregivers to actively engage in their children's online safety."
12_teen_parent_comment_young,Pinterest,Pinterest_Teen_safety_options.txt,"1. **Summary**: The policy document from Pinterest delineates its commitment to maintaining a safe and positive online environment for teenage users by providing specific privacy tools and resources. It outlines the regulatory framework governing teen accounts, emphasizing privacy settings and age-appropriate experiences, particularly for users under 16 whose accounts are automatically set to private. The document aims to empower teens with knowledge on managing their online presence and guides parents or caregivers in supporting their children's digital safety. Furthermore, it addresses procedures for rectifying account issues, such as incorrect age information, to ensure compliance with platform policies.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the language that emphasizes guidance, empowerment, and the provision of resources to help teens and their caregivers navigate safety settings effectively, rather than punitive measures or strict enforcement.

3. **Types of Harm Addressed**: The policy substantively addresses psychological harm, privacy harm, and identity-based harm. It focuses on protecting users' personal information and ensuring a safe environment that mitigates risks associated with exposure and identity disclosure.

4. **User Assumptions**: The policy assumes that teenage users may lack full capacity for self-regulation and are vulnerable to privacy and identity-based risks, necessitating structured guidance and parental involvement. It presupposes a need for age-specific interventions and the capability of teens to manage their privacy settings with appropriate support."
12_teen_parent_comment_young,WhatsApp,WhatsApp_Help_your_teen_stay_safe .txt,"1. **Summary**: The policy document aims to guide parents and guardians in fostering a safe digital environment for teens using WhatsApp by providing practical advice and tools. It emphasizes the importance of parental involvement in teaching teens about privacy settings, the risks of sharing personal information, and the use of safety features to mitigate potential harms. The document's regulatory scope is centered on promoting safe communication practices and encouraging open dialogue between parents and teens about online safety. It seeks to empower users by enhancing their understanding of privacy controls and the mechanisms available to address bullying and harassment.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by its focus on collaboration between parents and teens, the provision of educational resources, and the encouragement of proactive conversations about digital safety, rather than punitive measures.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through discussions of bullying and harassment, privacy harm through guidance on information sharing, and reputational harm by advising on the consequences of sharing personal information.

4. **User Assumptions**: The document assumes that teens may lack full awareness of digital risks and require guidance to navigate them safely. It presupposes a level of vulnerability in teens' online interactions and suggests that parents have a responsibility to educate and support their children in developing safe digital habits. Additionally, it implies that teens have the capacity to learn and apply safety practices with appropriate guidance."
12_teen_parent_comment_young,YouTube,YouTube_children_and_teens.txt,"1. **Summary**: The policy document outlines YouTube's strategic framework for safeguarding children and teenagers on its platform, emphasizing the creation of a secure and enriching digital environment. It delineates the Youth Principles, which guide the platform's efforts to provide age-appropriate content and protect young users from harmful experiences. The document underscores the importance of tailored experiences through YouTube Kids and supervised experiences, which are designed to accommodate the developmental needs of younger users while empowering caregivers with control tools. The regulatory scope is comprehensive, addressing issues from exposure to harmful content to the promotion of safe online interactions.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on fostering a positive and enriching environment for young users, as well as the proactive measures outlined to prevent exposure to harmful content and experiences.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as seen in references to combating eating disorders and suicide, and implicitly considers reputational and identity-based harms by promoting safe and trusted interactions. Privacy concerns are also addressed through the provision of tools for caregivers to manage online experiences.

4. **User Assumptions**: The document assumes that young users are inherently vulnerable and require special protections due to their developmental stage. It presumes a need for external regulation and oversight, particularly by caregivers, to ensure safe online engagement. Additionally, it suggests that young users are evolving in their online behaviors, necessitating adaptive and responsive platform policies."
12_teen_parent_comment_young,TikTok,TikTok_youth_safety_and_well-being.txt,"1. **Summary**: The TikTok Youth Safety and Well-Being policy document delineates the platform's commitment to ensuring a secure and positive environment for users under 18, emphasizing age-appropriate access and content. It establishes a regulatory framework that includes age verification, content restrictions, and specialized experiences for users under 13, particularly in the United States. The policy outlines mechanisms for account banning and appeals, alongside procedures for reporting and addressing severe violations, particularly those involving sexual offenses against minors. The document underscores the platform's collaboration with external organizations like the National Center for Missing and Exploited Children to report and mitigate instances of youth exploitation.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear stipulations on age restrictions, account management, and reporting protocols. The use of definitive language such as ""we will ban"" and ""we do not allow"" underscores a firm commitment to enforcing safety measures and regulatory compliance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, physical, and sexual harm, with additional implications for developmental harm. These are highlighted through the platform's prohibitions on content that risks such harms and its stringent actions against severe violations.

4. **User Assumptions**: The policy assumes that users, particularly young people, are vulnerable to various online harms and may lack the capacity for full self-regulation. It presumes a need for protective measures, such as age verification and content restrictions, to safeguard these users. Additionally, it implies a responsibility among users to report underage accounts and potential violations, indicating an expectation of community vigilance and participation in safety governance."
13_spam_server_report_account,Bumble,Bumble_spam.txt,"1. **Summary**: The policy document delineates a regulatory framework aimed at mitigating the proliferation of spam on the platform, with a focus on safeguarding user interactions from deceptive and misleading content. It establishes clear prohibitions against practices such as the dissemination of fraudulent links, the use of automation to manipulate engagement metrics, and the sharing of sensitive personal information. The document outlines enforcement mechanisms and provides a recourse for users to contest actions taken against their accounts, thereby promoting a balanced approach to regulation. The primary objective is to maintain the integrity of user interactions and the platform's reputation by curbing activities that disrupt or exploit the user experience.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the prescriptive language and clear delineation of prohibited behaviors. The document employs definitive statements such as ""We donâ€™t allow"" and ""Attempts to artificially influence"" to assert control and establish non-negotiable boundaries for user conduct.

3. **Types of Harm Addressed**: The policy explicitly addresses reputational harm by targeting deceptive practices that could mislead users and damage the platform's credibility. It also implicitly addresses privacy harm through the prohibition of sharing sensitive self-identifying information.

4. **User Assumptions**: The policy assumes that users may engage in behaviors that risk platform integrity, such as creating multiple accounts or using automation to manipulate interactions. It presumes a level of user responsibility in adhering to guidelines and provides mechanisms for users to appeal enforcement actions, suggesting an expectation of user engagement in self-regulation and accountability."
13_spam_server_report_account,Facebook Messenger,Facebook_Messenger_Spam.txt,"1. **Summary**: The document delineates Facebook's regulatory framework for managing spam, aiming to mitigate the spread of unwanted content and safeguard user accounts. It prescribes user interventions such as securing accounts, reviewing account activity, and reporting spam to enhance platform safety. The policy's scope encompasses preventative measures against unauthorized access and dissemination of malicious content. It emphasizes user participation in identifying and reporting spam to collectively uphold the integrity of the platform.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the guidance provided to users on securing their accounts and the encouragement to report spam, reflecting a collaborative approach to maintaining platform safety.

3. **Types of Harm Addressed**: The policy explicitly addresses economic harm, as spam can lead to scams and unauthorized access to accounts. It also implicitly touches on privacy harm, given the potential for unauthorized account access and dissemination of personal information.

4. **User Assumptions**: The policy assumes users possess the capacity for self-regulation and responsibility in managing their account security. It presupposes a level of digital literacy, expecting users to identify suspicious activities and take corrective actions such as changing passwords and reporting spam. Additionally, it implies a shared responsibility between the platform and users in maintaining a safe online environment."
13_spam_server_report_account,Discord,Discord_spam_and_hacking.txt,"1. **Summary**: The document delineates a safety policy aimed at mitigating risks associated with spam and hacking on the Discord platform. It emphasizes preventative measures users can take, such as avoiding unfamiliar links and downloads, and underscores the importance of safeguarding personal information. The policy outlines the platform's commitment to user safety through proactive spam filtering and provides guidance on reporting compromised accounts. It serves to empower users with knowledge and tools to enhance their digital security and maintain control over their online interactions.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on proactive user education and guidance, such as advising users to scan links and be cautious with personal information, which suggests a focus on equipping users with the knowledge to avoid potential harm.

3. **Types of Harm Addressed**: The policy explicitly addresses economic harm through potential phishing and hacking incidents, privacy harm through unauthorized access to personal information, and psychological harm through the stress and anxiety associated with compromised accounts and unsolicited communications.

4. **User Assumptions**: The policy assumes that users possess a basic level of digital literacy, enabling them to understand and implement the recommended safety measures. It also presumes a degree of user vulnerability to online threats, necessitating guidance and intervention. Furthermore, there is an implicit expectation of user responsibility in managing their own security settings and reporting issues to the platform's Trust & Safety team."
13_spam_server_report_account,Google Messages,Google_Messages_Block_senders_and_report_spam.txt,"1. **Summary**: The policy document outlines procedures for users to block and report spam messages within the Google Messages application, focusing on enhancing user control over unwanted communications. It primarily targets the mitigation of spam-related disruptions by providing clear instructions for blocking and unblocking contacts. The regulatory scope is limited to user-initiated actions on Android devices, emphasizing user autonomy in managing digital interactions. The document aims to empower users by facilitating a self-regulatory approach to maintaining a secure and orderly messaging environment.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the straightforward, instructional language designed to guide users through the process of managing spam. The document's emphasis on user empowerment and the provision of community support options further underscores a tone that prioritizes user assistance and engagement.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and privacy harms. The focus on blocking spam messages aims to alleviate user frustration and anxiety associated with unsolicited communications, while also protecting users' privacy by controlling who can contact them.

4. **User Assumptions**: The document assumes that users possess a basic level of digital literacy and the capacity to follow procedural instructions for managing spam. It also presupposes that users are proactive in seeking to protect their messaging environment from unwanted interactions, reflecting an expectation of user responsibility in digital self-regulation."
13_spam_server_report_account,Reddit,Reddit_spam.txt,"1. **Summary**: The Reddit policy document delineates the platform's regulatory framework for identifying and managing spam, defined as repetitive and unsolicited actions that detrimentally impact users and communities. The policy aims to mitigate spam through content removal and account restrictions, emphasizing the importance of authentic engagement and adherence to community-specific rules. It provides guidance for users to avoid being labeled as spammers, suggesting the use of advertising for business-related content. The document reflects Reddit's commitment to evolving its spam prevention strategies in response to changing user behaviors.

2. **Tone**: The tone of the policy is predominantly authoritative, as it clearly delineates the rules and consequences associated with spam, including account bans and content removal. This authoritative stance is reinforced by the policy's prescriptive guidelines and the emphasis on adherence to both platform-wide and community-specific rules.

3. **Types of Harm Addressed**: The policy explicitly addresses reputational harm, as spam can negatively affect the perception of users and communities. Additionally, it implicitly touches on economic harm by advising users to consider advertising options for business-related content, thereby acknowledging the potential financial implications of spam.

4. **User Assumptions**: The document assumes users have the capacity for self-regulation, as it encourages them to engage authentically and seek clarification from community moderators. It also presupposes a level of user responsibility in adhering to both general and community-specific guidelines, while recognizing the potential for users to inadvertently engage in spam-like behaviors."
13_spam_server_report_account,Discord,Discord_scams.txt,"1. **Summary**: The policy document aims to educate users on recognizing and mitigating the risks associated with common online scams, particularly within the Discord platform. It delineates various fraudulent tactics, such as social engineering and staff impersonation, to enhance user awareness and promote proactive self-protection measures. The regulatory scope is primarily preventative, focusing on empowering users with knowledge to avoid falling victim to scams. The document encourages users to report suspicious activities, thereby fostering a collaborative approach to platform safety.

2. **Tone**: The dominant rhetorical tone of the policy is preventative. This is evidenced by its focus on educating users about potential threats and providing guidance on how to avoid them, rather than solely penalizing or reprimanding users for falling victim to scams.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, through the manipulation involved in social engineering; economic harm, via financial losses from scams; and privacy harm, through unauthorized access to personal information.

4. **User Assumptions**: The document assumes that users possess a basic capacity for self-regulation and can be educated to recognize and avoid scams. It presupposes a level of vulnerability to manipulation tactics but also implies a responsibility on the part of users to remain vigilant and report suspicious activities to maintain platform safety."
13_spam_server_report_account,Discord,Discord_Platform_Manipulation.txt,"1. **Summary**: The document delineates Discord's Platform Manipulation Policy, which aims to safeguard the user experience by prohibiting platform abuse, specifically through spam and related activities. The regulatory scope encompasses actions taken against both individual accounts and servers that facilitate or engage in unsolicited bulk messaging and other disruptive behaviors. The policy outlines interventions such as the removal of accounts and servers that engage in or support such activities, emphasizing the prohibition of modifications to the Discord client for spam purposes. This framework seeks to maintain the integrity of user interactions by mitigating disruptions caused by automated and manual spam activities.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as it clearly delineates prohibited behaviors and the consequences for engaging in such activities. The use of definitive language, such as ""we prohibit"" and ""we will take action,"" underscores a firm stance on enforcement and compliance, reflecting a commitment to maintaining platform integrity.

3. **Types of Harm Addressed**: The policy primarily addresses reputational and economic harm. Reputational harm is implicated through the potential degradation of user experience and trust in the platform, while economic harm is suggested by the disruption caused to the platform's operational integrity and user engagement metrics.

4. **User Assumptions**: The policy assumes that users have the potential to engage in disruptive behaviors, either intentionally or unintentionally, through both manual and automated means. It presupposes a need for regulatory oversight due to users' capacity to exploit platform functionalities for spam. Additionally, there is an implicit assumption that users bear the responsibility to adhere to platform guidelines and refrain from modifying the client or engaging in coordinated abuse."
13_spam_server_report_account,Badoo,Badoo_spam.txt,"1. **Summary**: The policy document delineates the platform's regulatory framework aimed at mitigating spam-related activities, focusing on preventing deceptive practices and maintaining the integrity of user interactions. It outlines prohibitions against content designed to mislead, the use of automation to manipulate engagement, and the sharing of sensitive information. The document also specifies the enforcement mechanisms in place and provides a recourse for users to contest actions taken against their accounts. Overall, the policy seeks to foster a safe and authentic digital environment by curbing activities that could undermine user trust and platform credibility.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the explicit prohibitions and clear delineation of unacceptable behaviours, coupled with a structured enforcement mechanism. The language is directive and prescriptive, emphasizing compliance and adherence to the guidelines.

3. **Types of Harm Addressed**: The policy explicitly addresses reputational and privacy harms. Reputational harm is implicated through the prevention of misleading content and deceptive practices, while privacy harm is addressed by prohibiting the sharing of sensitive self-identifying information.

4. **User Assumptions**: The policy assumes that users have the potential to engage in deceptive or disruptive behaviours, necessitating clear guidelines and enforcement measures. It presumes a degree of user vulnerability to misleading content and unauthorized data sharing, while also expecting users to take responsibility for adhering to the platform's standards and to engage with the recourse process if they believe enforcement actions are unjust."
13_spam_server_report_account,YouTube,YouTube_spam_policy.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework aimed at mitigating spam, deceptive practices, and scams within its community. It emphasizes the collective responsibility of users to uphold the platform's safety by adhering to Community Guidelines, particularly those concerning misinformation. The document outlines specific user interventions, such as reporting violations and refraining from posting content that misleads or redirects users away from YouTube. The policy's objective is to preserve the integrity and security of the platform by preventing exploitative practices.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by the direct instructions and prohibitions regarding user content and behaviour. The document employs a prescriptive approach, underscoring the platform's regulatory authority while also invoking a sense of communal duty among users to maintain safety standards.

3. **Types of Harm Addressed**: The policy explicitly addresses reputational harm, economic harm, and privacy harm. Reputational harm is implied through the prohibition of deceptive practices that could mislead users, while economic harm is addressed by preventing scams that exploit users financially. Privacy harm is considered in the context of deceptive practices that may lead users to unsafe external sites.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and are capable of understanding and adhering to the Community Guidelines. It presupposes a level of user responsibility in identifying and reporting harmful content, suggesting an expectation of proactive engagement in safeguarding the platform. Additionally, there is an implicit assumption of user vulnerability to deceptive practices, necessitating clear guidelines and reporting mechanisms."
13_spam_server_report_account,LinkedIn,LinkedIn_Transparency_Community_Report.txt,"1. **Summary**: The policy document primarily aims to enhance platform integrity by addressing and mitigating the proliferation of fake accounts, spam, and scams, as well as handling content violations and copyright infringement claims. It outlines the regulatory scope encompassing automated and manual interventions to preemptively identify and remove fraudulent accounts, thereby maintaining a trusted and professional community environment. The document emphasizes transparency in its operations, detailing the effectiveness of its automated systems and manual reviews in preventing unauthorized activities. Furthermore, it provides a structured report on compliance with government requests and community standards over a specified six-month period.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the document's emphasis on proactive measures and the use of statistical data to assert the effectiveness of its automated systems in blocking fake accounts, thereby projecting a sense of control and vigilance over platform safety.

3. **Types of Harm Addressed**: The policy explicitly addresses reputational and economic harm. Reputational harm is implied through the focus on maintaining a trusted community by eliminating fake accounts, while economic harm is suggested through the emphasis on preventing scams and fraudulent activities that could financially impact users.

4. **User Assumptions**: The policy assumes that users are generally vulnerable to deception through fake accounts and scams, necessitating robust platform interventions. It also presupposes that users have a responsibility to report suspicious activities, although the platform primarily relies on its automated systems to detect and prevent harm before user intervention is required. This reflects an assumption of limited user capacity for self-regulation in identifying complex fraudulent behaviors."
14_account_ban_appeal_error,Snapchat,Snapchat_error_logging_in.txt,"1. **Summary**: The policy document from Snapchat outlines procedures for addressing login issues and account access errors, focusing on user interventions to resolve these problems. It primarily aims to safeguard the platform by temporarily disabling access in response to suspicious activities or violations of community guidelines. The regulatory scope is preventative, emphasizing the protection of the community through measures like device bans for repeated violations. Users are guided on corrective actions, such as waiting periods and network changes, to regain access.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the emphasis on safety measures and community protection, as well as the clear directives provided to users for resolving access issues, which underscores the platform's control over account security and user compliance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm by mitigating potential stress from account access issues and implicitly references reputational harm by maintaining community standards through enforcement actions. It also touches on privacy concerns by preventing unauthorized access through device bans.

4. **User Assumptions**: The document assumes users may engage in risky behaviours, such as repeated login attempts or creating multiple accounts, which could indicate a lack of self-regulation. It presumes users have the capacity to follow technical instructions to resolve issues and expects them to adhere to community guidelines, highlighting a responsibility to maintain account security and integrity."
14_account_ban_appeal_error,Telegram,Telegram_Creating_your_Telegram_Application.txt,"**Summary**: The policy document delineates the regulatory framework governing the use of third-party client applications interfacing with the platform's API, emphasizing a stringent prohibition on unauthorized access. The primary objective is to safeguard the platform's integrity by instituting permanent bans on accounts that violate these terms, thereby ensuring compliance and security. The scope of the policy extends to monitoring all accounts associated with specific API identifiers, highlighting a proactive approach to preventing unauthorized data access. User interventions are implicitly directed towards adherence to the platform's API terms and the responsible management of API credentials.

**Tone**: The document adopts a predominantly authoritative and punitive tone, as evidenced by the use of definitive language such as ""banned forever"" and ""under observation,"" which underscores a zero-tolerance policy towards violations. This tone reflects a firm regulatory stance aimed at deterring non-compliance and reinforcing the platform's governance protocols.

**Types of Harm Addressed**: The policy primarily addresses privacy and economic harms. Privacy harm is inferred from the emphasis on unauthorized access prevention, while economic harm is suggested by the potential misuse of API access that could lead to financial exploitation or loss.

**User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are responsible for understanding and adhering to the API terms of service. It presupposes a level of technical competence in managing API credentials and implies a potential vulnerability to punitive measures should they fail to comply with the outlined regulations."
14_account_ban_appeal_error,EA Sports FC 24,EA_locks_bans_and_suspensions.txt,"1. **Summary**: The document outlines the procedures and rationale behind account locks, bans, and suspensions within the EA platform, emphasizing adherence to the Positive Play Charter and User Agreement. It aims to inform users about the appeal process for perceived errors in enforcement actions, thereby enhancing transparency and user trust. The regulatory scope includes the prevention of misuse of in-game support features and the protection of user accounts from unauthorized access. The policy seeks to balance user accountability with platform integrity, ensuring that interventions are both corrective and preventative.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates the rules and consequences associated with non-compliance, while also providing structured guidance on how users can rectify or appeal enforcement actions. This tone is evident in the direct language used to describe the conditions under which locks, bans, and suspensions are applied, as well as the emphasis on adherence to established agreements and charters.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm, through the potential stress and confusion caused by account restrictions, and privacy harm, by focusing on unauthorized access prevention. Additionally, reputational harm is implicitly considered, as bans and suspensions can affect a user's standing within the gaming community.

4. **User Assumptions**: The policy assumes that users have a basic understanding of the platform's rules and the capacity to adhere to them, as evidenced by the expectation that users review the EA Rules of Conduct before contacting support. It also presumes a level of user vulnerability to unauthorized access, necessitating protective measures like account locks. Furthermore, there is an implicit expectation of user responsibility in not misusing support systems or filing false reports."
14_account_ban_appeal_error,Telegram,Telegram_Terms_of_Service.txt,"**Summary**: The policy document primarily aims to delineate the procedures and criteria for appealing account bans within the platform, emphasizing the enhancement of user experience through improved functionality and exclusive features for verified service accounts. It operates within a regulatory framework that seeks to balance user autonomy with platform governance, ensuring that account restrictions are applied and reviewed fairly. The document is designed to guide users through the appeal process, thereby mitigating potential misunderstandings and fostering trust in the platform's governance mechanisms. The intended interventions focus on providing a structured pathway for users to contest bans, thereby promoting transparency and accountability in enforcement actions.

**Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes clear guidelines and procedures for users to follow when appealing account bans. This tone is justified by the document's emphasis on structured processes and the platform's role in maintaining order and fairness, which underscores its regulatory authority.

**Types of Harm Addressed**: The policy implicitly addresses reputational and economic harm, as account bans can impact a user's online reputation and their ability to engage in economic activities through the platform. Additionally, privacy concerns are indirectly addressed through the emphasis on verified service accounts, suggesting a focus on safeguarding user data and identities.

**User Assumptions**: The document assumes that users possess a basic understanding of the platform's operational procedures and have the capacity for self-regulation in adhering to community standards. It also presupposes that users are motivated to maintain their accounts in good standing and are capable of engaging with the appeals process to rectify any perceived injustices."
14_account_ban_appeal_error,Reddit,Reddit_account_ban.txt,"1. **Summary**: The policy document delineates Reddit's regulatory framework for managing user accounts banned due to spam, inauthentic activity, or ban evasion, emphasizing the enforcement of sitewide rules to maintain community safety and integrity. It outlines the consequences of such bans, including restrictions on user interactions and content moderation capabilities, thereby underscoring the platform's commitment to a secure and authentic user environment. The document provides a mechanism for users to appeal bans they believe to be erroneous, reflecting a procedural safeguard within the governance structure. The overarching objective is to balance user engagement with the platform's need to uphold community standards and mitigate harmful behaviors.

2. **Tone**: The tone of the policy is authoritative, as it clearly delineates the rules and consequences associated with account bans, and prescriptive, as it provides explicit instructions and limitations on user actions during a ban. This is evidenced by the direct language used to describe the enforcement mechanisms and the structured guidance on appealing a ban.

3. **Types of Harm Addressed**: The policy primarily addresses reputational harm, as it involves the public visibility of a permanent ban on user profiles, and psychological harm, given the potential distress caused by restricted access and participation in the platform's community life.

4. **User Assumptions**: The document assumes users have the capacity for self-regulation and awareness of community rules, as it presupposes that users understand the implications of their actions leading to bans. It also implies a level of user responsibility in maintaining the integrity of the platform, while acknowledging the possibility of errors in the enforcement process, thus providing an appeal mechanism for users to contest perceived mistakes."
14_account_ban_appeal_error,Pinterest,Pinterest_Account_suspension.txt,"1. **Summary**: The policy document delineates Pinterest's regulatory framework for account suspension, primarily aimed at maintaining community safety and integrity by enforcing adherence to Community Guidelines. It outlines the procedural mechanisms for detecting violations, which include both automated and human reviews, and specifies the types of infractions that may lead to account suspension, such as violations related to user safety, account security, spam, and intellectual property. The document also provides a recourse mechanism for users to appeal suspensions they believe to be unjustified, thereby facilitating user engagement in the governance process. Overall, the policy seeks to balance enforcement with user support by offering clear guidelines and an appeals process.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear articulation of rules and consequences for non-compliance, alongside a structured appeals process. The language used is directive and formal, emphasizing the platform's commitment to upholding community standards and ensuring user safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., hateful speech), reputational harm (e.g., impersonation), identity-based harm (e.g., pornography), and privacy harm (e.g., third-party logins).

4. **User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviours, either intentionally or inadvertently, necessitating a robust framework for monitoring and enforcement. It presumes a level of user responsibility in understanding and adhering to community guidelines, while also acknowledging users' capacity to contest decisions through an appeals process, indicating an expectation of user engagement and self-advocacy."
14_account_ban_appeal_error,Minecraft,Minecraft_banned_accounts.txt,"1. **Summary**: The policy document delineates the regulatory framework governing account bans within the Minecraft platform, emphasizing the enforcement of community standards to maintain a safe gaming environment. It outlines specific violations that may result in temporary or permanent bans, such as hate speech, sexual content, and real-life threats, thereby aiming to mitigate various forms of digital harm. The document further describes the implications of a ban, including restrictions on gameplay and the necessity for users to manage their subscriptions appropriately. The appeal process is designed to provide transparency and clarity regarding the actions taken against users, underscoring the platform's commitment to a safe and inclusive community.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the clear delineation of rules and consequences for violations, alongside a structured appeal process. The language used is directive and prescriptive, reflecting the platform's commitment to enforcing community standards and ensuring user compliance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (through hate speech), sexual harm (via sexual content and soliciting improper contact), reputational harm (impersonating staff), identity-based harm (exposing personal information), and privacy harm (posting links to malicious software).

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and an understanding of community standards, as it outlines specific behaviors that are prohibited. It also presumes a level of user responsibility in managing their subscriptions and engaging with the appeal process if necessary. Additionally, there is an implicit assumption of user vulnerability to various forms of harm, necessitating protective measures."
14_account_ban_appeal_error,Hinge,Hinge_why_was_my_account_banned.txt,"1. **Summary**: The policy document from Hinge outlines the regulatory framework for account bans, emphasizing the enforcement of the platform's Terms of Service. It delineates the process by which bans are determined, involving both automated systems and human moderation, while maintaining the confidentiality of the factors leading to a ban. The policy underscores the platform's commitment to community safety and integrity, justifying the non-disclosure of specific ban reasons to protect the anonymity of reporting users. The document further clarifies that banned users are not permitted to create new accounts and that subscription fees are non-refundable.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the firm language used to communicate the seriousness with which the platform enforces its rules, the non-negotiable nature of bans, and the lack of recourse for users seeking further information about their ban.

3. **Types of Harm Addressed**: The policy primarily addresses reputational and privacy harms. Reputational harm is implied through the mention of user reports and content moderation, while privacy harm is addressed by the platform's commitment to protecting the anonymity of users who report violations.

4. **User Assumptions**: The policy assumes that users may engage in behaviors that violate community standards, necessitating strict enforcement measures. It also presumes a level of user frustration due to the lack of transparency in ban reasons but prioritizes community safety over individual user grievances. Additionally, there is an implicit assumption of users' inability to self-regulate, as evidenced by the need for both automated and human moderation to enforce compliance."
14_account_ban_appeal_error,Facebook,Facebook_account_suspension.txt,"1. **Summary**: The policy document delineates the procedural framework for account suspension and appeal on Facebook, emphasizing compliance with Community Standards as a regulatory objective. It outlines the conditions under which an account may be suspended or disabled, providing a 180-day window for users to appeal such decisions. The document aims to mitigate harm by enforcing standards against misleading identity representation and content violations. It also specifies the permanent nature of account disabling if appeals are not made or are unsuccessful, thereby reinforcing adherence to platform rules.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the clear and firm language used to describe the conditions under which accounts may be suspended or disabled, the structured appeal process, and the finality of decisions if appeals are not made or are unsuccessful. The document conveys a sense of institutional control and non-negotiable adherence to established standards.

3. **Types of Harm Addressed**: The policy explicitly addresses reputational harm and identity-based harm. It highlights the risks associated with misrepresenting one's identity to deceive others and the potential for content violations to impact users' reputations.

4. **User Assumptions**: The policy assumes that users may engage in behaviours that violate Community Standards, either intentionally or unintentionally, and that they possess the capacity to understand and adhere to these standards. It presumes a level of user responsibility in maintaining compliance and the ability to engage with the appeals process within the specified timeframe. Additionally, there is an implicit assumption of user vulnerability to reputational damage through identity misrepresentation."
14_account_ban_appeal_error,Google Messages,Google_Messages_your_account_is_disabled.txt,"1. **Summary**: The policy document outlines the procedures and conditions under which a Google Account may be disabled and the subsequent appeal process available to users. It delineates the regulatory scope by detailing the limitations on account access and the steps required for users to request account restoration. The document aims to inform users of their rights and responsibilities in the event of account disablement, including specific provisions for EU citizens. The policy is designed to manage digital harm by providing a structured appeal process, albeit with limitations on the number of appeals permitted for certain violations.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative. This is evidenced by the clear, directive language used to outline the consequences of account disablement and the structured, procedural nature of the appeal process. The document emphasizes compliance and adherence to Google's regulatory framework, reflecting a top-down communication style.

3. **Types of Harm Addressed**: The policy substantively addresses economic harm, as the disablement of an account can impede access to services that may be critical for users' professional or financial activities. Additionally, it touches upon reputational harm, given the potential implications of account disablement on a user's digital identity and interactions.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation and are responsible for adhering to Google's policies to maintain account access. It presupposes a level of digital literacy, as users are expected to navigate the appeal process independently. Furthermore, there is an implicit assumption of user vulnerability, particularly for those in the EU, who are afforded additional resolution options, acknowledging potential disparities in users' ability to resolve account issues."
15_strike_restriction_policy_violation,Meta,Meta_content_violating_community_standards.txt,"1. **Summary**: The document delineates a policy framework aimed at preemptively identifying and mitigating content that is likely to contravene established Community Standards, thereby reducing potential harm to users. It operates within a regulatory scope that includes monitoring and assessing content related to hate speech, violence, self-harm, harassment, and other forms of harmful or illicit activity. The policy seeks to intervene by predicting and removing unconfirmed but potentially harmful content before it can cause damage. This proactive approach underscores the platform's commitment to maintaining a safe digital environment by minimizing users' exposure to harmful content.

2. **Tone**: The dominant rhetorical tone of the policy is preventative. This is evidenced by the emphasis on preemptive measures to reduce exposure to potentially harmful content, suggesting a forward-looking strategy designed to protect users before violations are confirmed.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., bullying and harassment, suicide, and self-injury), reputational harm (e.g., fake accounts, scam), sexual harm (e.g., adult nudity and sexual activity), and identity-based harm (e.g., hate speech).

4. **User Assumptions**: The policy assumes that users may be exposed to harmful content and thus require protection through proactive content moderation. It implies a user base that may be vulnerable to various forms of digital harm, necessitating a regulatory framework that anticipates and mitigates these risks. Additionally, there is an implicit expectation that users may not always self-regulate effectively, justifying the platform's interventionist stance."
15_strike_restriction_policy_violation,Quora,Quora_Acceptable_Use_Policy.txt,"1. **Summary**: The Quora Acceptable Use Policy delineates the regulatory framework aimed at ensuring a secure and constructive environment for knowledge sharing. It explicitly prohibits malicious or illegal activities, including the dissemination of malware and engagement in unlawful acts, and outlines enforcement mechanisms such as content removal and user access restrictions. The policy empowers users to report violations through designated channels, thereby fostering a collaborative approach to platform governance. Quora retains unilateral authority to interpret and enforce these guidelines, with provisions for policy updates to adapt to evolving digital safety needs.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear delineation of prohibited activities and the assertion of Quora's exclusive right to interpret and enforce the guidelines. This tone is reinforced by the definitive language used to describe enforcement actions and the platform's control over policy updates.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and privacy harms. Psychological harm is implicated through the emphasis on maintaining a safe environment free from malicious activities, while privacy harm is addressed through the prohibition of activities that interfere with platform security and authentication measures.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and responsibility, as it encourages them to report violations proactively. It also suggests an inherent risk of malicious behavior among users, necessitating stringent enforcement measures and the potential for punitive actions to maintain platform integrity."
15_strike_restriction_policy_violation,Google Messages,Google_Messages_policies.txt,"1. **Summary**: The policy document delineates a comprehensive framework aimed at regulating user interactions and content across various digital products, with the primary objective of ensuring a safe and positive user experience. It establishes clear guidelines for content creation, sharing, and monetization, alongside stipulations for data privacy and security, particularly concerning developers' interactions with user data. The document is structured to support content moderation and enforcement, thereby maintaining high standards of quality and reliability for all stakeholders, including advertisers and content creators. By setting these policies, the platform seeks to foster a secure and innovative digital ecosystem.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by the use of definitive language such as ""clear policies,"" ""rules of the road,"" and ""requirements."" This tone underscores the platform's commitment to enforcing strict guidelines and maintaining control over user interactions and content to ensure safety and reliability.

3. **Types of Harm Addressed**: The policy explicitly addresses privacy and reputational harm, as it outlines privacy and security requirements for handling user data and sets standards for acceptable content, thereby protecting users' personal information and public image.

4. **User Assumptions**: The document assumes that users may engage in behaviors that require regulation, such as content creation and data sharing, and that they possess varying capacities for self-regulation. It also presumes a level of responsibility among users to adhere to the established guidelines to maintain a safe and positive platform environment."
15_strike_restriction_policy_violation,Tinder,Tinder_Enforcing_our_policies.txt,"1. **Summary**: The policy document delineates Tinder's regulatory framework aimed at maintaining a secure and authentic user environment through the enforcement of Community Guidelines. It outlines a tiered response system to policy violations, ranging from warnings and content removal to user bans, and emphasizes collaboration with authorities in cases of immediate danger or child exploitation. The document underscores a commitment to proportionality in enforcement actions and highlights ongoing efforts to educate users about acceptable conduct. The overarching objective is to balance punitive measures with preventative education to foster a safer community.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear delineation of enforcement actions and the structured hierarchy of responses to violations. This authoritative stance is further reinforced by the policy's emphasis on collaboration with legal authorities and its commitment to user education, indicating a comprehensive approach to governance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on maintaining a positive community environment, reputational harm via content removal and user bans, and identity-based harm through verification processes. It also addresses sexual harm, particularly in the context of child abuse material, and privacy concerns through its enforcement mechanisms.

4. **User Assumptions**: The policy assumes that users may inadvertently or deliberately engage in harmful behaviors, necessitating a structured response system. It presupposes a degree of user vulnerability to both external threats and self-regulation challenges, highlighting the need for educational interventions. Additionally, the policy assumes users have a responsibility to adhere to community standards and that they possess the capacity to understand and comply with these guidelines upon receiving appropriate guidance."
15_strike_restriction_policy_violation,Meta,Meta_counting_strikes.txt,"1. **Summary**: The document delineates the enforcement mechanisms of Meta's strike policy, which is designed to regulate user behavior on Facebook and Instagram by applying strikes for content that contravenes community standards. The policy aims to balance fairness and proportionality by considering the severity, context, and timing of violations, with a specific focus on severe infractions such as child sexual exploitation, which may result in immediate account disablement. Strikes are not applied to content older than ninety days for most violations or four years for severe ones, and certain exceptions are made for specific policy breaches. The policy also stipulates that strikes expire after one year, ensuring a temporal limitation on punitive measures.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, underscored by its definitive language regarding enforcement actions and the structured application of strikes. This authoritative stance is evident in the clear delineation of rules and consequences, as well as the emphasis on the platform's discretion in determining the severity and context of violations.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and sexual harm, particularly through its focus on severe violations like child sexual exploitation, which are deemed significant enough to warrant immediate account disablement.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are aware of community standards, as it holds them accountable for content violations. It also presumes a degree of user vulnerability, particularly in cases of financial information sharing, where the platform intervenes to prevent fraud. Additionally, the policy implies that users managing groups or pages bear responsibility for content approved within those spaces."
15_strike_restriction_policy_violation,Meta,Meta_restricting_accounts.txt,"1. **Summary**: The policy document delineates Meta's strike-based enforcement mechanism for violations of Facebook Community Standards and Instagram Community Guidelines, aiming to regulate user behavior through a graduated system of restrictions. The regulatory scope is primarily punitive, escalating from warnings to temporary suspensions of content creation privileges, with the severity of restrictions increasing with the number of violations. The policy is designed to deter harmful behaviors by imposing incremental penalties, thereby encouraging compliance with platform standards. The document specifically targets violations related to severe policies, such as those concerning dangerous individuals and adult sexual exploitation, indicating a focus on mitigating significant digital harms.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative and punitive. This is evidenced by the structured escalation of penalties and the clear delineation of consequences for repeated violations, which underscores a firm stance on compliance and enforcement.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm and reputational harm, as it seeks to prevent behaviors that could lead to harassment or defamation. It also implicitly addresses identity-based harm by including policies on dangerous individuals and organizations, as well as sexual harm through its focus on adult sexual exploitation.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are aware of the community standards, as it provides a warning for initial violations. It also presumes a degree of user responsibility in adhering to platform guidelines, with the expectation that the threat of escalating penalties will deter non-compliant behavior. Additionally, the policy implies a vulnerability among users to certain types of harmful content, justifying the need for strict enforcement measures."
15_strike_restriction_policy_violation,LinkedIn,LinkedIn_enforcement.txt,"1. **Summary**: The policy document delineates the enforcement mechanisms for violations of the platform's User Agreement and Professional Community Policies, emphasizing a graduated response to infractions. It aims to regulate user behavior by implementing visibility restrictions, content labeling, or removal, with an appeals process available for contested actions. The document outlines a strike-based system where repeated violations lead to account restrictions, potentially culminating in permanent bans for severe infractions such as child sexual abuse material or terrorism-related content. Exceptions are made for content shared to raise awareness or condemn harmful actions, which may be labeled but not removed.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear delineation of consequences for policy violations and the structured, rule-based approach to enforcement. The language is formal and prescriptive, underscoring the platform's commitment to maintaining a professional and safe community environment.

3. **Types of Harm Addressed**: The policy explicitly addresses several types of harm, including psychological (through the potential distress caused by sensitive content), reputational (via content that could damage professional standing), sexual (particularly egregious sexual harassment), and identity-based harms (such as content related to terrorism).

4. **User Assumptions**: The policy assumes users have the capacity for self-regulation and are responsible for adhering to community standards, as indicated by the opportunity to appeal and the potential for account reinstatement upon agreement to comply. It also presupposes a level of vulnerability among users to certain types of content, justifying the labeling and obscuring of sensitive material."
15_strike_restriction_policy_violation,Meta,Meta_violating_content.txt,"1. **Summary**: The policy document outlines Meta's regulatory framework for enforcing content standards on Facebook and Instagram, primarily through a strike-based system to manage user violations. Its objectives include the removal of content that contravenes community guidelines and the imposition of account restrictions or disabling based on the severity and frequency of violations. The policy aims to educate users by providing notifications and explanations for content removal, thereby promoting compliance and reducing future infractions. Additionally, it offers a mechanism for users to contest removals, acknowledging potential errors in enforcement.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it emphasizes compliance with established community standards and the consequences of non-compliance. This is evidenced by the structured enforcement measures and the clear communication of potential penalties, underscoring the platform's commitment to maintaining a regulated digital environment.

3. **Types of Harm Addressed**: The policy primarily addresses reputational harm by managing content that could damage the platform's integrity or users' perceptions. It also implicitly touches on psychological harm by aiming to prevent exposure to harmful content.

4. **User Assumptions**: The policy assumes users have the capacity for self-regulation and the responsibility to adhere to community standards. It presumes a level of user engagement with the platform's guidelines and an understanding of the consequences of violations. Additionally, it suggests users are capable of recognizing and rectifying their content-related infractions through the feedback and appeal processes provided."
15_strike_restriction_policy_violation,LinkedIn,LinkedIn_how_we_enforce_our_professional_community_policies.txt,"1. **Summary**: The document delineates the enforcement mechanisms of a platform's Professional Community Policies, emphasizing a tiered response to policy violations. It outlines the regulatory scope by detailing actions such as content visibility limitation, labeling, removal, and account restrictions, with provisions for user appeals. The policy aims to deter harmful behaviors by escalating consequences for repeated infractions, culminating in permanent account restrictions for severe breaches. It also allows for exceptions where content serves educational or condemnatory purposes, ensuring nuanced application of the rules.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates the consequences of non-compliance with the platform's rules and emphasizes the platform's control over user content and accounts. This is evidenced by the structured escalation of penalties and the explicit mention of permanent restrictions for severe violations.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., extremely violent content, egregious sexual harassment), reputational harm (through content labeling and visibility restrictions), and sexual harm (e.g., child sexual abuse material).

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for understanding and adhering to the platform's rules. It presumes a level of user awareness and engagement with the appeals process, suggesting an expectation of user accountability and willingness to comply with community standards. Additionally, it implies that users may inadvertently or deliberately engage in harmful behaviors, necessitating a structured enforcement framework."
15_strike_restriction_policy_violation,Meta,Meta_community_standards_update.txt,"1. **Summary**: The document outlines the consolidation of Community Standards across multiple platforms, namely Facebook, Instagram, Messenger, and Threads, into a singular, unified set of guidelines. This regulatory adjustment aims to enhance user accessibility and comprehension of the rules governing platform use, without altering the existing content of the policies. The document emphasizes the importance of transparency and regular reporting on policy enforcement, thereby reinforcing the platform's commitment to user safety and governance. The intended intervention is to simplify the user experience by centralizing policy access, thus facilitating better adherence and understanding.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This classification is justified by the document's focus on streamlining access to information, which is framed as a measure to prevent misunderstandings and enhance user compliance. The language used conveys a commitment to user assistance and clarity, aiming to preemptively address potential user confusion.

3. **Types of Harm Addressed**: The policy implicitly addresses psychological and reputational harm by emphasizing the importance of clear and accessible guidelines, which help prevent misuse and misunderstandings that could lead to such harms. Additionally, privacy concerns are indirectly addressed through the mention of authentic identity requirements on Facebook, suggesting an awareness of identity-based and privacy-related issues.

4. **User Assumptions**: The document assumes that users have a basic capacity for self-regulation and a willingness to comply with platform rules, provided they are easily accessible and understandable. It also presupposes a level of user vulnerability to confusion or oversight, which the policy aims to mitigate by consolidating guidelines. Furthermore, there is an implicit expectation of user responsibility in familiarizing themselves with these unified standards to ensure compliance."
16_appeal_pin_deactivate_request,Snapchat,Snapchat_Transparency_Report_2023.txt,"**Summary**: The document serves as a transparency report from Snap, detailing its safety and content moderation efforts from July to December 2023. It aims to provide stakeholders with comprehensive data on content and account-level reports, law enforcement interactions, and enforcement actions by country. The report introduces expanded categories, specifically addressing issues related to Terrorism & Violent Extremism and Child Sexual Exploitation & Abuse (CSEA). This initiative reflects Snap's commitment to enhancing the safety and well-being of its community through detailed and transparent reporting.

**Tone**: The rhetorical tone of the policy is predominantly authoritative, as it systematically presents data and procedural updates in a factual and structured manner. This is evidenced by the emphasis on comprehensive reporting and the introduction of new elements to enhance transparency, suggesting a commitment to accountability and governance.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm, sexual harm, and identity-based harm. These are inferred from the focus on Terrorism & Violent Extremism and Child Sexual Exploitation & Abuse (CSEA), which encompass threats to mental health, sexual safety, and identity security.

**User Assumptions**: The document assumes users are potentially vulnerable to various forms of digital harm, necessitating robust content moderation and enforcement actions. It presupposes a need for user protection against severe threats such as terrorism and exploitation, while also implying an expectation of user responsibility in reporting harmful content."
16_appeal_pin_deactivate_request,Meta,Meta_community_standards_enforcement_report.txt,"1. **Summary**: The document outlines the regulatory framework of Facebook and Instagram's Community Standards, emphasizing the platforms' commitment to fostering safe and inclusive environments for user expression. It details the objectives of the Community Standards Enforcement Report, which is published quarterly to track and communicate progress in policy enforcement. The report highlights the shared content policies between Facebook and Instagram and notes the ongoing evolution of enforcement methodologies and metrics. This approach underscores the platforms' dedication to transparency and accountability in safeguarding user safety, privacy, dignity, and authenticity.

2. **Tone**: The rhetorical tone of the policy document is predominantly authoritative and preventative. This is evidenced by the structured presentation of enforcement metrics and the emphasis on continuous improvement and transparency in policy application, which collectively aim to preemptively address and mitigate potential harms.

3. **Types of Harm Addressed**: The policy document substantively addresses psychological, reputational, and privacy harms. These are inferred from the focus on user safety, dignity, and authenticity, as well as the explicit mention of privacy protection within the community standards framework.

4. **User Assumptions**: The document assumes that users are inherently vulnerable to various forms of harm, necessitating protective measures to ensure their safety and dignity. It also implies a responsibility on the part of users to adhere to community standards, suggesting an expectation of user capacity for self-regulation and compliance with established guidelines."
16_appeal_pin_deactivate_request,Reddit,Reddit_quarantined_communities.txt,"1. **Summary**: The policy document delineates Reddit's regulatory framework for managing ""quarantined communities,"" which are spaces that, while not explicitly prohibited, may contain content deemed offensive or misleading to the general user base. The primary objective is to shield users from inadvertently encountering such content by implementing access restrictions that require explicit user consent to view. The document outlines the operational constraints placed on quarantined communities, such as exclusion from revenue generation and visibility in non-subscriber feeds, thereby minimizing their reach and influence. Additionally, it specifies the procedural aspects of notifying community moderators and the potential for appealing quarantine status.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by the clear delineation of rules and enforcement measures. The document employs definitive language to assert Reddit's regulatory prerogatives, such as the use of ""may apply a quarantine"" and ""are still fully obliged,"" indicating a top-down approach to governance and compliance.

3. **Types of Harm Addressed**: The policy addresses psychological harm by aiming to prevent exposure to offensive or upsetting content. It also implicitly considers reputational harm by restricting the visibility of communities that promote hoaxes, thereby safeguarding the platform's credibility.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation, as it requires them to opt-in explicitly to view quarantined content. It also presupposes a degree of vulnerability among average users, who may inadvertently encounter harmful content without such protective measures. Furthermore, there is an implicit expectation of responsibility on the part of community moderators to manage their spaces in accordance with Reddit's content policies."
16_appeal_pin_deactivate_request,Pinterest,Pinterest_transparency_report_2023.txt,"1. **Summary**: The policy document from Pinterest outlines the platform's commitment to fostering an inspiring and safe online environment through the implementation and enforcement of content policies. It emphasizes the use of evolving moderation practices, including machine learning and collaboration with external experts, to address harmful content. The document highlights the publication of a biannual transparency report, which details the platform's efforts in content moderation, including data on deactivations and compliance with law enforcement requests. This report aims to enhance user trust by providing insights into Pinterest's regulatory actions and adherence to community guidelines.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the emphasis on proactive measures such as evolving moderation practices and the use of advanced technologies to combat policy violations, alongside the authoritative disclosure of compliance and enforcement actions through transparency reports.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm by focusing on creating a positive and inspiring environment and preventing the dissemination of harmful content. It also implicitly addresses privacy concerns through its mention of handling deactivation requests from law enforcement and government entities.

4. **User Assumptions**: The document assumes that users may encounter or engage in behaviours that require moderation, indicating a potential risk of exposure to harmful content. It presumes users have a limited capacity for self-regulation, necessitating the platform's intervention through technological and policy measures. Additionally, it suggests users expect transparency and accountability from the platform regarding content moderation practices."
16_appeal_pin_deactivate_request,Google Messages,Google_Messages_about_community_guidelines.txt,"1. **Summary**: The document delineates a set of community guidelines aimed at fostering a responsible, thoughtful, and respectful communication environment within the organization. It emphasizes the regulatory scope of maintaining a safe, productive, and inclusive workplace by adhering to core values that prioritize respect for users, opportunities, and colleagues. The policy outlines specific user interventions, such as avoiding disruptive conversations and ensuring discussions do not alienate or marginalize others. It underscores the importance of personal accountability and collective responsibility in upholding these standards.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the prescriptive language used to instruct users on expected behaviors and the emphasis on accountability and adherence to organizational values, which conveys a clear expectation of compliance and responsibility.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. It explicitly warns against actions that could lead to feelings of exclusion or misrepresentation, thereby protecting individuals' mental well-being and reputational integrity within the workplace.

4. **User Assumptions**: The policy assumes users possess the capacity for self-regulation and are capable of understanding the impact of their words and actions. It presupposes a level of vulnerability to psychological and reputational harm among users, necessitating a framework that guides behavior to prevent such outcomes. Additionally, it assumes users have a responsibility to contribute positively to the workplace environment and to avoid engaging in disruptive or harmful discussions."
16_appeal_pin_deactivate_request,YouTube,YouTube_creator_responsibility.txt,"1. **Summary**: The policy document delineates the regulatory framework governing YouTube creators, emphasizing adherence to Community Guidelines and Terms of Service to maintain platform integrity and safety. It outlines the dual objectives of ensuring community health and facilitating monetization, contingent upon compliance with additional guidelines such as AdSense Program Policies and Advertiser-friendly content guidelines. The document underscores the potential consequences of non-compliance, including content removal, channel strikes, and monetization penalties, thereby incentivizing creators to uphold community standards. It further articulates a collective responsibility model, urging creators to contribute positively to the platform's ecosystem both on and off YouTube.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by its clear delineation of rules and consequences for non-compliance. This is reinforced by the documentâ€™s emphasis on adherence to guidelines and the structured enumeration of potential penalties, which collectively underscore the platform's regulatory authority and the creators' obligations.

3. **Types of Harm Addressed**: The policy primarily addresses reputational and economic harm. Reputational harm is implied through the emphasis on community health and the potential for content removal or channel termination, while economic harm is directly addressed through the discussion of monetization penalties and the disabling of ads for non-compliance.

4. **User Assumptions**: The document assumes that users, specifically creators, possess a significant degree of influence and responsibility within the platform's ecosystem. It presupposes creators' capacity for self-regulation and their ability to understand and adhere to complex guidelines. Additionally, it implies a vulnerability to economic repercussions should they fail to comply with the outlined policies, highlighting an expectation of proactive engagement with the platform's regulatory framework."
16_appeal_pin_deactivate_request,Bumble,Bumble_politics_filter.txt,"1. **Summary**: The policy document articulates the platform's regulatory response to the misuse of its politics filter in the aftermath of the U.S. Capitol attack, emphasizing the temporary removal and subsequent reinstatement of this feature to enhance moderation capabilities. It delineates the platform's prohibition of content that incites violence, terrorism, or spreads misinformation, particularly in relation to the U.S. Election results. The document underscores the platform's commitment to user safety by encouraging community reporting of guideline violations and collaborating with law enforcement as necessary. The policy also highlights an intensified monitoring focus on the DC area, utilizing AI technology to detect and remove harmful content.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative and preventative. This classification is justified by the decisive language used to describe the platform's actions, such as ""temporarily remove,"" ""prohibits,"" and ""banned,"" which convey a firm stance on enforcing rules and preventing harm. Additionally, the emphasis on collaboration with law enforcement and the use of AI for monitoring further underscores a proactive approach to governance and safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, and identity-based harm. Psychological harm is implied through the potential distress caused by insurrectionist content and misinformation. Reputational harm is addressed through the prohibition of content that could damage individuals' or groups' standing. Identity-based harm is reflected in the prohibition of content promoting racism.

4. **User Assumptions**: The document assumes that users have the capacity to recognize and report harmful content, indicating an expectation of user responsibility in maintaining platform safety. It also suggests a vulnerability among users to misinformation and harmful content, necessitating enhanced monitoring and moderation efforts. Additionally, there is an implicit assumption that users may engage in risky behaviors, such as spreading insurrectionist content, which requires regulatory intervention."
16_appeal_pin_deactivate_request,Reddit,Reddit_transparency_report_2024.txt,"**Summary**: The document serves as a biannual transparency report from Reddit, detailing the platform's regulatory efforts to maintain a safe and healthy digital environment. It outlines the scope of content moderation activities, including the removal of content through automated tools and the response to legal and governmental requests. The report aims to provide insights into the volume of content posted, the percentage of content removed, and the reasons for such removals, emphasizing the platform's commitment to fostering safe interactions. The document also highlights the significant role of moderators and administrators in enforcing community standards and addressing violations.

**Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the structured presentation of data and metrics, the emphasis on compliance with legal requests, and the clear delineation of moderation activities, which collectively underscore the platform's commitment to governance and accountability.

**Types of Harm Addressed**: The policy primarily addresses reputational and privacy harms. This is indicated by the focus on content policy violations and the handling of legal requests for content removal or user data disclosure, which are crucial for protecting users' reputations and personal information.

**User Assumptions**: The document assumes that users are active content creators with varying levels of adherence to community standards, necessitating moderation. It also presumes a degree of user vulnerability to reputational and privacy risks, as evidenced by the platform's proactive content removal and compliance with external requests for data disclosure."
16_appeal_pin_deactivate_request,Reddit,Reddit_Content_Moderation.txt,"**Summary**: The document delineates Reddit's multi-tiered content moderation strategy, emphasizing a community-driven model that integrates user participation with platform-wide enforcement mechanisms. It aims to maintain a healthy and inclusive environment by empowering subreddit moderators to establish and enforce community-specific rules, while Reddit administrators ensure compliance with overarching global content policies. The policy underscores the importance of community self-regulation as a scalable solution to online moderation challenges. It also outlines procedural avenues for content appeals, thereby enhancing transparency and accountability in enforcement actions.

**Tone**: The dominant rhetorical tone of the policy is authoritative yet collaborative. This is evidenced by the emphasis on structured governance frameworks that combine top-down enforcement with bottom-up community participation, suggesting a balance between directive oversight and user empowerment.

**Types of Harm Addressed**: The policy primarily addresses psychological, reputational, and privacy harms. These are inferred from the focus on maintaining a ""welcoming, healthy, and real platform"" and the mechanisms in place to remove and report content that violates community norms and global content policies.

**User Assumptions**: The document assumes users possess the capacity for self-regulation and are capable of participating in community governance. It presupposes a level of user responsibility in adhering to both community-specific and global content policies, while also recognizing potential vulnerabilities that necessitate structured moderation and appeal processes."
16_appeal_pin_deactivate_request,X,X_transparency_report.txt,"1. **Summary**: The document outlines X's commitment to maintaining a safe and open platform for public discourse, emphasizing transparency in content moderation and enforcement strategies from January to June 2024. It aims to balance freedom of expression with the responsibility to protect users from harmful content, employing a philosophy of ""Freedom of Speech, not Freedom of Reach."" The policy underscores the use of educational and rehabilitative measures alongside deterrence to address violations. It positions itself within a human rights framework, seeking to prevent violence, harassment, and other behaviors that could stifle user expression.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative yet supportive. This is evidenced by its firm commitment to safeguarding public conversation through structured enforcement while simultaneously promoting user education and rehabilitation, reflecting a balanced approach to governance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on preventing violence and harassment, which can discourage user expression. It also implicitly touches on reputational harm by restricting the reach of harmful posts to protect users' public personas.

4. **User Assumptions**: The document assumes that users are both capable of self-expression and vulnerable to harm from other users' content. It presupposes a need for external regulation to maintain a safe environment, suggesting users may not always self-regulate effectively. Additionally, it implies a user responsibility to adhere to platform rules to ensure a constructive public conversation."
17_trans_shame_body_report,Tinder,Tinder_How_To_Deal.txt,"1. **Summary**: The document delineates Tinder's commitment to fostering a secure environment for its users by encouraging the reporting of inappropriate or criminal behavior. It outlines the regulatory scope by specifying behaviors that warrant reporting, such as harassment, racial slurs, and unsolicited sexual content, thereby aiming to mitigate various forms of digital harm. The policy emphasizes user intervention through a confidential reporting mechanism, underscoring the platform's zero-tolerance stance on harassment. This framework is designed to enhance user safety and uphold community standards by actively involving users in the governance process.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on user empowerment through reporting mechanisms (""If you see something, say something"") and the assurance of confidentiality and support (""Weâ€™re here for you""), which collectively aim to preempt harmful interactions and foster a safe user environment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (harassment, threats), identity-based harm (racial slurs), sexual harm (unsolicited explicit content), reputational harm (derogatory language), and economic harm (solicitation for financial help).

4. **User Assumptions**: The policy assumes users possess the capacity to recognize and report inappropriate behavior, suggesting a level of behavioral awareness and responsibility. It also presumes users are vulnerable to various forms of harm and require a supportive mechanism to address these risks, indicating an understanding of the potential for both proactive and reactive user engagement in maintaining platform safety."
17_trans_shame_body_report,Bumble,Bumble_Microaggressions_and_fetishization.txt,"1. **Summary**: The policy document primarily aims to provide a framework for users to report safety concerns and incidents, particularly focusing on microaggressions and fetishization experienced by trans individuals. It outlines the procedures for reporting abusive behavior and offers guidance on personal interventions, emphasizing user autonomy in addressing harmful interactions. The regulatory scope is designed to mitigate identity-based harm by facilitating user empowerment through reporting mechanisms and support resources. The document seeks to balance platform responsibility with user agency, ensuring that users have multiple avenues for addressing grievances.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive. This is evidenced by the language that validates users' feelings and experiences, such as acknowledging the discomfort caused by microaggressions and fetishization, and offering reassurance that there is no singular correct way to handle such situations. The policy emphasizes user empowerment and provides options for both self-regulation and platform intervention.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, particularly focusing on the psychological impact of microaggressions and fetishization. It also implicitly touches on reputational harm by providing mechanisms to report and block abusive users, thereby protecting users' dignity and social standing within the platform.

4. **User Assumptions**: The document assumes that users possess varying capacities for self-regulation and may choose different methods to handle harmful interactions, reflecting an understanding of diverse user vulnerabilities and preferences. It presumes users have the agency to decide whether to engage directly with offenders or seek platform intervention, highlighting an expectation of user responsibility in managing their safety while acknowledging the platform's role in providing support."
17_trans_shame_body_report,Bumble,Bumble_What_happens_when_you_report.txt,"1. **Summary**: The policy document from Bumble delineates the platform's procedures and commitments to user safety, particularly focusing on the reporting mechanisms for incidents that compromise user comfort and security. It aims to provide a structured response to user-reported issues such as microaggressions, fetishization, catfishing, and abusive messages, with a dedicated team of human moderators tasked with reviewing and addressing these reports. The regulatory scope emphasizes user empowerment through accessible reporting tools, while maintaining user privacy by limiting the disclosure of report statuses. The document underscores the platform's proactive stance in safeguarding users, particularly those vulnerable to identity-based harms, by ensuring a responsive and supportive reporting process.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the platform's emphasis on user safety and comfort, and the assurance of a human moderation team to address reported concerns. The language used suggests a commitment to user well-being and a collaborative approach to resolving safety issues, reinforcing a sense of trust and reliability in the platform's governance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on user discomfort and safety, identity-based harm particularly concerning trans individuals facing fetishization, and privacy concerns through its handling of report confidentiality.

4. **User Assumptions**: The document assumes that users are capable of identifying and reporting harmful interactions, indicating a level of expected self-regulation and awareness. It also presumes a vulnerability among certain user groups, such as trans individuals, who may be more susceptible to specific types of harm like fetishization. Additionally, there is an implicit expectation that users will engage with the platform's support mechanisms when needed, highlighting a shared responsibility in maintaining a safe digital environment."
17_trans_shame_body_report,Bumble,Bumble_Support_fetishized_trans_woman.txt,"1. **Summary**: The policy document primarily aims to provide a structured framework for reporting and addressing safety concerns, particularly focusing on the experiences of transgender women within the online dating environment. It delineates the regulatory scope by offering tools for users to report instances of fetishization and microaggressions, thereby promoting a safer and more respectful platform. The document emphasizes user interventions such as the Block & Report Tool and support services in partnership with Trans Lifeline, underscoring a commitment to user safety and emotional well-being. The policy is designed to empower users to take action against harmful interactions while fostering an inclusive community.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive. This is evidenced by the language used to reassure users of their safety and the emphasis on emotional support, particularly through statements like ""Your safety comes first on Bumble"" and the partnership with Trans Lifeline, which highlights a commitment to user welfare and empowerment.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, particularly through the lens of fetishization and microaggressions experienced by transgender women. It also implicitly touches on psychological harm by acknowledging the emotional impact of such interactions and providing guidance on emotional recovery.

4. **User Assumptions**: The document assumes that users, particularly transgender women, are vulnerable to identity-based harm and may require external support to navigate these challenges. It presumes a need for self-regulation and proactive reporting of harmful incidents, suggesting users have the capacity to identify and act upon negative interactions. Additionally, there is an expectation that users will engage with the platform's support mechanisms to ensure their safety and well-being."
17_trans_shame_body_report,Badoo,Badoo_body_shaming.txt,"1. **Summary**: The document articulates Badoo's commitment to combating body shaming on its platform, emphasizing the need for a safe and respectful online dating environment. It delineates the regulatory scope by identifying body shaming as a form of digital harm that encompasses derogatory comments related to appearance, size, or health, and highlights the platform's interventions aimed at protecting users from such behavior. The policy underscores the societal pressures of beauty standards and the resultant psychological harm, advocating for user confidence and security. Badoo's approach is to illuminate the issue and implement protective measures to foster a supportive community.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its emphasis on user confidence, safety, and the platform's proactive role in addressing body shaming. The language used is inclusive and empathetic, aiming to foster a sense of community and mutual respect among users.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm, as it focuses on the negative impact of body shaming on individual self-esteem and mental well-being. It also touches upon identity-based harm by recognizing the intersectionality of derogatory comments that can be fat-phobic, ableist, racist, colourist, homophobic, or transphobic.

4. **User Assumptions**: The document assumes that users may be vulnerable to societal beauty standards and the resultant pressures, which can manifest in self-critical behaviors or the shaming of others. It presumes a need for external regulation to mitigate these risks, suggesting that users may lack the capacity for self-regulation in the context of ingrained societal norms. Additionally, it implies a responsibility on the part of users to contribute to a respectful and safe community environment."
17_trans_shame_body_report,Bumble,Bumble_Reporting_after_being_unmatched.txt,"1. **Summary**: The policy document from Bumble primarily aims to establish a framework for users to report safety concerns and incidents, particularly focusing on the experiences of transgender individuals facing microaggressions and fetishization. It outlines procedural guidance for reporting abusive interactions, including those occurring after being unmatched, thereby enhancing user safety and accountability within the platform. The regulatory scope is designed to address both immediate and residual harms by facilitating user reports and ensuring community closure. The document also emphasizes the importance of user engagement in maintaining a safe digital environment through active reporting and awareness.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the language used to provide reassurance and guidance to users, particularly those who may have experienced discomfort or harm, such as offering closure and assistance in reporting incidents.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through the discussion of discomfort and unsafe feelings, identity-based harm concerning the experiences of trans individuals, and reputational harm through the mention of catfishing and fake profiles.

4. **User Assumptions**: The policy assumes that users possess a certain level of vulnerability, particularly those who are transgender, and acknowledges their potential exposure to microaggressions and fetishization. It also presumes users have the capacity for self-regulation and responsibility, as they are encouraged to actively report incidents and engage with the platformâ€™s safety mechanisms to protect themselves and the community."
17_trans_shame_body_report,Tinder,Tinder_the_basics.txt,"1. **Summary**: The policy document from Tinder serves as a comprehensive guide aimed at enhancing user safety both online and in real life (IRL). Its regulatory scope encompasses guidelines for personal information protection, cautious interaction, and immediate reporting of inappropriate behavior, thereby fostering a secure user environment. The document outlines specific interventions, such as advising users to withhold personal information until trust is established and to report any suspicious activities. The overarching objective is to mitigate risks associated with online dating by promoting informed and cautious user behavior.

2. **Tone**: The tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on proactive measures users can take to protect themselves, such as withholding personal information and reporting suspicious behavior, which underscores a commitment to user empowerment and safety.

3. **Types of Harm Addressed**: The policy explicitly addresses several types of harm, including psychological (harassment or threats), reputational (unsolicited requests for nude images), identity-based (members under 18), and privacy (sharing of personal information).

4. **User Assumptions**: The policy assumes users possess a basic capacity for self-regulation and the ability to make informed decisions about their safety. It presupposes a level of vulnerability inherent in online interactions, necessitating guidance on cautious behavior. Additionally, it implies a responsibility on the part of users to actively engage in safeguarding their own and others' safety by reporting inappropriate conduct."
17_trans_shame_body_report,Bumble,Bumble_Reporting_abusive_messages.txt,"1. **Summary**: The policy document from Bumble delineates the platform's commitment to user safety by providing mechanisms for reporting abusive behavior, with a particular focus on identity-based and psychological harms. It aims to empower users to report incidents such as threats, derogatory language, and unsolicited sexual content, thereby fostering a safe and inclusive environment. The regulatory scope is preventative and supportive, ensuring anonymity for reporters to encourage proactive engagement with safety protocols. The document underscores the platform's role in safeguarding user well-being and maintaining community standards through clear reporting channels and responsive support systems.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the language that reassures users of the platform's backing (""we have your back"") and emphasizes the importance of maintaining a safe community environment. The policy encourages user engagement in safety processes by providing anonymity and clear guidance on reporting procedures.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., harassment, belittlement), identity-based harm (e.g., hate speech, sexism, racism), and sexual harm (e.g., unsolicited sexual images). It also implicitly considers privacy harm through the emphasis on anonymous reporting.

4. **User Assumptions**: The document assumes that users are capable of identifying and reporting harmful behaviors, suggesting a level of self-regulation and awareness. It also presumes a vulnerability to various forms of abuse, necessitating robust support and reporting mechanisms. Additionally, there is an implicit expectation that users are responsible for contributing to a safe community by actively engaging with the platform's reporting tools."
17_trans_shame_body_report,Bumble,Bumble_Unmatch_someone.txt,"1. **Summary**: The document delineates Bumble's policy framework for reporting safety concerns, emphasizing user empowerment in managing uncomfortable or unsafe interactions. It outlines procedures for reporting abusive messages, fake profiles, and incidents of microaggressions and fetishization, particularly concerning trans women. The policy aims to create a safer digital environment by facilitating user-driven interventions such as reporting and unmatching. The regulatory scope extends to enhancing user autonomy while providing support mechanisms for those experiencing identity-based harm.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the language encouraging users to report any discomfort and the provision of specific guidance for vulnerable groups, such as trans women, indicating an emphasis on user well-being and empowerment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, identity-based harm, and privacy concerns. These are evidenced through discussions of microaggressions, fetishization, and the need to report abusive messages and fake profiles.

4. **User Assumptions**: The document assumes users have the capacity for self-regulation and are responsible for initiating safety measures by reporting incidents. It also implies a recognition of user vulnerability, particularly for marginalized groups such as trans women, and assumes users seek an active role in maintaining their digital safety."
17_trans_shame_body_report,Grindr,Grindr_trans_support.txt,"1. **Summary**: The policy document primarily aims to provide safety resources and support for transgender individuals facing crisis situations, particularly in the context of transphobia. It outlines a regulatory framework that includes directing users to external support services such as the National Center for Transgender Equality, Trans Lifeline, and other crisis hotlines. The document's objective is to mitigate psychological and identity-based harms by facilitating access to immediate crisis intervention and support networks. This intervention-centric approach underscores the platform's commitment to user safety and well-being, particularly for vulnerable transgender communities.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive. This is evidenced by the document's emphasis on providing resources and assistance, as well as its empathetic language aimed at reassuring users of available help during crises. The use of direct contact information for various support services further reinforces a tone of care and accessibility.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and identity-based harms. It highlights the risks of transphobia and the potential for emotional distress, suicidal crisis, and violence against transgender individuals, thereby focusing on the mental health and safety of this community.

4. **User Assumptions**: The document assumes that transgender users may be particularly vulnerable to identity-based discrimination and psychological distress. It presupposes a need for external support and crisis intervention, suggesting an understanding of users' limited capacity for self-regulation in moments of crisis. Additionally, it implies a responsibility on the part of the platform to facilitate access to appropriate resources and support networks."
18_animal_violence_violent_harm,Bumble,Bumble_violent_content.txt,"1. **Summary**: The policy document delineates the platform's prohibition against violent or graphic content, aiming to regulate and mitigate exposure to potentially harmful imagery. It explicitly outlines the types of content that are not permitted, such as depictions of blood, injuries, and violent acts involving humans or animals, with specific exceptions for certain types of hunting imagery. The regulatory scope is comprehensive, encompassing both user-generated content and profile descriptions, with a focus on preventing psychological and reputational harm. The document also provides a mechanism for users to contest enforcement actions, indicating an avenue for user engagement and feedback.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the clear and direct language used to outline prohibitions and the structured list of unacceptable content. This tone is reinforced by the definitive statements regarding what is not permitted, suggesting a strict adherence to the outlined guidelines.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. The prohibition of graphic and violent content aims to protect users from distressing imagery that could impact mental well-being, while also safeguarding the platform's reputation by maintaining a safe and respectful environment.

4. **User Assumptions**: The policy assumes that users may inadvertently or deliberately post harmful content, necessitating clear guidelines to preempt such actions. It presumes a level of user responsibility in adhering to these guidelines and provides an avenue for users to appeal enforcement decisions, suggesting an expectation of user engagement and a capacity for self-regulation. The document implies a recognition of user vulnerability to graphic content, underscoring the need for protective measures."
18_animal_violence_violent_harm,Meta,Meta_Coordinating_harm_and_promoting_crime _ Transparency Centre.txt,"1. **Summary**: The policy document primarily aims to mitigate the coordination of harm and the promotion of criminal activities on the platform, with a regulatory scope that encompasses the detection and prevention of content that facilitates such behaviors. It outlines specific interventions designed to identify and remove harmful content, thereby safeguarding users from exposure to violence and crime. The document emphasizes the platform's commitment to transparency and accountability in enforcing these standards. The intended user interventions include reporting mechanisms and educational resources to enhance user awareness and participation in maintaining a safe online environment.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it asserts the platform's commitment to enforcing strict standards against harmful and criminal content. This is evidenced by the clear delineation of prohibited behaviors and the emphasis on the platform's role in actively monitoring and regulating user activity to prevent harm.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and physical harm, as it focuses on preventing the coordination of violence and crime. Additionally, it implicitly considers reputational harm, given the potential for criminal activities to damage individuals' public standing.

4. **User Assumptions**: The policy assumes that users may inadvertently or deliberately engage in behaviors that contribute to harm, necessitating a regulatory framework to guide and correct such actions. It presumes a level of user vulnerability to harmful content, highlighting the need for protective measures and user education. Furthermore, it expects users to actively participate in the platform's safety protocols, such as reporting harmful content, indicating an assumption of user responsibility and capacity for self-regulation."
18_animal_violence_violent_harm,Snapchat,Snapchat_Violent_or_Disturbing.txt,"1. **Summary**: The policy document primarily aims to regulate the depiction of violence and disturbing content across the platform, focusing on preventing the dissemination of graphic and glorified violence, including animal abuse. It delineates strict guidelines for advertising content, allowing violent imagery only within legitimate newsworthy or documentary contexts and with appropriate viewer preparation and age targeting. The policy seeks to mitigate potential psychological harm by prohibiting content that may cause distress, such as graphic depictions of gore or bodily fluids. The document emphasizes the importance of maintaining a safe and respectful environment by setting clear boundaries for content creators and advertisers.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the use of definitive language such as ""we prohibit"" and ""must,"" which underscores the platform's commitment to enforcing strict content guidelines and ensuring compliance from users and advertisers.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm by prohibiting content that may cause distress or fear, such as graphic violence and intense jump scares. It also implicitly addresses physical harm by restricting content that glorifies violence, self-harm, and abuse.

4. **User Assumptions**: The policy assumes that users may be exposed to harmful content and therefore require protection through stringent content regulations. It also presumes a level of user vulnerability to psychological distress from graphic or disturbing imagery. Additionally, there is an implicit expectation that users and advertisers have the responsibility to adhere to the platform's content guidelines to maintain a safe environment."
18_animal_violence_violent_harm,Discord,Discord_Violence _and_Graphic_Content.txt,"1. **Summary**: The policy document aims to establish a regulatory framework prohibiting the dissemination of violent and graphic content on Discord, with a specific focus on material depicting real violence, gore, or animal cruelty. Its objectives include preventing the glorification and incitement of violence to safeguard the mental health and safety of users and communities. The policy outlines strict prohibitions against uploading, sharing, or engaging with content that portrays physical harm, and it reserves the right to involve law enforcement when necessary. User interventions are designed to deter participation in servers dedicated to violent content and to prevent the promotion of dangerous organizations.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the use of definitive language such as ""we do not allow,"" ""we have a strict policy,"" and ""we may escalate threats to law enforcement,"" which underscores a firm commitment to enforcing safety standards and maintaining community well-being.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, physical harm, and reputational harm. It highlights the mental health risks associated with exposure to violent content and the potential for physical harm through incitement, as well as the reputational damage that can arise from association with or support for violent acts.

4. **User Assumptions**: The policy assumes that users may be at risk of exposure to harmful content and that some may actively seek out or participate in communities centered around violence. It presumes a need for external regulation to ensure user safety, indicating a belief in limited user capacity for self-regulation in these contexts. Additionally, it implies a responsibility on the part of users to avoid engaging with or supporting violent content and communities."
18_animal_violence_violent_harm,Badoo,Badoo_violent_or_graphic_content.txt,"1. **Summary**: The policy document delineates the platform's regulatory framework concerning violent or graphic content, aiming to mitigate exposure to harmful imagery that might disturb users. It explicitly prohibits content featuring realistic blood, injuries, human remains, and certain depictions of hunting, with a nuanced exception for specific animal trophy images under controlled conditions. The policy seeks to enforce a safe digital environment through content moderation and offers users recourse to contest enforcement actions. The guidelines are structured to prevent psychological and reputational harm by restricting access to disturbing visual content.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the clear, directive language used to outline prohibitions and the structured list of unacceptable content types, reflecting a firm stance on maintaining community standards.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm by restricting exposure to violent and graphic imagery. Additionally, it implicitly considers reputational harm by regulating content that could be associated with dangerous organizations or individuals.

4. **User Assumptions**: The policy assumes users have a vulnerability to psychological distress from exposure to graphic content and a limited capacity for self-regulation in content sharing. It also presupposes a responsibility among users to adhere to community standards and engage with the platform's enforcement mechanisms if disputes arise."
18_animal_violence_violent_harm,YouTube,YouTube_Violent_or_graphic_content.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework aimed at mitigating the dissemination of violent or graphic content on its platform. It underscores the collective responsibility of users to adhere to Community Guidelines, thereby fostering a secure and respectful digital environment. The policy explicitly prohibits content designed to shock or incite violence, and it provides procedural guidance for reporting violations. The document seeks to engage users in proactive content moderation, emphasizing their role in maintaining community safety.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as it clearly delineates prohibited behaviors and outlines the responsibilities of users in maintaining platform safety. This is evidenced by the directive language used in phrases such as ""Donâ€™t post content"" and the emphasis on user compliance with community standards.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, through the prohibition of content intended to shock or disgust, and physical harm, by banning content that incites violence or depicts violent acts.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are capable of identifying and reporting harmful content. It presupposes a shared responsibility among users to uphold community standards, implying a level of digital literacy and ethical engagement in content moderation."
18_animal_violence_violent_harm,TikTok,TikTok_Safety_and_civility.txt,"1. **Summary**: The policy document delineates a framework aimed at safeguarding physical and psychological well-being by promoting civility and preventing violent and criminal behavior on the platform. It explicitly prohibits violent threats, incitement to violence, and the promotion of criminal activities that could harm individuals, animals, or property. The document underscores the platform's commitment to reporting credible and imminent threats to law enforcement, thereby integrating a proactive intervention strategy. The regulatory scope is comprehensive, addressing the potential real-world ramifications of online content and emphasizing the importance of respectful interaction among users.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear prohibitions and the unequivocal language used to define unacceptable behaviors. The document asserts strong regulatory measures and outlines specific actions that will be taken against violations, reflecting a firm commitment to maintaining safety and order.

3. **Types of Harm Addressed**: The policy explicitly addresses physical and psychological harm, as well as harm to animals and property. It also implicitly touches on reputational harm by emphasizing the importance of civility and respectful engagement.

4. **User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviors, necessitating strict regulations and interventions. It presumes a level of user responsibility in maintaining civility and recognizes the vulnerability of users to both perpetrate and be affected by violence. The document implies that users are capable of self-regulation but require clear guidelines to navigate acceptable conduct."
18_animal_violence_violent_harm,Reddit,Reddit_Do_not_post_violent_content.txt,"1. **Summary**: The policy document delineates Reddit's regulatory framework aimed at mitigating violent content, emphasizing the prohibition of posts that incite or glorify violence against individuals, groups, or animals. It seeks to balance content moderation with allowances for educational, newsworthy, or artistic expressions, provided they are contextualized appropriately. The document outlines specific interventions, such as tagging borderline content as NSFW, to prevent unexpected exposure to violence. Overall, the policy underscores the platform's commitment to maintaining a harassment-free environment while acknowledging the complexity of content moderation.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by its clear directives and prohibitive language regarding violent content. The use of imperative verbs such as ""do not post"" and ""ensure you provide context"" reinforces the platform's firm stance on content regulation, while also incorporating a preventative aspect by advising users on appropriate content tagging.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, physical harm, and reputational harm. It also implicitly touches on identity-based harm through its prohibition of content that targets specific groups.

4. **User Assumptions**: The policy assumes that users possess a baseline capacity for self-regulation, as it instructs them to provide context for potentially violent content and to use NSFW tags for borderline cases. It also presumes a level of vulnerability among users, recognizing the potential psychological impact of unexpected exposure to violent content. Additionally, the policy implies a responsibility on the part of users to discern and prevent the dissemination of harmful content."
18_animal_violence_violent_harm,Snapchat,"Snapchat_Threats,_Violence_&_Harm.txt","1. **Summary**: The policy document delineates Snapchat's commitment to prohibiting and removing content that incites or depicts violence, including animal abuse, and glorification of self-harm. It establishes a regulatory framework aimed at safeguarding user safety by outlining prohibitions against threatening behaviour and graphic violence, with particular emphasis on preventing self-harm and suicide. The document underscores the platform's proactive measures, including user reporting mechanisms and collaboration with law enforcement, to address imminent threats. Additionally, it highlights Snapchat's investment in supportive resources to enhance user well-being and safety.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This classification is justified by the clear prohibitions against specific harmful behaviours and the emphasis on proactive measures and user reporting to prevent harm, reflecting a firm stance on maintaining a safe digital environment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, physical harm, and reputational harm. Psychological harm is evidenced by the focus on self-harm and emotional distress, physical harm is indicated through the prohibition of violent behaviour, and reputational harm is implied in the context of threats and intimidation.

4. **User Assumptions**: The policy assumes that users have the capacity to recognize harmful content and are responsible for reporting such content. It also presumes a level of vulnerability among users, particularly regarding self-harm and emotional distress, necessitating the provision of supportive resources and potential intervention by emergency responders."
19_misinformation_false_content_health,YouTube,YouTube_Misinformation.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework aimed at curbing misinformation that poses significant risks of harm, particularly in contexts such as public health and democratic processes. It explicitly prohibits content that misleads users about civic activities like census participation, or that involves technically manipulated or misattributed media. The policy outlines mechanisms for users to report violations, thereby facilitating community-driven enforcement. The document's primary objective is to mitigate the dissemination of harmful misinformation by defining clear content boundaries and promoting user vigilance.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by the prescriptive language and categorical prohibitions on specific types of content. The document employs definitive terms such as ""not allowed"" and ""donâ€™t post,"" which underscore a regulatory approach that prioritizes compliance and enforcement over user education or engagement.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm by targeting content that could mislead or deceive users, potentially causing confusion or distress. It also considers reputational harm, particularly through the prohibition of misattributed content that could falsely influence public perception. Additionally, the policy implicitly addresses economic harm by safeguarding the integrity of processes like the census, which have significant socio-economic implications.

4. **User Assumptions**: The policy assumes that users possess the capacity to identify and report harmful content, indicating an expectation of user vigilance and responsibility. It also presumes a level of vulnerability among users to misinformation, necessitating protective measures against deceptive content. Furthermore, there is an implicit assumption that users may not always self-regulate effectively, justifying the need for stringent content guidelines and reporting mechanisms."
19_misinformation_false_content_health,Bumble,Bumble_Disinformation.txt,"1. **Summary**: The policy document aims to regulate the dissemination of disinformation by prohibiting the sharing of demonstrably false or materially misleading content that poses significant risks to individual and public safety. Its regulatory scope encompasses health-related misinformation, specifically targeting content that contradicts guidance from reputable health organizations, as well as false claims about civic processes and conspiracy theories. The policy seeks to intervene by disallowing content that could lead to physical harm or undermine public trust in institutions. It emphasizes the importance of aligning with authoritative health guidance while allowing personal opinions, provided they do not mislead or harm.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the firm prohibition of specific types of content and the reliance on guidance from ""leading and reputable global health organizations,"" which underscores a reliance on expert authority to define acceptable discourse and safeguard public welfare.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, physical, and reputational harms. Psychological harm is implied through the potential for misinformation to cause public panic or distress. Physical harm is directly referenced in relation to health misinformation that could result in injury. Reputational harm is considered in the context of undermining trust in public institutions and civic processes.

4. **User Assumptions**: The policy assumes users may lack the capacity to discern credible information, necessitating regulatory intervention to prevent the spread of harmful misinformation. It presumes a level of vulnerability to misleading content, particularly in health and civic contexts, and implies a user responsibility to engage with content that aligns with authoritative guidance while maintaining respectful discourse."
19_misinformation_false_content_health,Meta,Meta_misinformation.txt,"1. **Summary**: The document delineates a policy framework addressing misinformation, emphasizing the challenges in defining and regulating such content due to its inherently fluid nature. It outlines the platform's strategy of categorizing misinformation to provide guidance on permissible speech, balancing expression with safety and authenticity. The policy prioritizes the removal of misinformation that poses an imminent risk of physical harm or interferes with political processes. This approach reflects a nuanced regulatory scope aimed at mitigating specific harms while respecting user freedoms.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it seeks to preemptively manage misinformation by categorizing it and setting guidelines for its treatment. This is evidenced by the document's focus on balancing expression with safety and its proactive stance on removing content that could lead to harm or disrupt political processes.

3. **Types of Harm Addressed**: The policy explicitly addresses physical harm and interference with political processes, which can be interpreted as a form of reputational harm to democratic institutions. The emphasis on these harms underscores the platform's prioritization of preventing tangible and systemic disruptions.

4. **User Assumptions**: The policy assumes that users possess varying levels of information and may inadvertently spread misinformation, highlighting a perceived vulnerability in user knowledge. It also suggests an expectation of user responsibility in adhering to guidelines, despite the inherent challenges in defining misinformation. This reflects an assumption of limited user capacity for self-regulation in the context of rapidly changing information landscapes."
19_misinformation_false_content_health,Badoo,Badoo_misinformation.txt,"1. **Summary**: The policy document aims to mitigate the dissemination of misinformation by prohibiting the sharing of false or misleading content that poses significant risks to individual and public safety. It delineates a regulatory scope that encompasses health-related misinformation, particularly concerning communicable diseases and reproductive health, as well as false claims about civic processes. The policy seeks to intervene by restricting content that contradicts authoritative guidance from reputable health organizations and public authorities, while allowing personal opinions that do not intend harm or mislead. The document underscores the importance of maintaining public safety and integrity by preventing the spread of dangerous conspiracy theories and unverified health cures.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by its firm stance on not allowing the dissemination of misinformation and its reliance on guidance from ""leading and reputable global health organisations and public health authorities"" as the standard for determining the veracity of content.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, physical, and reputational harm. It highlights the potential for misinformation to cause injury or harm to the public, undermine public safety, and damage the credibility of civic processes.

4. **User Assumptions**: The policy assumes that users may inadvertently or deliberately share false information, necessitating a regulatory framework to prevent such actions. It presumes a degree of user vulnerability to misinformation, particularly in health and civic contexts, and expects users to adhere to guidelines that align with authoritative sources. Additionally, it implies a responsibility on the part of users to engage in respectful discourse and avoid spreading harmful or misleading content."
19_misinformation_false_content_health,TikTok,TikTok_Integrity_and_Authenticity.txt,"1. **Summary**: The policy document aims to enhance platform integrity by ensuring users access reliable and authentic information, thereby fostering a community grounded in trust and accountability. It explicitly prohibits misinformation that could lead to significant harm, utilizing independent fact-checkers and public health guidance to assess content accuracy. The policy outlines interventions such as warning labels and sharing prompts to mitigate the spread of potentially harmful misinformation, particularly in health-related contexts and during emergencies. The regulatory scope extends to moderating content that may cause moderate harm, including conspiracy theories and misrepresented authoritative sources.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes measures to preclude misinformation from causing harm by employing fact-checking and user prompts. This tone is evident in the document's focus on preemptive strategies to manage misinformation before it leads to significant harm.

3. **Types of Harm Addressed**: The policy explicitly addresses physical harm, particularly severe forms that are life-threatening, as well as psychological harm through the potential spread of misinformation that could cause societal panic or distress.

4. **User Assumptions**: The document assumes users may inadvertently engage with or share misinformation, indicating a perceived need for external regulation and guidance to ensure content accuracy. It presumes a limited capacity for self-regulation among users, necessitating platform interventions such as warning labels and prompts to reconsider sharing unverified information."
19_misinformation_false_content_health,Snapchat,Snapchat_harmful_false_or_deceptive_information.txt,"1. **Summary**: The policy document primarily aims to mitigate the spread of misinformation and deceptive practices on the platform, focusing on content that could harm users or society by distorting facts or impersonating others. It establishes a regulatory framework that prohibits the dissemination of false information, particularly that which denies tragic events, makes unverified medical claims, or undermines civic processes. The policy also addresses fraudulent behaviours, such as impersonation and spam, to maintain user trust and platform integrity. By setting these guidelines, the document seeks to foster a responsible information environment and protect users from various forms of digital harm.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates prohibitions and expectations regarding user behaviour, emphasizing the platform's commitment to maintaining safety and integrity. This is evidenced by the firm language used in phrases like ""We prohibit"" and ""We disallow,"" which underscores the non-negotiable nature of these rules.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, and privacy harm. Psychological harm is implied through the potential distress caused by false information and impersonation. Reputational harm is addressed through the prohibition of impersonation and deceptive content that could damage individuals' or organizations' credibility. Privacy harm is considered in the context of deceptive practices that may infringe upon users' personal information.

4. **User Assumptions**: The policy assumes that users may lack the capacity to discern false information, necessitating clear guidelines to prevent misinformation. It also presupposes a vulnerability to deceptive practices, such as impersonation and spam, indicating an expectation that users may be susceptible to such threats. Additionally, there is an implicit assumption of user responsibility to adhere to the guidelines and contribute to a safe information environment."
19_misinformation_false_content_health,Snapchat,Snapchat_False_or_Deceptive_Information_eligibility_requirements.txt,"1. **Summary**: The policy document delineates Snapchat's regulatory framework aimed at mitigating the dissemination of false or deceptive information, particularly concerning political, health, and other socially significant topics. It establishes clear guidelines for content eligibility, emphasizing the responsibility of creators and partners to ensure the accuracy of their content. The document prohibits the recommendation of content containing false information, thereby aiming to protect users from misinformation that could undermine civic processes or public health. The policy underscores the platform's commitment to maintaining a safe and informed community by restricting the spread of harmful content.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the prescriptive language used to outline the responsibilities of creators and partners, as well as the definitive prohibitions on certain types of content. The policy employs a directive approach to ensure compliance with its guidelines, reflecting an emphasis on maintaining control over the platform's informational integrity.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and identity-based harms. Psychological harm is implied through the prohibition of disturbing or violent content, while reputational harm is addressed through the restriction of false information that could damage individuals or entities. Identity-based harm is considered in the context of political misinformation that could undermine civic identities and processes.

4. **User Assumptions**: The policy assumes that users, particularly creators and partners, have the capacity for self-regulation and are responsible for fact-checking their content. It presupposes a level of vulnerability among the general user base to misinformation, necessitating protective measures. Additionally, the policy implies that users have a responsibility to contribute to a safe informational environment by adhering to community guidelines."
19_misinformation_false_content_health,Bumble,Bumble_misinformation.txt,"1. **Summary**: The policy document aims to mitigate the dissemination of misinformation by prohibiting the sharing of demonstrably false or misleading content that poses significant risks to individual and public safety. Its regulatory scope encompasses content that contradicts authoritative health guidance, promotes unverified medical treatments, misrepresents abortion care, or distorts civic processes. The policy seeks to intervene by delineating clear boundaries for acceptable discourse, particularly in relation to public health and civic integrity. It emphasizes the importance of aligning shared content with credible sources to prevent harm and maintain informational integrity.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes strict guidelines and non-negotiable standards for content sharing, particularly emphasizing alignment with reputable health and civic authorities. This tone is evident in the unequivocal language used to prohibit specific types of misinformation and the clear delineation of unacceptable content.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, physical, and reputational harms. Psychological harm is implied through the potential distress caused by misinformation; physical harm is directly referenced in the context of false health information leading to injury; and reputational harm is suggested through the emphasis on maintaining the credibility of public health and civic institutions.

4. **User Assumptions**: The policy assumes that users may lack the capacity to independently verify the credibility of information, necessitating regulatory intervention to prevent harm. It presupposes a vulnerability to misinformation, particularly in contexts of health and civic processes, and implies a responsibility for users to engage with content critically and align with authoritative sources."
1_chat_message_messenger_block,Facebook Messenger,Facebook_Messenger_Preventing_Unwanted_Contacts.txt,"1. **Summary**: The policy document outlines Messenger's strategic initiative to enhance user safety by introducing new features aimed at preventing unwanted contacts and scams. It emphasizes the integration of safety notices within the chat interface, designed to alert users to suspicious activities and empower them to take preventive actions such as blocking or ignoring potential threats. The regulatory scope extends to the deployment of machine learning algorithms to detect behavioral patterns indicative of abuse, particularly focusing on interactions involving minors. The document underscores the commitment to maintaining user privacy even as the platform transitions to end-to-end encryption.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on providing users with proactive tools and information to identify and mitigate risks, alongside a commitment to safeguarding privacy while enhancing security measures.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly through the prevention of unwanted interactions that could lead to distress. It also implicitly considers privacy harm by ensuring that safety measures do not compromise user confidentiality.

4. **User Assumptions**: The document assumes that users may lack the ability to independently identify and manage potential threats, necessitating the provision of in-app guidance and alerts. It also presupposes a degree of user vulnerability, particularly among minors, and implies a responsibility for users to engage with the provided safety features to protect themselves."
1_chat_message_messenger_block,Facebook Messenger,"Facebook_Messenger_blocking,_reporting,_and_deleting.txt","1. **Summary**: The policy document delineates the procedures and implications of blocking profiles on Messenger and Facebook, aiming to empower users with tools to manage unwanted interactions. It specifies the dual functionality of blocking, distinguishing between blocking messages and calls, and blocking profiles entirely, thereby offering users a nuanced approach to personal safety and privacy. The regulatory scope is focused on user autonomy in digital interactions, providing clear instructions to facilitate user control over their social media environment. The document's objective is to mitigate potential harms by enabling users to prevent unwanted contact and maintain personal boundaries across digital platforms.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes user empowerment through proactive measures to avoid unwanted interactions. This is evidenced by the detailed procedural guidance on blocking and the emphasis on user control over personal digital spaces, suggesting a focus on preemptive harm reduction.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and privacy harms. By enabling users to block unwanted interactions, it seeks to protect them from potential distress or harassment (psychological harm) and ensures their personal information and digital presence are shielded from unwanted scrutiny (privacy harm).

4. **User Assumptions**: The policy assumes users possess the capacity for self-regulation and the ability to identify and manage their own digital boundaries. It presupposes that users are proactive in safeguarding their online interactions and are responsible for utilizing the platform's tools to mitigate potential vulnerabilities."
1_chat_message_messenger_block,LinkedIn,LinkedIn_sending_requests.txt,"1. **Summary**: The policy document delineates LinkedIn's regulatory measures concerning invitation limits to safeguard user experience and maintain network quality. It articulates specific conditions under which user accounts may face temporary restrictions, particularly emphasizing the prevention of spam and the maintenance of meaningful connections. The policy aims to foster a secure and professional community by encouraging users to connect only with individuals they know and trust, in alignment with LinkedInâ€™s broader user agreements and community standards. Furthermore, it outlines procedural details regarding the duration and non-negotiability of these restrictions, reinforcing the platform's commitment to privacy and user autonomy.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the emphasis on safeguarding user experience and the imposition of strict limits and non-negotiable restrictions to preempt spam and irrelevant connections, thereby asserting control over user interactions to maintain community standards.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. It aims to prevent the negative impact of spam and unwanted invitations, which can lead to user frustration and damage to professional reputations within the network.

4. **User Assumptions**: The policy assumes that users may engage in behaviours that risk overwhelming others with unsolicited invitations, potentially leading to spam. It presupposes a need for external regulation to ensure users maintain quality connections and adhere to community standards. Additionally, it implies that users possess the capacity for self-regulation by recommending connections only with known and trusted individuals, yet acknowledges potential lapses in this behaviour by instituting automatic restrictions."
1_chat_message_messenger_block,WhatsApp,WhatsApp_How_to_stay_safe.txt,"1. **Summary**: The document outlines WhatsApp's commitment to user safety through the implementation of its Terms of Service, which delineate prohibited activities to mitigate potential harms. It emphasizes the importance of user awareness and responsibility in sharing content, highlighting the potential for messages to be forwarded or shared beyond the original recipient. The policy aims to prevent the dissemination of illegal, obscene, or otherwise harmful content by detailing the consequences of violating these terms, including account bans. Additionally, it provides guidance on the use of features like location sharing, underscoring the platform's preventative approach to user safety.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it focuses on outlining measures and guidelines designed to avert potential harms before they occur. This is evidenced by the emphasis on user education and the proactive nature of the Terms of Service in defining and discouraging harmful behaviors.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and identity-based harms. Psychological harm is implied through the prohibition of threatening or intimidating content, reputational harm through the sharing of defamatory content, and identity-based harm through the restriction of racially or ethnically offensive material.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation and are responsible for the content they share. It presupposes a level of user awareness and discretion, as it encourages users to consider the implications of their shared content. Additionally, there is an implicit assumption of user vulnerability to the misuse of shared information, necessitating the outlined preventative measures."
1_chat_message_messenger_block,Hinge,Hinge_are_you_sure.txt,"1. **Summary**: The policy document introduces ""Are You Sure?"", a feature aimed at enhancing user interactions by encouraging respectful communication within a dating platform. Its regulatory scope focuses on providing users with reflective prompts when potentially harmful language is detected, thereby promoting self-regulation and positive engagement. The feature is designed to facilitate safe and constructive exchanges without completely blocking messages, aligning with the platform's broader objectives of fostering genuine connections. The document also references additional resources outlining user conduct expectations, underscoring a commitment to community standards.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on fostering respectful communication and providing users with opportunities to reflect and amend their language, rather than imposing punitive measures or outright censorship.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm, as it seeks to mitigate negative exchanges and promote respectful communication. It implicitly acknowledges the potential for reputational harm by encouraging users to reconsider language that could be perceived as disrespectful or harmful.

4. **User Assumptions**: The policy assumes that users are generally well-intentioned but may inadvertently engage in harmful communication due to mismatched styles. It presumes a capacity for self-regulation, as users are given the opportunity to edit their messages. Additionally, it suggests an expectation of user responsibility in adhering to community standards as outlined in the platform's conduct guidelines."
1_chat_message_messenger_block,WhatsApp,WhatsApp_Messaging_Guidelines.txt,"1. **Summary**: The WhatsApp Messaging Guidelines document articulates the regulatory framework governing user interactions within the platform's messaging and calling services, emphasizing the protection of personal communications through end-to-end encryption. It delineates specific prohibitions against sharing illegal content, including child exploitation material, and engaging in activities such as terrorism, violence, and drug trafficking. The document outlines the platform's commitment to taking action against violations based on limited information, such as user reports and basic account data. This policy aims to ensure a secure and lawful communication environment while maintaining user privacy.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates prohibited behaviors and the platform's enforcement mechanisms. This is evidenced by the direct language used in prohibitions and the emphasis on the platform's ability to take action against violations, reinforcing a sense of regulatory control and compliance expectation.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (through the prohibition of content that exploits or endangers children), reputational harm (by preventing the sharing of intellectual property without rights), and identity-based harm (through the prohibition of activities supporting terrorism).

4. **User Assumptions**: The document assumes that users possess a basic understanding of legal and ethical standards, as it expects them to refrain from engaging in illegal activities or sharing prohibited content. It also implies a level of user responsibility for self-regulation, given the reliance on user reports to identify violations, suggesting an expectation of active participation in maintaining community standards."
1_chat_message_messenger_block,Google Messages,Google_Messages_Understand_the_basics_of_privacy.txt,"1. **Summary**: The policy document outlines Google's commitment to safeguarding user privacy and information security within the Google Messages platform, emphasizing the use of end-to-end encryption for private communications. It aims to empower users by providing control over their privacy settings and ensuring that personal information is not inadvertently shared. The regulatory scope includes guidance on managing Google Account privacy settings and enhancing user experience through secure and encrypted messaging. The document's primary objective is to protect users' data while facilitating secure communication, thereby mitigating potential privacy breaches.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on user empowerment through privacy controls and the proactive measures described to secure user data, such as end-to-end encryption and detailed guidance on privacy settings.

3. **Types of Harm Addressed**: The policy primarily addresses privacy-related harm, focusing on the protection of personal information and communication content from unauthorized access or exposure.

4. **User Assumptions**: The document assumes that users may lack awareness of privacy settings and the implications of their digital interactions, necessitating guidance on managing account visibility and encryption features. It presumes a user capacity for self-regulation, with an expectation that users will actively engage with privacy tools to safeguard their information."
1_chat_message_messenger_block,WhatsApp,WhatsApp_How_to_use_WhatsApp_responsibly.txt,"1. **Summary**: The policy document delineates WhatsApp's regulatory framework aimed at promoting responsible messaging practices among its users. It emphasizes the importance of privacy and security, outlining guidelines such as communicating with known contacts, respecting boundaries, and utilizing group controls to mitigate potential harms. The policy also addresses the issue of misinformation by advising users to verify the authenticity of messages before forwarding them. Overall, the document seeks to foster a safe and respectful communication environment on the platform.

2. **Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on proactive measures users can take to ensure responsible use, such as obtaining permission before adding contacts to groups and utilizing group controls to manage communications effectively.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on respecting boundaries and privacy. It also implicitly tackles reputational harm by advising caution in forwarding messages, thereby preventing the spread of misinformation.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation and are capable of understanding and implementing the guidelines provided. It presupposes a level of vulnerability to misinformation and unsolicited communication, thus emphasizing the importance of user responsibility in maintaining a safe messaging environment."
1_chat_message_messenger_block,WhatsApp,WhatsApp_How_to_keep_your_groups_and_community_safe.txt,"1. **Summary**: The policy document from WhatsApp articulates a framework for enhancing user safety and privacy within group and community interactions, emphasizing the importance of a secure and meaningful communication environment. It outlines specific interventions such as end-to-end encryption, two-step verification, and biometric authentication to safeguard user accounts and communications. The document also introduces features like disappearing messages and 'view once' media to empower users with control over their shared content. Collectively, these measures are designed to mitigate risks associated with unauthorized access and privacy breaches.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on user empowerment through the provision of tools and features that enhance privacy and security, as well as the encouragement to share safety practices within user communities.

3. **Types of Harm Addressed**: The policy explicitly addresses privacy-related harm, focusing on preventing unauthorized access to user communications and safeguarding personal information through encryption and verification measures.

4. **User Assumptions**: The document assumes users possess a baseline capacity for self-regulation and responsibility in managing their privacy settings, as evidenced by the instructions to enable security features like two-step verification and biometric authentication. It also presumes a level of vulnerability to privacy breaches, necessitating the provision of tools to protect against such risks."
1_chat_message_messenger_block,Facebook Messenger,Facebook_Messenger_Blocked_from_sending_friend_requests on Facebook.txt,"1. **Summary**: The policy document primarily aims to regulate user interactions on Facebook by imposing temporary restrictions on the ability to send friend requests, thereby maintaining the platform's integrity and user experience. It specifically targets behaviours that result in a high volume of unanswered or unwelcome friend requests, suggesting a preventative approach to mitigate potential digital harm. The policy underscores the importance of users only sending friend requests to individuals they know personally, thus fostering a more authentic and secure online environment. Additionally, it provides guidance on alternative ways to connect with unfamiliar individuals, such as following public figures, to prevent future infractions.

2. **Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the document's emphasis on educating users about proper friending practices and its focus on maintaining a welcoming platform environment. The language used is instructive and aims to guide users towards compliant behaviours rather than penalizing them harshly.

3. **Types of Harm Addressed**: The policy addresses psychological harm by aiming to prevent users from receiving unwanted friend requests, which can lead to discomfort or distress. It also implicitly addresses privacy concerns by encouraging connections only with known individuals, thereby reducing the risk of exposing personal information to strangers.

4. **User Assumptions**: The document assumes that users may lack awareness of the platform's friending policies and thus inadvertently engage in behaviours that lead to blocks. It presupposes a capacity for self-regulation, as users are expected to modify their behaviour based on the guidance provided. Additionally, it assumes a level of vulnerability among users who might receive unwanted friend requests, necessitating protective measures to maintain a safe online environment."
20_content_edsa_guideline_misinformation,Pinterest,Pinterest_Community_Guidelines.txt,"**Summary**: The Pinterest Community Guidelines document articulates the platform's regulatory framework aimed at fostering a safe and inspiring environment by delineating acceptable content and user conduct. The policy's primary objective is to mitigate the dissemination of harmful and misleading information, thereby safeguarding users from various digital harms. It outlines a proactive approach to content moderation, emphasizing user participation in reporting violations and the platform's commitment to evolving its standards through expert consultation. The guidelines are designed to be transparent and user-friendly, with clear enforcement mechanisms and avenues for user feedback.

**Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on user engagement in reporting harmful content and the collaborative approach to refining guidelines through expert input, suggesting a focus on preemptive harm reduction and community involvement.

**Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and privacy harms. It highlights the removal of antagonistic, false, and misleading content, which can impact users' mental well-being, damage reputations, and infringe on privacy.

**User Assumptions**: The document assumes users have the capacity and responsibility to identify and report inappropriate content, indicating a belief in users' ability to self-regulate and contribute to the platform's safety. It also presumes a level of user vulnerability to misinformation and harmful content, necessitating clear guidelines and protective measures."
20_content_edsa_guideline_misinformation,YouTube,YouTube_Educational_Documentary_Scientific_and_Artistic_content.txt,"1. **Summary**: The policy document delineates YouTube's approach to evaluating content under its Educational, Documentary, Scientific, and Artistic (EDSA) framework, aiming to balance community safety with the preservation of informative content. It outlines a regulatory scope where content that might otherwise infringe community guidelines can remain on the platform if it meets specific contextual criteria for an EDSA exception. The document's primary objective is to guide users in adding sufficient context to their content to qualify for such exceptions, although it clarifies that context alone does not guarantee exemption. This framework seeks to facilitate user interventions by providing explicit criteria for content evaluation, thereby promoting informed content creation.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes clear guidelines and criteria for content evaluation and exceptions. This is evidenced by the structured presentation of rules and the emphasis on the platform's discretion in assessing content on a case-by-case basis, underscoring YouTube's regulatory authority.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. It acknowledges the potential for content to be violent, graphic, or sexual, which could impact viewers' mental well-being and the reputation of individuals depicted.

4. **User Assumptions**: The document assumes that users are capable of understanding and implementing the guidelines for context addition, suggesting a baseline capacity for self-regulation. It also implies a responsibility on the part of content creators to ensure their material is appropriately contextualized to avoid potential harm, indicating an expectation of user accountability and proactive engagement with the platform's safety protocols."
20_content_edsa_guideline_misinformation,YouTube,YouTube_community_guidelines.txt,"1. **Summary**: The YouTube Community Guidelines document delineates the platform's regulatory framework aimed at maintaining a safe digital environment while allowing diverse content expression. It outlines specific prohibitions against various harmful practices, including misinformation, spam, and harassment, and details enforcement mechanisms involving both human and algorithmic oversight. The guidelines are designed to be inclusive and uniformly applied, reflecting a commitment to fairness irrespective of content creator backgrounds. The policy underscores the importance of adapting to emerging digital challenges through ongoing consultation with external experts and content creators.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes clear rules and enforcement procedures for content on the platform. This is evidenced by the explicit listing of prohibited behaviors and the emphasis on equal application of guidelines, reflecting a firm commitment to maintaining order and safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., harassment and cyberbullying), reputational harm (e.g., impersonation, misinformation), and privacy harm (e.g., sensitive content, external links). It also implicitly touches on identity-based harm through its prohibition of hate speech.

4. **User Assumptions**: The document assumes that users may engage in risky behaviors such as spreading misinformation or engaging in harassment, necessitating regulatory oversight. It presumes a need for external regulation to mitigate these risks, suggesting limited capacity for self-regulation among users. Additionally, it implies a shared responsibility among users to adhere to guidelines to maintain a safe community."
20_content_edsa_guideline_misinformation,YouTube,YouTube_community_guidelines_2.txt,"1. **Summary**: The YouTube Community Guidelines aim to maintain a safe and enjoyable environment for users by outlining acceptable content standards and providing mechanisms for reporting violations. The policy encompasses a broad regulatory scope, applying to all forms of content, including unlisted and private materials, and emphasizes the removal of content that involves spam, deception, or harm to minors. However, exceptions are made for content with educational, documentary, scientific, or artistic value, highlighting a nuanced approach to content moderation. The guidelines also encourage user participation in governance by reporting inappropriate content, thereby fostering a community-based regulatory framework.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates rules and expectations for user behavior and content, while also incorporating a preventative aspect by outlining specific types of prohibited content. This tone is evidenced by the direct and prescriptive language used to communicate the guidelines and the emphasis on user responsibility in maintaining community standards.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly in relation to protecting minors, as well as reputational harm through its focus on deceptive practices and impersonation. It also touches on privacy concerns by regulating content that could potentially exploit or harm individuals.

4. **User Assumptions**: The policy assumes that users have the capacity to discern inappropriate content and are responsible for reporting violations, suggesting an expectation of user engagement in self-regulation. It also presumes a level of vulnerability among minors, necessitating specific protective measures, and implies that users are generally trustworthy but require clear guidelines to maintain community standards."
20_content_edsa_guideline_misinformation,YouTube,YouTube_external_links_policy.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework concerning external links, aiming to prevent the dissemination of harmful content by prohibiting links that contravene the platform's Community Guidelines. It outlines specific prohibitions against linking to content such as pornography, malware, phishing sites, unauthorized access to paid services, and sites promoting terrorism or hate speech. The policy is designed to safeguard users by mandating the removal of links that could lead to psychological, reputational, or economic harm, particularly through misinformation or deceptive practices. The document emphasizes user responsibility in adhering to these guidelines and encourages reporting violations to maintain a safe digital environment.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the directive language used, such as ""Donâ€™t post links"" and ""Links that send users to content that violates our Community Guidelines are not allowed,"" which underscores a strict enforcement approach and a clear delineation of prohibited behaviors.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, economic, and privacy harms. It highlights the risks associated with exposure to harmful content, phishing, unauthorized access to services, and the spread of misinformation, particularly in the context of public health.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for ensuring their content complies with the guidelines. It presupposes a level of user awareness regarding the potential harms of linking to prohibited content and the expectation that users will actively participate in maintaining platform safety by reporting violations."
20_content_edsa_guideline_misinformation,YouTube,YouTube_manage_harmful_content.txt,"**Summary**: The YouTube safety policy document delineates a comprehensive framework aimed at mitigating harmful content through a structured approach known as the ""four Rs"": Remove, Reduce, Raise, and Reward. The regulatory scope encompasses the enforcement of Community Guidelines designed to protect users from content that violates standards related to hate speech, harassment, child safety, and violent extremism. The policy objectives are to swiftly remove harmful content, limit the dissemination of borderline material, elevate credible sources, and incentivize compliance among content creators. The document underscores a collaborative policy development process involving industry experts and creators to ensure guidelines remain relevant and effective.

**Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the clear articulation of guidelines and the structured approach to content regulation. This is further reinforced by the emphasis on responsibility and the systematic review of policies in collaboration with external experts, indicating a command over the regulatory process.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm (through hate speech and harassment), identity-based harm (through hate speech), and child safety concerns, which can encompass both psychological and physical harm.

**User Assumptions**: The policy assumes that users have the potential to both contribute to and be affected by harmful content, necessitating a regulatory framework that balances creative freedom with community protection. It presumes a level of user responsibility in adhering to guidelines and acknowledges the need for authoritative intervention to manage risks associated with misinformation and harmful content dissemination."
20_content_edsa_guideline_misinformation,Instagram,Instagram_content_lowering.txt,"1. **Summary**: The policy document delineates Instagram's guidelines for demoting content in user feeds and stories to enhance transparency and adherence to community standards. It primarily aims to mitigate the visibility of content that potentially contravenes these standards, utilizing predictive technology to identify and lower the reach of such content. The guidelines address various forms of harmful content, including hate speech, bullying, harassment, and misinformation, with a focus on reducing the dissemination of fact-checked misinformation. The document underscores an ongoing commitment to refining technological systems to ensure precise enforcement and transparency in content moderation practices.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the document's emphasis on preemptive measures to reduce the visibility of potentially harmful content and its reliance on technological systems to enforce community standards, reflecting a proactive and controlling approach to content governance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., bullying and harassment), reputational harm (e.g., misinformation), sexual harm (e.g., adult nudity and sexual solicitation), identity-based harm (e.g., hate speech), and physical harm (e.g., violence and incitement).

4. **User Assumptions**: The document assumes that users may inadvertently or deliberately engage in behaviours that contravene community standards, necessitating technological intervention. It presupposes a limited capacity for self-regulation among users, highlighting a need for external moderation to manage potential vulnerabilities and uphold platform integrity. Additionally, it implies an expectation of user compliance with evolving content guidelines."
21_violence_violent_organisation_extremist,Discord,Discord_Violent_Extremism.txt,"1. **Summary**: The Discord Violent Extremism Policy articulates a stringent regulatory framework aimed at prohibiting the use of its platform for the organization, promotion, or support of violent extremist activities or ideologies. It delineates a comprehensive scope that encompasses a variety of actors, including terrorist groups, violent extremist organizations, and informal networks with extremist beliefs. The policy explicitly forbids users from sharing or promoting content related to these groups, extending its governance to include off-platform behaviors that support violent extremism. This policy underscores Discord's commitment to mitigating high-risk digital harm by preventing the proliferation of extremist content and activities on its platform.

2. **Tone**: The rhetorical tone of the policy is authoritative and preventative. This classification is justified by the firm language used, such as ""we take a firm stance"" and ""we do not tolerate,"" which underscores a zero-tolerance approach to violent extremism and emphasizes the platform's proactive measures to prevent such activities.

3. **Types of Harm Addressed**: The policy primarily addresses psychological, physical, and reputational harm. Psychological harm is implicated through the potential distress caused by exposure to extremist content, physical harm is suggested by the potential for violence advocated by extremist groups, and reputational harm is considered in the context of users' associations with such groups.

4. **User Assumptions**: The policy assumes that users have the potential to engage in or be influenced by extremist activities, indicating a perceived risk of behavioral deviance. It also presumes a level of user responsibility in self-regulating their content and interactions to avoid the promotion or support of violent extremism. The policy implies a vulnerability to extremist influence, necessitating stringent governance to protect the user community."
21_violence_violent_organisation_extremist,Meta,Meta_Dangerous_organisations_and_individuals.txt,"1. **Summary**: The policy document aims to prevent and mitigate real-world harm by prohibiting the presence of violent organisations and individuals on the platform. It establishes a regulatory framework that categorizes entities into two tiers based on their connection to violence, with Tier 1 necessitating the most stringent content enforcement. The policy's objectives include the identification and removal of entities that engage in or advocate for violence, particularly those involved in hate crimes, terrorism, and organized crime. This approach underscores a commitment to safeguarding users from entities with direct ties to offline harm.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the use of definitive language such as ""we do not allow"" and ""we remove,"" which conveys a firm and non-negotiable stance on the presence of violent entities on the platform. The policy's structured tier system further reinforces this authoritative tone by clearly delineating the levels of enforcement based on the severity of the threat.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, physical, and identity-based harm. Psychological harm is implied through the mention of dehumanization and advocacy of violence against individuals based on protected characteristics. Physical harm is directly referenced through the focus on violence against civilians and systematic criminal operations. Identity-based harm is addressed through the policy's emphasis on protecting individuals from violence based on protected characteristics.

4. **User Assumptions**: The policy assumes that users are vulnerable to the influence and actions of violent organisations and individuals, necessitating protective measures. It presumes a lack of capacity for self-regulation among users when exposed to such harmful entities, thereby justifying the platform's proactive enforcement measures. The policy also implies a responsibility on the part of users to adhere to community standards that reject violence and support safe interactions."
21_violence_violent_organisation_extremist,Bumble,Bumble_dangerous_organisations.txt,"1. **Summary**: The policy document delineates Bumble's regulatory framework aimed at prohibiting the presence of organizations and individuals associated with violence, extremism, and terrorism on its platform. Its primary objective is to mitigate risks posed by entities that support or engage in violent and criminal activities, thereby safeguarding users from exposure to harmful content. The policy outlines specific interventions, including content removal and account actions, to enforce compliance and ensure user safety. Additionally, it provides conditional allowances for discussions related to dangerous entities for educational or awareness purposes, contingent upon clear intent.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the firm language used to delineate prohibited behaviors and the clear articulation of consequences for non-compliance, reflecting a zero-tolerance stance towards violence and extremism.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, physical harm, and identity-based harm. It focuses on the prevention of intimidation, violence, and hate speech, which can affect users' mental well-being, physical safety, and identity security.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for clarifying their intentions when discussing sensitive topics related to dangerous organizations. It also presumes a level of vulnerability among users to the harms associated with exposure to violent and extremist content, necessitating protective measures."
21_violence_violent_organisation_extremist,Meta,Meta_Violence_and_incitement.txt,"1. **Summary**: The policy document primarily aims to mitigate the risk of offline violence by regulating content that incites or facilitates violence on the platform. Its regulatory scope encompasses the removal of language that poses credible threats to public or personal safety, particularly targeting individuals or groups based on protected characteristics or immigration status. The policy outlines interventions such as content removal, account disabling, and collaboration with law enforcement to address genuine risks of physical harm. It emphasizes a nuanced approach to distinguishing between casual expressions and credible threats, considering factors like public visibility and context.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the firm language used in describing the platform's actions, such as ""remove content,"" ""disable accounts,"" and ""work with law enforcement,"" which conveys a strong commitment to enforcing safety standards and preventing harm.

3. **Types of Harm Addressed**: The policy explicitly addresses physical harm and identity-based harm. It focuses on preventing violence that could lead to physical injury and targets speech that discriminates based on protected characteristics or immigration status.

4. **User Assumptions**: The policy assumes that users may engage in casual or non-serious expressions of violence but also recognizes the potential for such expressions to escalate into credible threats. It presumes a level of user responsibility in understanding the impact of their language and suggests that users possess varying degrees of vulnerability, particularly those with public visibility or belonging to protected groups."
21_violence_violent_organisation_extremist,Snapchat,Snapchat_Hateful_Content.txt,"1. **Summary**: The policy document delineates Snapchat's regulatory framework aimed at eliminating the presence of terrorist organizations, violent extremists, and hate groups from its platform. It establishes a zero-tolerance stance on content that promotes or glorifies violence, discrimination, or hate speech, thus prioritizing user safety and community protection. The policy outlines proactive measures, including collaboration with civil rights organizations and law enforcement, to enforce these regulations effectively. The document underscores the platform's commitment to continuous improvement in policy enforcement through ongoing consultation with experts and advocacy groups.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative and preventative. This is evidenced by the unequivocal language used to describe the platform's zero-tolerance stance and the explicit prohibition of certain types of content, as well as the emphasis on collaboration with authoritative bodies to enforce these rules.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and identity-based harms. It highlights the prohibition of content that demeans or discriminates based on various identity markers, thereby acknowledging the potential psychological and reputational impacts on affected individuals and communities.

4. **User Assumptions**: The policy assumes that users may engage in or be exposed to harmful behaviors, necessitating strict regulations and external collaborations to mitigate risks. It presupposes a need for external oversight and expertise, indicating an assumption of users' potential vulnerability to extremist content and their limited capacity for self-regulation in the context of hate speech and violent extremism."
21_violence_violent_organisation_extremist,YouTube,YouTube_Violent_extremist_policy.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework aimed at mitigating the presence and influence of violent extremist and criminal organizations on its platform. It explicitly prohibits content that praises, promotes, or supports these entities, thereby safeguarding the community from potential harm and misuse. The document emphasizes a collective responsibility model, urging users to adhere to guidelines and actively report violations. This policy seeks to prevent the recruitment and dissemination of extremist ideologies, ensuring a secure digital environment for all users.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the clear directives against specific types of content and the emphasis on user compliance and proactive reporting. The language underscores a zero-tolerance stance towards violations, reinforcing the platform's commitment to maintaining safety and order.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm, given the focus on content that could influence or radicalize viewers. It also implicitly considers reputational harm to the platform by associating with extremist content, and physical harm, as indicated by the directive to contact law enforcement if immediate danger is perceived.

4. **User Assumptions**: The policy assumes users possess the capacity for self-regulation and a shared responsibility in maintaining platform safety. It presupposes users' ability to identify and report harmful content, suggesting a baseline level of digital literacy and awareness. Additionally, it implies a vulnerability to extremist content, necessitating clear guidelines and community vigilance."
22_request_law_enforcement_user,Pinterest,Pinterest_Law_enforcement_guidelines.txt,"**Summary**: The policy document outlines Pinterest's regulatory framework for responding to law enforcement requests for user information, emphasizing compliance with legal standards and privacy considerations. It delineates the conditions under which user data may be disclosed, primarily targeting law enforcement, judicial, and regulatory personnel. The document underscores the necessity of legitimate legal instruments, such as subpoenas or court orders, to access user information. It also highlights the limitations of data availability, as Pinterest may not retain copies of certain user-generated content.

**Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the clear delineation of legal requirements and procedural guidelines, which convey a sense of regulatory compliance and control over user data disclosure.

**Types of Harm Addressed**: The policy primarily addresses privacy-related harm, as it focuses on the conditions under which user information may be disclosed to law enforcement, thereby implicating concerns about user data protection and confidentiality.

**User Assumptions**: The document assumes that users may not be fully aware of the legal processes involved in data disclosure, as it directs non-law enforcement individuals to the Help Centre for further information. It also implies a level of user responsibility in understanding that not all content saved on Pinterest is stored by the platform, which suggests an expectation of user awareness regarding data storage practices."
22_request_law_enforcement_user,Quora,Quora_law_enforcement.txt,"1. **Summary**: The document outlines Quora's policy regarding the disclosure of user information to governmental entities, including law enforcement, emphasizing compliance with legally valid requests such as subpoenas, court orders, or warrants. It asserts Quora's commitment to user notification, providing a 14-day notice period before information disclosure, unless legally prohibited or in emergency situations involving imminent danger. The policy aims to balance legal compliance with user privacy protection, allowing users the opportunity to contest data requests. The document serves to inform users of their rights and the procedural safeguards in place concerning governmental data requests.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates the conditions under which user information may be disclosed and the legal frameworks governing such actions. The use of definitive language such as ""requires,"" ""will endeavor,"" and ""generally provides"" underscores a commitment to procedural rigor and legal compliance.

3. **Types of Harm Addressed**: The policy primarily addresses privacy harm, as it concerns the conditions under which user data may be disclosed to governmental authorities. It also implicitly references potential physical harm in its provision for emergency disclosures involving danger of death or serious physical injury.

4. **User Assumptions**: The policy assumes that users have a vested interest in their privacy and the protection of their personal data. It presupposes that users are capable of understanding legal processes and may wish to contest data requests, as evidenced by the provision of a notice period to allow for legal intervention. The document also implies a level of user vulnerability to governmental data requests, necessitating procedural safeguards and transparency."
22_request_law_enforcement_user,WhatsApp,WhatsApp_Information_for_Law_Enforcement.txt,"1. **Summary**: The document outlines WhatsApp's procedural guidelines for responding to law enforcement requests for user data, emphasizing compliance with applicable legal frameworks such as the U.S. Stored Communications Act. Its primary objective is to delineate the conditions under which law enforcement can access user information, thereby balancing legal obligations with user privacy. The policy specifies the types of user data that may be disclosed and the legal prerequisites for such disclosures, including the necessity of a valid subpoena. The document serves as a resource for law enforcement officials, clarifying the process and limitations of data requests.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes clear guidelines and legal prerequisites for law enforcement data requests. This is evidenced by the precise legal references and the emphasis on compliance with statutory requirements, underscoring WhatsApp's commitment to adhering to legal standards while managing user data.

3. **Types of Harm Addressed**: The policy implicitly addresses privacy harm by outlining the conditions under which user data may be disclosed to law enforcement, thereby seeking to protect user privacy while fulfilling legal obligations.

4. **User Assumptions**: The document assumes that users have a basic understanding of their privacy rights and the legal processes involved in data disclosure. It presupposes users' capacity for self-regulation by directing them to the ""Request Account Info"" feature for personal data inquiries, indicating an expectation of user responsibility in managing their account information."
22_request_law_enforcement_user,Quora,Quora_law_enforcement_2.txt,"1. **Summary**: The policy document articulates Quora's regulatory framework regarding the disclosure of user information to law enforcement agencies. It emphasizes adherence to legal processes, specifying that user data will only be disclosed upon receipt of a valid subpoena, court order, or warrant, depending on the nature of the request and jurisdiction. The policy delineates procedures for both U.S. and international law enforcement, highlighting the necessity of compliance with the Mutual Legal Assistance Treaty for foreign requests. Additionally, it clarifies that anonymously posted content on Quora is not linked to identifiable user accounts, thereby limiting the scope of data disclosure.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the document's reliance on legal terminology and procedural specificity, underscoring Quora's commitment to legal compliance and user privacy protection while delineating clear boundaries for law enforcement interactions.

3. **Types of Harm Addressed**: The policy implicitly addresses privacy harm by outlining the conditions under which user information may be disclosed to law enforcement, thereby protecting users from unwarranted invasions of privacy.

4. **User Assumptions**: The document assumes that users value their privacy and that they may engage in anonymous posting to protect their identity. It also presumes that users are not inherently aware of the legal processes involved in data disclosure, thus necessitating clear communication of these procedures. Additionally, there is an implicit assumption that users are responsible for understanding the implications of anonymity on the platform."
22_request_law_enforcement_user,Snapchat,Snapchat_law_enforcement.txt,"1. **Summary**: The policy document delineates Snap Inc.'s regulatory framework for collaborating with law enforcement agencies to ensure user safety on its platform, Snapchat. It outlines the procedures for law enforcement to request user data, emphasizing compliance with legal standards and privacy obligations. The document aims to balance the facilitation of legal investigations with the protection of user privacy rights. It serves as a guide for law enforcement on the legal processes necessary to access Snapchat account records.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes clear guidelines and procedures for law enforcement interactions, emphasizing legal compliance and privacy considerations. This tone is evident in the document's structured presentation of legal requirements and its emphasis on adherence to applicable laws.

3. **Types of Harm Addressed**: The policy implicitly addresses privacy harm by focusing on the protection of user data and the conditions under which it may be disclosed to law enforcement. The mention of ""misuse of our platform"" suggests a broader concern for potential psychological and reputational harms that may arise from such misuse.

4. **User Assumptions**: The document assumes that users are vulnerable to misuse of the platform, necessitating protective measures and collaboration with law enforcement. It also presumes that users have a right to privacy, which must be safeguarded even in the context of legal investigations. Additionally, there is an implicit expectation that users may not always be capable of self-regulating their interactions on the platform, thereby requiring external oversight and intervention."
22_request_law_enforcement_user,Reddit,Reddit_Guidelines_for_Law_Enforcement.txt,"1. **Summary**: The document serves as a guideline for law enforcement and government agencies seeking to request user account information or the removal of user-generated content from Reddit, emphasizing the platform's commitment to user privacy and legal compliance. It delineates the procedural requirements necessary for such requests, highlighting the need for authenticity and legal sufficiency in submissions. The policy underscores Reddit's non-contractual stance, reserving the right to object to requests that do not meet its standards. This framework aims to balance the facilitation of lawful investigations with the protection of user privacy and rights.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the document's emphasis on legal compliance, the procedural rigor required for requests, and the explicit reservation of rights to object to insufficient submissions, which collectively underscore a commitment to safeguarding user privacy against unwarranted intrusion.

3. **Types of Harm Addressed**: The policy implicitly addresses privacy harm, as it outlines the conditions under which user information may be disclosed, thereby aiming to prevent unauthorized access to personal data.

4. **User Assumptions**: The document assumes that users have a reasonable expectation of privacy and that they are part of a community that values shared interests. It also presupposes that users may be subject to legal scrutiny, necessitating a structured process for information requests to protect against potential overreach by law enforcement."
23_job_report_select_match,Fortnite,Fortnite_How_to_report_bad_player_behavior.txt,"1. **Summary**: The policy document outlines the procedures for reporting inappropriate player behavior within the Fortnite gaming environment, aiming to uphold a safe and enjoyable user experience. It delineates the regulatory scope by providing detailed instructions on how users can report misconduct through in-game mechanisms and encourages contacting local authorities for severe issues. The policy's objectives are to empower users to actively participate in community governance while ensuring adherence to the platform's Terms of Service and Code of Conduct. The document emphasizes user intervention as a critical component in maintaining digital safety and community standards.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the language that encourages user participation in maintaining safety and provides clear, step-by-step guidance on how to report misconduct, reflecting a focus on proactive harm prevention and user empowerment.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. It acknowledges the potential for frustration and worry caused by negative player behavior, implicating psychological distress, and it provides mechanisms to report and potentially sanction users, which relates to reputational consequences.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and are willing to engage in maintaining community standards. It presupposes a level of digital literacy sufficient to navigate reporting tools and implies a shared responsibility among users to uphold a safe gaming environment. The policy also suggests that users are vulnerable to certain behaviors that may require intervention from both the platform and external authorities."
23_job_report_select_match,LinkedIn,LinkedIn_reporting_jobs.txt,"1. **Summary**: The LinkedIn safety policy document delineates procedures for users to report inappropriate job postings, aiming to maintain a secure and professional platform environment. It provides a structured mechanism for flagging jobs deemed as spam, scams, discriminatory, or offensive, thereby facilitating user intervention in content moderation. The regulatory scope is primarily preventative, focusing on user empowerment to identify and report harmful content. The policy underscores LinkedIn's commitment to safeguarding users from various digital harms through community-driven oversight.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes user engagement in identifying and reporting potentially harmful job postings. This tone is evident in the detailed guidance provided for users to actively participate in maintaining platform integrity, suggesting a collaborative approach to harm prevention.

3. **Types of Harm Addressed**: The policy explicitly addresses economic harm (through scams and phishing), psychological harm (via offensive or harassing content), and identity-based harm (through discriminatory postings).

4. **User Assumptions**: The policy assumes that users possess the capacity to discern inappropriate content and are willing to engage in self-regulation by reporting such content. It presupposes a level of digital literacy and responsibility among users to contribute to the platform's safety and integrity."
23_job_report_select_match,Tinder,Tinder_how_to_report.txt,"1. **Summary**: The policy document outlines the procedures for reporting inappropriate behavior on the platform, emphasizing user safety and community standards. It provides detailed instructions for reporting both online and offline incidents, including those involving users who have unmatched. The regulatory scope is primarily preventative, aiming to mitigate harm by facilitating user intervention through reporting mechanisms. The document underscores the platform's commitment to maintaining a safe environment by encouraging users to report any behavior that contravenes community guidelines.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the emphasis on user empowerment through clear instructions for reporting and the platform's commitment to taking reports seriously, indicating a focus on fostering a safe and enjoyable user experience.

3. **Types of Harm Addressed**: The policy addresses psychological harm, reputational harm, and privacy concerns. It highlights the importance of reporting rude, inappropriate, or creepy behavior, which can impact users' mental well-being and personal reputation, and it stresses the need for detailed information to protect users' privacy.

4. **User Assumptions**: The document assumes that users are proactive and capable of identifying and reporting harmful behavior. It presumes a level of digital literacy and responsibility among users to provide detailed reports, suggesting an expectation of user engagement in maintaining community standards. Additionally, it implies that users are vulnerable to inappropriate behavior, necessitating a robust reporting mechanism to safeguard their experience on the platform."
23_job_report_select_match,Hinge,Hinge_reporting.txt,"1. **Summary**: The policy document from Hinge outlines a structured protocol for users to report inappropriate or harmful interactions within the app, emphasizing the anonymity and permanence of such reports. It aims to regulate user interactions by providing clear steps for reporting both within and outside the app, thereby enhancing user safety and accountability. The document underscores the importance of detailed reporting to facilitate swift investigation and resolution of issues, aligning with the platformâ€™s broader governance framework. This policy seeks to empower users by offering a straightforward mechanism to address and mitigate potential harms encountered on the platform.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear, directive language that instructs users on specific actions to take when reporting harm. The policy's emphasis on the seriousness with which reports are treated further reinforces this authoritative stance, aiming to instill confidence in the platformâ€™s governance mechanisms.

3. **Types of Harm Addressed**: The policy substantively addresses psychological, reputational, and privacy harms. It implicitly acknowledges the potential for psychological distress through harmful interactions, reputational damage through false or misleading profiles, and privacy violations through unauthorized access to personal information.

4. **User Assumptions**: The policy assumes that users possess the capacity to identify and articulate instances of harm, as well as the responsibility to provide detailed information to facilitate investigations. It presumes a level of digital literacy and self-regulation, expecting users to engage proactively with the reporting mechanisms to maintain a safe online environment."
23_job_report_select_match,Tinder,Tinder_off-line_behaviour.txt,"1. **Summary**: The policy document delineates the procedures for reporting inappropriate or harmful behaviour on a dating platform, both within the app and for offline incidents. Its regulatory scope encompasses user interactions before and after matching, as well as encounters that extend beyond the digital environment. The document aims to empower users to report misconduct by providing clear, step-by-step instructions for various reporting scenarios. It emphasizes the platform's commitment to user safety and the importance of detailed reports to facilitate swift investigation and resolution.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the document's focus on guiding users through the reporting process and its emphasis on the platform's dedication to maintaining a safe environment for user interactions.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it refers to interactions that are ""rude, inappropriate or just plain creepy,"" which can cause distress or discomfort to users. It also implicitly acknowledges reputational harm by allowing users to report behaviours that may affect their standing or perception within the community.

4. **User Assumptions**: The document assumes that users are capable of identifying inappropriate behaviour and are responsible for initiating reports to maintain community safety. It implies a level of user vulnerability to negative interactions, while also presuming users possess the capacity for self-regulation and the responsibility to contribute to a safe platform environment by reporting misconduct."
23_job_report_select_match,Tinder,Tinder_reporting.txt,"1. **Summary**: The policy document from Tinder outlines procedures for reporting inappropriate content or behavior, aiming to enhance user safety and promote a respectful dating environment. It delineates the regulatory scope by providing step-by-step instructions for reporting incidents both within the app and via email, emphasizing user participation in maintaining community standards. The policy seeks to empower users to identify and report violations of the platform's Terms of Use or Community Guidelines, thereby facilitating effective intervention and resolution of harmful actions. The document underscores the importance of detailed reporting to ensure that issues are addressed appropriately and efficiently.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on user empowerment and community involvement in fostering a safe environment, as well as the detailed guidance provided for reporting concerns, which suggests a collaborative approach to harm prevention.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and identity-based harms. It focuses on inappropriate content or behavior that could negatively impact users' mental well-being, social standing, or personal identity within the platform.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and are proactive in identifying and reporting harmful behavior. It presumes a level of user responsibility in maintaining community standards and implies that users have the capability to discern violations and provide accurate, detailed reports to facilitate effective platform governance."
24_filter_comment_word_message,Facebook,Facebook_Why_you_can't_post.txt,"1. **Summary**: The document outlines Facebook's regulatory framework for managing user participation in groups, specifically addressing restrictions on posting, commenting, and group involvement. The policy aims to enforce compliance with Facebook's Community Standards by implementing temporary suspensions or limitations on user activities, either by group administrators or Facebook itself. It provides mechanisms for users to understand and potentially contest these restrictions through the Support Inbox and review requests. The document serves to balance community safety with user engagement by delineating clear procedural guidelines for addressing violations.

2. **Tone**: The tone of the policy is predominantly authoritative, as it delineates specific conditions under which user actions may be restricted and emphasizes adherence to established Community Standards. This authoritative stance is reinforced by the procedural language used to describe the enforcement and appeal processes, indicating a structured and rule-based approach to governance.

3. **Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. Psychological harm is implied through the emphasis on maintaining a safe community environment, while reputational harm is addressed through the potential consequences of violating Community Standards and the subsequent restrictions on user participation.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation but may occasionally breach community guidelines, necessitating external intervention. It presumes a level of user responsibility to be aware of and comply with Community Standards, while also acknowledging user vulnerability to administrative errors by providing a review process for contested decisions."
24_filter_comment_word_message,Reddit,Reddit_harassment_filter.txt,"**Summary**: The policy document outlines the implementation and operationalization of a harassment filter within online community moderation tools, aiming to enhance user safety by automatically filtering potentially harassing content. It provides moderators with the ability to customize the filter's sensitivity, offering ""Moderate"" and ""High"" filtering options to balance between content accuracy and comprehensiveness. The regulatory scope is primarily preventative, focusing on reducing exposure to harmful interactions by leveraging a large language model trained on historical moderation data. The document emphasizes the importance of community-specific customization, suggesting that the effectiveness of the filter is contingent on the unique characteristics and needs of each online community.

**Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on providing moderators with tools to proactively manage community safety, as well as the flexibility offered in adjusting the filter settings to suit specific community needs, thereby fostering an environment of empowerment and protection.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm by focusing on the filtering of harassing content, which can negatively impact users' mental well-being. It also implicitly touches on reputational harm, as harassment can damage an individual's standing within a community.

**User Assumptions**: The document assumes that users, specifically moderators, possess a degree of technical competence and responsibility, as they are expected to configure and manage the harassment filter settings. It also presupposes that users are vulnerable to harassment, necessitating protective measures, and that moderators can accurately assess the needs of their community to optimize the filter's effectiveness."
24_filter_comment_word_message,Instagram,Instagram_tools_protect_against_abuse.txt,"1. **Summary**: The policy document delineates Instagram's introduction of new tools aimed at mitigating user exposure to abusive Direct Messages (DMs), thereby enhancing community safety. It articulates a regulatory framework focused on preemptively filtering offensive content, specifically within DM requests, to shield users from potential harm. The policy underscores the complexity of eradicating abuse entirely, acknowledging the limitations of current measures while emphasizing the platform's commitment to user protection. By implementing these tools, Instagram seeks to balance user privacy with proactive harm reduction strategies.

2. **Tone**: The document employs a preventative and supportive rhetorical tone. This is evidenced by the emphasis on protecting users from harmful interactions before they occur and the acknowledgment of the platform's responsibility to foster a safer environment. The language is reassuring, highlighting Instagram's commitment to user safety and the proactive steps being taken to address abuse.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on abusive content, including racist, sexist, and homophobic messages. It also implicitly considers reputational harm, as abusive messages can impact users' social standing and mental well-being.

4. **User Assumptions**: The document assumes that users, particularly those with larger followings, are vulnerable to receiving abusive messages from unknown individuals. It presupposes a limited capacity for self-regulation in avoiding such content, thus necessitating platform intervention. Additionally, it implies a user responsibility to activate the filtering tool, suggesting an expectation of user engagement with safety features to enhance personal protection."
24_filter_comment_word_message,Instagram,Instagram_anti_bullying.txt,"1. **Summary**: The document articulates Instagram's regulatory framework aimed at mitigating online bullying through a suite of user-centric tools and interventions. Its primary objective is to enhance user safety by providing mechanisms such as comment warnings, mention controls, and blocking features that empower users to manage their interactions. The policy's regulatory scope encompasses both proactive and reactive measures, facilitating user autonomy in filtering and reporting harmful content. By embedding these tools within the platform's governance structure, Instagram seeks to uphold community standards and reduce exposure to potentially offensive or harmful interactions.

2. **Tone**: The dominant rhetorical tone of the policy is preventative. This is evidenced by the emphasis on tools designed to preemptively warn users about potentially offensive comments and the provision of features that allow users to control who can interact with them. The language suggests a focus on foreseeing and mitigating harm before it occurs, rather than solely responding to incidents post facto.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm by focusing on tools that prevent exposure to bullying and offensive content. It also implicitly considers reputational harm through mechanisms that allow users to control mentions and tags, which can affect how individuals are perceived by others on the platform.

4. **User Assumptions**: The policy assumes that users possess a degree of agency and responsibility in managing their online interactions, as evidenced by the provision of customizable tools for filtering and blocking content. It also presumes a certain level of vulnerability to psychological harm, necessitating protective measures. Furthermore, the policy implies an expectation that users will engage in self-regulation by utilizing the platform's features to maintain their own safety and adhere to community guidelines."
24_filter_comment_word_message,Instagram,Instagram_anti-harassment_features.txt,"1. **Summary**: The policy document from Instagram outlines a regulatory framework aimed at mitigating bullying and harassment on the platform through user-centric safety features. It emphasizes the implementation of tools such as Hidden Words and Advanced Comment Filtering, which are designed to automatically block unwanted comments and messages, thereby fostering a secure environment for content creation and sharing. The policy's scope extends to empowering users with customizable options to filter specific words, emojis, or phrases, and to manage interactions through account-level controls. The overarching objective is to maintain a supportive community by proactively addressing potential digital harms associated with user interactions.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the language used to convey commitment to user protection and the proactive nature of the tools provided, such as ""we're committed to protecting and supporting you"" and ""help keep you safe,"" which underscore a focus on user empowerment and harm prevention.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly in the form of bullying and harassment, as well as reputational harm through the prevention of spam and offensive content in comments and messages.

4. **User Assumptions**: The policy assumes that users are at risk of encountering unwanted interactions and may lack the capacity to self-regulate without platform-provided tools. It also presumes a degree of user responsibility in customizing their safety settings and managing their interactions, suggesting an expectation of user engagement with the platform's safety features to mitigate potential harms."
24_filter_comment_word_message,Instagram,Instagram_bullying_and_harassment_guide.txt,"1. **Summary**: The policy document from Instagram's Help Center outlines the platform's commitment to safeguarding users against bullying and harassment through the implementation of protective features such as Hidden Words and Advanced Comment Filtering. These tools are designed to automatically block or filter out unwanted comments and direct messages, including those containing profanity, bullying, or spam. The policy emphasizes user empowerment by allowing customization of word lists to further tailor the filtering process, while also offering tools like Limited Interactions to manage unwelcome engagement. The overarching objective is to foster a safe and supportive community where users can focus on content creation and sharing without fear of abuse.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as evidenced by the language that emphasizes user protection and empowerment. The document reassures users of the platform's commitment to their safety and provides clear guidance on utilizing the available tools, indicating a focus on prevention and user autonomy.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on bullying and harassment, as well as reputational harm by preventing spam and offensive content from appearing in user interactions.

4. **User Assumptions**: The document assumes that users are at risk of encountering harmful interactions, such as bullying and spam, and may lack the capacity for self-regulation without platform-provided tools. It presumes a level of user responsibility in customizing their safety settings to suit personal needs, indicating an expectation of proactive engagement with the platform's safety features."
25_member_boundary_ghost_feel,WhatsApp,WhatsApp_Establish_boundaries_and_a_positive_atmosphere.txt,"1. **Summary**: The policy document primarily aims to establish a framework for maintaining a safe and positive online community by setting and communicating clear boundaries. It emphasizes the importance of educating members on recognizing and responding to misinformation, hoaxes, and abusive behavior to foster an inclusive environment. The document outlines strategies for community leaders to engage members actively in safety practices, thereby empowering them to contribute to a respectful culture. It also highlights the necessity of limiting community size to ensure member engagement and commitment, thereby preserving group morale.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on education and empowerment, as well as the proactive strategies suggested for community leaders to preemptively address potential disruptions and foster a positive atmosphere.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, through its focus on bullying and harassment; reputational harm, by educating members on misinformation and hoaxes; and identity-based harm, by promoting an inclusive community environment.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and can be educated to identify and respond to harmful behaviors. It also presumes a level of vulnerability to misinformation and harassment, necessitating guidance and support from community leaders. Additionally, there is an expectation that users will take an active role in maintaining community safety and adhere to established boundaries."
25_member_boundary_ghost_feel,Bumble,Bumble_what_will_get_you_kicked_off.txt,"**Summary**: The Bumble safety policy document establishes a regulatory framework aimed at fostering a positive and secure user experience by mandating adherence to community guidelines. It delineates the conditions under which users may be banned, emphasizing the importance of authenticity and respect in user interactions. The policy seeks to prevent harm by prohibiting impersonation, misrepresentation, and non-consensual sexual advances, thereby safeguarding users' psychological and reputational well-being. Through these measures, the policy intends to create a respectful digital environment conducive to genuine connections.

**Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on creating a ""positive and safe experience"" and the encouragement for users to ""celebrate"" their true selves, indicating a focus on fostering a constructive and respectful community rather than solely punishing misconduct.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on respect and consent, reputational harm by prohibiting impersonation and misrepresentation, and sexual harm by regulating non-consensual sexual content and advances.

**User Assumptions**: The document assumes that users possess the capacity for self-regulation and are responsible for maintaining authenticity and respect in their interactions. It also presumes a level of vulnerability among users, necessitating protections against impersonation, misrepresentation, and unwanted sexual advances."
25_member_boundary_ghost_feel,Tinder,Tinder_ghosting.txt,"1. **Summary**: The policy document primarily aims to delineate circumstances under which it is deemed acceptable to ""ghost"" someone, framing this action as a legitimate response to certain negative behaviours in digital interactions. The regulatory scope is focused on personal relationship management within online dating contexts, advocating for user autonomy in disengaging from harmful or disrespectful communications. The document outlines specific scenarios, such as inconsistent communication and disregard for consent, where ghosting is positioned as a protective measure. Intended user interventions include encouraging individuals to prioritize their psychological well-being and personal safety by disengaging from potentially harmful interactions.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it seeks to empower users to preemptively protect themselves from potential harm by disengaging from interactions that exhibit red flags. This tone is evident in the language used, which emphasizes user autonomy and the importance of self-preservation in the face of disrespectful or unsafe behaviours.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it discusses the emotional toll of engaging with unreliable or disrespectful individuals. It also touches upon issues of personal safety, particularly in relation to consent, suggesting that disengagement is a valid response to potential threats to one's well-being.

4. **User Assumptions**: The document assumes that users possess the capacity to identify red flags in digital interactions and have the agency to disengage when necessary. It presumes a level of vulnerability in users, particularly in the context of dating, and suggests that users have a responsibility to protect their own psychological and physical safety by recognizing and responding to harmful behaviours."
25_member_boundary_ghost_feel,Hinge,Hinge_Communicating_and_Obtaining_Consent.txt,"1. **Summary**: The Hinge safety policy document primarily aims to promote a culture of respect and communication by emphasizing the importance of obtaining mutual consent in relationships. It outlines regulatory measures that encourage users to engage in active communication and respect personal boundaries, both online and offline. The policy collaborates with safety experts to provide users with guidelines on how to navigate consent and establish personal boundaries effectively. The document's interventions are designed to empower users to articulate their preferences and make informed decisions about their interactions.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the document's emphasis on empowerment, respect, and personal agency, as well as its collaborative approach with safety experts to provide guidance and resources for users.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and sexual harm by focusing on consent and the importance of respecting personal boundaries to prevent coercion and discomfort.

4. **User Assumptions**: The document assumes that users are capable of self-regulation and are responsible for actively communicating their boundaries and preferences. It presumes a level of vulnerability in users, acknowledging that they may face pressure or coercion, and thus emphasizes the importance of empowerment and trust in one's instincts."
25_member_boundary_ghost_feel,Tinder,Tinder_Community_Guidelines.txt,"1. **Summary**: The Tinder Community Guidelines aim to establish a regulatory framework that ensures a safe and inclusive environment for users engaging in online interactions. The policy delineates behavioural expectations both on and off the app, emphasizing the importance of consent, privacy, and respect for personal boundaries. It seeks to mitigate potential harms by prohibiting the sharing of explicit content, personal information, and violent material, thereby fostering a positive user experience. The guidelines underscore the consequences of non-compliance, ranging from minor warnings to permanent bans, to enforce adherence to these standards.

2. **Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on creating a ""fun, safe and inclusive space"" and the proactive measures outlined to prevent harm, such as setting clear behavioural expectations and highlighting the importance of consent and privacy.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on consent and boundaries, privacy harm by advising against sharing personal information, and reputational harm by regulating the type of content that can be shared publicly. Additionally, it implicitly addresses economic harm by cautioning against sharing financial information and sending money.

4. **User Assumptions**: The policy assumes that users possess a basic understanding of privacy risks and the importance of consent but may require guidance on specific behaviours that ensure safety. It presumes a level of vulnerability to psychological and privacy-related harms, suggesting that users might not always be aware of the potential consequences of their actions. Furthermore, there is an implicit expectation that users are responsible for adhering to the guidelines to maintain a safe community environment."
25_member_boundary_ghost_feel,Hinge,Hinge_report.txt,"1. **Summary**: The policy document from Hinge outlines the platform's regulatory framework aimed at fostering a respectful and authentic dating environment. The primary objective is to provide users with a mechanism to report inappropriate behavior, thereby enhancing user safety and promoting a culture of kindness and respect. The policy emphasizes anonymity and permanence in reporting, ensuring that reported users are effectively removed from the reporter's digital space. This document underscores Hinge's commitment to transforming dating culture by focusing on meaningful connections rather than superficial interactions.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the language that emphasizes user empowerment through anonymity in reporting and the platformâ€™s commitment to fostering a respectful environment. The policyâ€™s focus on kindness, authenticity, and meaningful connections further reinforces a supportive atmosphere intended to prevent harm.

3. **Types of Harm Addressed**: The policy substantively addresses psychological harm by promoting a safe and respectful environment and preventing exposure to unwanted interactions. It also implicitly addresses reputational harm by ensuring that reports are anonymous and permanent, protecting users from potential backlash or further negative interactions.

4. **User Assumptions**: The policy assumes that users are capable of identifying inappropriate behavior and are willing to take action to report it. It presupposes a user base that values respectful interactions and is motivated by the desire for meaningful connections. Additionally, there is an implicit expectation that users are responsible for contributing to a positive community culture by utilizing the reporting tools provided."
2_game_player_voice_account,Fortnite,Fortnite_Report_Content.txt,"1. **Summary**: The policy document primarily aims to establish a framework for reporting misconduct within the Epic Games ecosystem, focusing on user-generated content and behaviour that contravenes established community standards. It delineates the types of violations that warrant reporting, including hateful language, scams, bullying, harassment, cheating, illegal activities, and intellectual property infringements. The regulatory scope encompasses various Epic Games products and services, indicating a comprehensive approach to maintaining a safe and respectful digital environment. User interventions are facilitated through a structured reporting mechanism, empowering users to identify and report harmful content effectively.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as it clearly delineates the rules and expectations for user behaviour within the platform. This is evidenced by the explicit categorization of reportable offences and the emphasis on compliance with both community standards and legal requirements.

3. **Types of Harm Addressed**: The policy explicitly addresses several types of harm, including psychological harm (bullying and harassment), reputational harm (scams), identity-based harm (hateful language), and legal/economic harm (intellectual property infringement).

4. **User Assumptions**: The policy assumes that users possess the capacity to recognize and report violations, indicating an expectation of user vigilance and responsibility in maintaining community standards. It also presumes a level of user awareness regarding the legal and ethical implications of their online interactions, as well as an understanding of the platform's rules and guidelines."
2_game_player_voice_account,Minecraft,Minecraft_community_guidelines.txt,"1. **Summary**: The Community Standards for Minecraft document articulates Mojang Studios' commitment to fostering a safe and inclusive environment for all players, aligning with the broader Xbox Community Standards. It emphasizes the importance of diversity and inclusion as foundational values, aiming to create a community where players can express themselves freely and respectfully. The policy outlines a zero-tolerance stance on hate speech and violence, underscoring the platform's dedication to maintaining a welcoming atmosphere. These standards are designed to ensure that interactions within the Minecraft community are conducted in a manner that is respectful and considerate of all participants.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on inclusion, diversity, and community values, as well as the proactive measures outlined to prevent hate speech and violence, suggesting a focus on fostering a positive and safe environment rather than punitive enforcement.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on creating a safe and inclusive environment, and identity-based harm by emphasizing diversity and a zero-tolerance policy towards hate speech.

4. **User Assumptions**: The document assumes that users are capable of self-regulation and are responsible for maintaining a respectful community atmosphere. It presumes that users understand the importance of diversity and inclusion and are expected to engage in behaviors that reflect these values. Additionally, there is an implicit assumption that users are vulnerable to psychological and identity-based harms, necessitating the outlined protective measures."
2_game_player_voice_account,Fortnite,Fortnite_Content_Guidelines.txt,"1. **Summary**: The Epic Games Content Guidelines aim to establish a safe and inclusive environment by regulating user-generated content within its ecosystem. The policy explicitly prohibits content that is discriminatory, graphically explicit, or promotes illegal activities, thereby setting clear boundaries for acceptable user behavior. The guidelines are designed to prevent the dissemination of harmful content that could negatively impact users based on race, ethnicity, gender identity, and other personal attributes. By enforcing these standards, Epic Games seeks to foster a welcoming community and mitigate risks associated with digital interactions.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the use of definitive language such as ""do not allow,"" ""will not be allowed,"" and ""do not promote,"" which underscores a strict regulatory stance aimed at ensuring compliance and maintaining a safe digital environment.

3. **Types of Harm Addressed**: The policy addresses several types of harm, including psychological harm (through the prohibition of discriminatory and hateful content), reputational harm (by preventing doxing and harassment), sexual harm (by banning pornography and child sexual abuse material), and identity-based harm (by disallowing content that marginalizes individuals based on identity attributes).

4. **User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviors, whether intentionally or inadvertently, necessitating clear guidelines to curb such actions. It presumes a degree of user responsibility in adhering to these guidelines to maintain a safe community. Furthermore, the policy implicitly acknowledges user vulnerability to various forms of harm, thus justifying the need for stringent content regulation."
2_game_player_voice_account,Minecraft,Minecraft_realms_safety.txt,"1. **Summary**: The Minecraft Realms Safety policy document articulates a comprehensive regulatory framework aimed at ensuring a secure and inclusive online environment for users of Minecraft Realms, a subscription-based personal server service. The policy outlines a multi-faceted approach to player safety, incorporating community guidelines, proactive moderation, and parental controls to mitigate online harms. It emphasizes the importance of maintaining a positive gaming experience through the enforcement of community standards and the deployment of advanced chat filtering systems to identify and manage instances of harassment, abuse, and hate speech. The document underscores the role of human moderation in reviewing escalated cases to uphold a safe and welcoming community.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This classification is justified by the document's emphasis on proactive measures such as chat filtering and community guidelines, as well as its focus on fostering a positive and inclusive environment for players.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on harassment and abuse, identity-based harm through the mention of hate speech, and reputational harm by ensuring appropriate names and descriptions within the Realms.

4. **User Assumptions**: The policy assumes that users may engage in harmful behaviours such as harassment and hate speech, necessitating proactive moderation and filtering systems. It also presumes a degree of vulnerability among users, particularly younger players, which is addressed through parental controls. Additionally, there is an implicit expectation that users will adhere to community standards and engage responsibly within the platform."
2_game_player_voice_account,Call of Duty HQ,COD_Privacy_Policy.txt,"1. **Summary**: The Activision Privacy Policy document outlines the company's approach to data collection, storage, usage, and disclosure across its digital properties. It serves as a regulatory framework for managing user information, emphasizing the role of Activision as the data controller. The policy aims to enhance user experience while safeguarding personal data through transparent practices and user consent mechanisms. It also integrates a Cookie Policy to inform users about data tracking technologies and their options for managing consent.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative. This is evidenced by the formal and structured language used to assert Activision's role as a data controller and its commitment to processing user information responsibly, thus establishing trust and compliance with regulatory standards.

3. **Types of Harm Addressed**: The policy primarily addresses privacy-related harm. It focuses on the protection of personal information and the implications of data tracking technologies, which could potentially infringe on user privacy if not properly managed.

4. **User Assumptions**: The document assumes that users are generally trusting of Activision's data practices but also recognizes their need for control over personal data. It presumes a level of user awareness and responsibility in managing consent for data usage, particularly concerning cookies and targeted advertising. The policy implies that users have the capacity to understand and exercise their rights regarding personal information."
2_game_player_voice_account,Call of Duty HQ,COD_reporting_guide_Call_of_Duty_Warzone_mobile.txt,"1. **Summary**: The policy document outlines the procedures for reporting players suspected of cheating or using offensive language in Call of Duty: Warzone Mobile. It aims to maintain a fair and respectful gaming environment by empowering users to report misconduct directly through the game interface. The regulatory scope is focused on user-generated reports, which are reviewed by the platform to determine appropriate actions. The policy emphasizes confidentiality in handling reports and does not disclose outcomes to the reporting user.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the document's focus on guiding users through the reporting process and its assurance that reports are taken seriously, aiming to preemptively address and mitigate harmful behaviors within the gaming community.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and reputational harm. Psychological harm is implied through the reference to offensive language, while reputational harm is suggested in the context of cheating, which can undermine fair play and trust among players.

4. **User Assumptions**: The document assumes that users possess the capacity to identify and report inappropriate behavior, indicating a level of self-regulation and responsibility. It also presumes that users are motivated to maintain a positive gaming environment and are willing to engage with the reporting system to address potential harms."
2_game_player_voice_account,Fortnite,Fortnite_reporting_misconduct.txt,"**Summary**: The Epic Games Safety and Security Center policy document delineates a comprehensive framework aimed at maintaining a secure and enjoyable environment within the Epic Games ecosystem. It establishes Community Rules and Content Guidelines applicable to all users, outlining the procedures for reporting misconduct and the consequences for rule violations. The policy emphasizes user engagement in safety measures by encouraging the reporting of inappropriate behavior and content, and provides mechanisms for users to block or mute others. Sanctions for non-compliance range from warnings to permanent bans, contingent on the severity and recurrence of the offense.

**Tone**: The document exhibits a predominantly authoritative and preventative tone. This is evidenced by the clear articulation of rules and guidelines, the structured hierarchy of consequences for violations, and the emphasis on user responsibility in maintaining community standards.

**Types of Harm Addressed**: The policy primarily addresses psychological and reputational harm. This is inferred from the focus on inappropriate conduct and content, which can affect users' mental well-being and social standing within the gaming community.

**User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for adhering to community standards. It presupposes a level of vulnerability to inappropriate content and interactions, thereby necessitating the provision of tools for reporting and blocking. Additionally, it implies that users are proactive agents in fostering a safe environment by participating in the reporting process."
2_game_player_voice_account,Fortnite,Fortnite_Cabined_Accounts.txt,"1. **Summary**: The document delineates the regulatory framework for ""Cabined Accounts"" within Epic Games, aimed at safeguarding younger users by restricting access to certain features until parental consent is obtained. The policy's primary objective is to create a secure and inclusive digital environment by disabling features such as voice and text communication, monetary transactions, and external service linkages for users under the age of digital consent. This regulatory scope is designed to protect minors from potential harms while allowing them limited access to gaming content. The document outlines specific interventions to ensure compliance with digital consent laws and enhance user safety.

2. **Tone**: The rhetorical tone of the policy is predominantly preventative and authoritative. This is evidenced by the clear delineation of restrictions and the emphasis on parental oversight, which underscores the platform's commitment to preemptively mitigating risks associated with underage users' online interactions.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, economic, and privacy-related harms. By restricting communication features and financial transactions, the document seeks to prevent exposure to inappropriate content, financial exploitation, and unauthorized data sharing.

4. **User Assumptions**: The policy assumes that younger users are inherently vulnerable to online risks and lack the capacity for self-regulation, necessitating parental involvement for full account functionality. It presupposes that users under the age of digital consent require additional safeguards to protect them from potential online harms and assumes a responsibility on the part of parents or guardians to manage and consent to their children's digital activities."
2_game_player_voice_account,EA Sports FC 24,EA_positive_play_community_guidelines.txt,"**Summary**: The policy document from EA articulates a framework for fostering a safe, fair, and inclusive gaming environment, emphasizing the importance of community cooperation in achieving these goals. It outlines specific behavioral guidelines for players, such as respecting others, maintaining fairness, and adhering to legal standards, to ensure a positive gaming experience. The document also highlights available tools and controls, including account management and parental controls, to empower users in managing their interactions and gaming activities. Furthermore, it delineates potential consequences for non-compliance, underscoring a commitment to uphold the integrity of the gaming community.

**Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the emphasis on community collaboration and empowerment through tools and guidelines, as well as the encouragement for players to contribute to a positive environment.

**Types of Harm Addressed**: The policy primarily addresses psychological, reputational, and identity-based harms. It focuses on creating a respectful and inclusive community, which implicitly seeks to mitigate psychological distress, protect reputations, and ensure identity-based inclusivity.

**User Assumptions**: The document assumes that users possess the capacity for self-regulation and are motivated to contribute positively to the community. It presumes a level of user responsibility in adhering to guidelines and utilizing available tools to manage their gaming experience. Additionally, there is an implicit assumption of user vulnerability, particularly concerning exposure to inappropriate content and the need for parental controls."
2_game_player_voice_account,Call of Duty HQ,COD_black_ops_editions.txt,"1. **Summary**: The document under review is primarily a promotional communication detailing the various editions and pre-order incentives for the video game ""Call of Duty: Black Ops 6."" It outlines the availability of the game across multiple platforms and highlights specific features and bonuses associated with different purchase options. The regulatory scope is minimal, focusing instead on consumer information and marketing strategies rather than explicit safety or harm mitigation measures. The document does not directly address user safety or regulatory interventions, suggesting its primary objective is to inform and persuade potential buyers.

2. **Tone**: The dominant rhetorical tone of the policy document is promotional and informative. This classification is justified by the document's focus on detailing product features, purchase incentives, and platform availability, with language that aims to entice and inform potential consumers rather than regulate or guide user behavior in terms of safety.

3. **Types of Harm Addressed**: The document does not explicitly address any types of harm such as psychological, physical, reputational, sexual, identity-based, economic, or privacy-related harms. Its content is centered on product information and marketing.

4. **User Assumptions**: The document assumes users are primarily consumers interested in gaming content and related incentives. There is an implicit assumption of users being capable of navigating digital marketplaces and making informed purchasing decisions. The document does not address user vulnerabilities or responsibilities beyond consumer engagement with the product offerings."
3_suicide_disorder_eat_selfharm,Badoo,Badoo_suicide_and_self-injury.txt,"1. **Summary**: The policy document articulates a regulatory framework aimed at safeguarding users from content related to suicide, self-injury, and disordered eating. It delineates clear prohibitions against the promotion, glorification, or instructional dissemination of such harmful activities, while allowing for the safe sharing of personal experiences. The document emphasizes intervention strategies, including the removal of harmful content and the provision of local support resources, with potential escalation to emergency services if users are deemed to be in imminent danger. This policy underscores a commitment to creating a safe digital environment by balancing user expression with protective measures against self-harm.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the document's focus on preventing harmful content through explicit prohibitions and its supportive approach in offering resources and interventions for users at risk, reflecting a concern for user welfare and mental health.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and physical harm. Psychological harm is evident in the focus on mental health issues such as suicidal thoughts and eating disorders, while physical harm is considered in the context of self-injury and dangerous challenges.

4. **User Assumptions**: The policy assumes that users may be vulnerable to mental health struggles and potentially at risk of engaging in harmful behaviors. It presupposes a need for external regulation and intervention, indicating a belief that users may lack the capacity for self-regulation in these contexts. Additionally, it suggests a responsibility for users to engage with content in a manner that respects the well-being of themselves and others."
3_suicide_disorder_eat_selfharm,TikTok,TikTok_eating_disorders.txt,"1. **Summary**: The policy document primarily aims to inform and guide users on the recognition and management of eating disorders, emphasizing their serious and potentially life-threatening nature. It delineates the scope of eating disorders, including Anorexia Nervosa, Bulimia Nervosa, and others, and underscores the universal susceptibility across demographics. The document seeks to facilitate early intervention by encouraging users to seek help when their relationship with food, exercise, or body image adversely impacts daily life. Additionally, it provides pathways for users to report issues on the platform, thereby integrating user engagement into its safety framework.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive. This is evidenced by its emphasis on the availability of help and recovery, as well as its inclusive language that acknowledges the broad spectrum of individuals who may be affected by eating disorders, thereby fostering a sense of community and understanding.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on the mental health aspects of eating disorders and their impact on users' daily functioning and well-being.

4. **User Assumptions**: The document assumes users may lack awareness of the severity of their condition or the need for intervention, as it provides detailed descriptions of eating disorders and signs that warrant seeking help. It also presupposes a level of vulnerability among users, given the emphasis on the potential for eating disorders to affect anyone, regardless of external appearances. Furthermore, it implies a responsibility on the part of users to engage with the platform's reporting mechanisms to address issues related to eating disorders."
3_suicide_disorder_eat_selfharm,Instagram,Instagram_content_reccomendations.txt,"**Summary**: The policy document outlines Instagram's approach to content recommendations, aiming to enhance user experience by suggesting relevant and valuable content through personalized algorithms. It establishes a regulatory framework that sets higher standards for recommended content compared to general community standards, specifically to prevent exposure to low-quality, objectionable, or sensitive material. The document emphasizes the use of technology to enforce these guidelines, thereby ensuring that recommendations do not include inappropriate content, particularly for younger audiences. The policy's primary objective is to safeguard users from potentially harmful content while fostering community engagement.

**Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on avoiding low-quality and sensitive content in recommendations and the proactive use of technology to enforce guidelines, reflecting a commitment to user safety and well-being.

**Types of Harm Addressed**: The policy primarily addresses psychological harm by aiming to prevent exposure to objectionable or sensitive content that could negatively impact users' mental health. Additionally, it implicitly considers reputational harm by maintaining high standards for recommended content, thereby protecting users from potentially damaging associations.

**User Assumptions**: The document assumes that users are diverse in their interests and interactions, necessitating personalized recommendations. It also presupposes a degree of user vulnerability, particularly among younger audiences, who may be more susceptible to inappropriate content. Furthermore, there is an implicit expectation that users rely on the platform to curate safe and relevant content, indicating a limited capacity for self-regulation in navigating potentially harmful material."
3_suicide_disorder_eat_selfharm,Instagram,Instagram_suicide_and_self-injury.txt,"1. **Summary**: The policy document primarily aims to provide immediate guidance and resources for individuals experiencing suicidal thoughts or self-injury tendencies, emphasizing the importance of contacting emergency services in acute situations. It outlines supportive interventions, such as reaching out to trusted individuals and utilizing helplines, while also advocating for the use of personalized ""Safety Plans"" developed with professional assistance. The regulatory scope is focused on preventing psychological harm by promoting safe online communication practices, particularly for youth, as informed by Orygen's guidelines. The document seeks to empower users with actionable strategies to manage distress triggered by online content.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its empathetic language and emphasis on providing practical resources and emotional support. The document prioritizes user well-being by encouraging communication with trusted individuals and professionals, reflecting a compassionate approach to addressing self-harm and suicidal ideation.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, focusing on mitigating the impact of suicidal thoughts and self-injury. It also implicitly considers the potential for physical harm given the context of self-injury and suicide.

4. **User Assumptions**: The document assumes users may be vulnerable to psychological distress and may lack immediate self-regulation capabilities in crisis situations. It presumes a level of responsibility among users to seek help and utilize available resources, such as helplines and safety plans, to manage their mental health proactively. Additionally, it assumes users have access to trusted individuals and professional support systems."
3_suicide_disorder_eat_selfharm,Meta,Meta_Suicide_and_self-injury.txt,"1. **Summary**: The policy document articulates Facebook's commitment to safeguarding users from content related to suicide, self-injury, and eating disorders by prohibiting the promotion or celebration of such behaviors while permitting discussions aimed at awareness and support. The regulatory scope encompasses the removal of content that encourages harmful behaviors or mocks affected individuals, with particular attention to graphic depictions and real-time incidents. The platform collaborates with experts and global organizations to inform policy and provide assistance to distressed users. Interventions include sensitivity screens for potentially upsetting recovery content, balancing user safety with the facilitation of supportive discourse.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the platform's emphasis on collaboration with experts, the removal of harmful content, and the allowance of discussions that foster awareness and support, reflecting a dual focus on harm prevention and user empowerment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it pertains to the mental health implications of suicide, self-injury, and eating disorders. It also implicitly considers reputational harm by removing content that mocks victims or survivors.

4. **User Assumptions**: The policy assumes users may be vulnerable to psychological distress and potentially influenced by harmful content, necessitating protective measures. It also presumes users have the capacity to engage in supportive discussions and seek assistance, indicating an expectation of responsible engagement within the community."
3_suicide_disorder_eat_selfharm,YouTube,YouTube_suicide_and_self-harm_guide.txt,"1. **Summary**: The policy document outlines YouTube's implementation of crisis resource panels designed to provide immediate support to users engaging with content related to suicide, self-harm, or eating disorders. These panels appear during video playback or search queries on sensitive topics, offering direct links to professional crisis services. The primary objective is to facilitate timely intervention by connecting users with appropriate resources, thereby mitigating potential psychological harm. The policy emphasizes the non-dismissible nature of these panels, underscoring a commitment to user safety and proactive harm reduction.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the language used to describe the crisis resource panels as tools for immediate assistance and the emphasis on connecting users with professional help. The policy's focus on providing ""helpful and timely"" information further reinforces its supportive nature.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on issues related to suicide, self-harm, and eating disorders, which are inherently linked to mental health crises.

4. **User Assumptions**: The policy assumes that users may be at risk of experiencing emotional distress or mental health crises, necessitating external intervention. It presumes a lack of capacity for self-regulation in critical moments, thereby justifying the non-dismissible nature of the crisis panels. Additionally, it implies a responsibility on the part of the platform to ensure user safety by facilitating access to professional support services."
3_suicide_disorder_eat_selfharm,Hinge,Hinge_self-harm.txt,"1. **Summary**: The policy document primarily aims to provide guidance for users concerned about the safety of others, particularly in situations involving emotional distress or suicidal ideation. It delineates a regulatory framework that emphasizes immediate intervention through local law enforcement and offers resources for emotional support via established helplines. The document seeks to facilitate user intervention by directing them to appropriate crisis resources, both domestically and internationally. It also provides a mechanism for users to report safety concerns directly to the platform, thereby integrating community vigilance into its safety governance model.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the language used to encourage users to seek help and offer support, emphasizing the availability of resources and guidance for those in distress. The policyâ€™s focus on providing contact information for crisis intervention services further underscores its supportive nature, aiming to empower users to take proactive steps in safeguarding themselves and others.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly focusing on emotional distress and suicidal ideation. It implicitly acknowledges the potential for physical harm by advising contact with law enforcement in situations of immediate danger.

4. **User Assumptions**: The document assumes that users may encounter situations involving individuals at risk of self-harm or suicide and possess the capacity to recognize such distress. It presupposes a level of responsibility among users to act upon these concerns by contacting appropriate authorities or utilizing provided resources. Additionally, it implies that users have the ability to navigate and access external support systems, both locally and internationally."
3_suicide_disorder_eat_selfharm,Facebook Messenger,Facebook_Messenger_suicide_and_self-harm.txt,"**Summary**: The policy document primarily aims to provide support and intervention for users experiencing suicidal ideation, self-injury, and eating disorders, emphasizing immediate and accessible resources. It delineates a regulatory scope that includes partnerships with expert organizations and offers a comprehensive list of helplines and online support options. The document's objectives are to facilitate user engagement with professional help and encourage communication with trusted individuals. It seeks to empower users by providing information and resources to mitigate psychological harm.

**Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its emphasis on providing resources, encouraging communication with trusted individuals, and offering direct links to professional help. The language used is empathetic and reassuring, aiming to guide users towards seeking assistance in a non-judgmental manner.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm, focusing on mental health issues such as suicidal thoughts, self-injury, and eating disorders.

**User Assumptions**: The document assumes that users may be experiencing significant emotional distress and may lack immediate access to professional support. It presumes a level of vulnerability and a need for external intervention, while also assuming users have the capacity to reach out for help and communicate their needs to trusted individuals. The policy implicitly expects users to take proactive steps in seeking assistance and utilizing the resources provided."
3_suicide_disorder_eat_selfharm,Facebook,Facebook_Suicide_and_self-injury_resources.txt,"1. **Summary**: The policy document primarily aims to provide guidance and resources for individuals experiencing suicidal thoughts, self-injury, or eating disorders, emphasizing immediate intervention and support. It outlines a regulatory framework that connects users with local and international helplines and expert organizations, thereby facilitating access to professional assistance. The document underscores the importance of reaching out to trusted individuals, such as family or counselors, to share personal struggles and seek support. The policy's scope is preventative, focusing on mitigating psychological harm by promoting proactive engagement with available resources and support networks.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the document's emphasis on providing resources and encouraging users to seek help from trusted individuals and professional organizations, rather than imposing punitive measures or authoritative directives.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, particularly in the context of suicidal ideation, self-injury, and eating disorders. It implicitly acknowledges the potential for physical harm associated with these conditions.

4. **User Assumptions**: The document assumes users may be experiencing significant psychological distress and may lack immediate access to support systems. It presumes a degree of user vulnerability and emphasizes the importance of self-regulation through seeking help. The policy also assumes users have the capacity to reach out to trusted individuals or organizations for support, highlighting an expectation of proactive engagement in managing their well-being."
3_suicide_disorder_eat_selfharm,Discord,Discord_Suicide_and_Self-harm.txt,"**Summary**: The policy document from Discord delineates its commitment to fostering a secure online environment by explicitly prohibiting the coordination, encouragement, or glorification of suicide and self-harm behaviors. Its regulatory scope includes the prevention of content that promotes or normalizes self-harm, with a focus on maintaining a supportive community atmosphere. The policy aims to intervene by disallowing the sharing of methods or advice related to self-harm and discouraging behaviors that could trigger self-harm responses in others. The document underscores the importance of users feeling safe and supported, thereby emphasizing community well-being.

**Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on creating a ""positive and healthy environment"" and the proactive measures outlined to prevent the normalization of self-harm behaviors, reflecting a focus on community support and harm prevention.

**Types of Harm Addressed**: The policy explicitly addresses psychological and physical harm, as it focuses on preventing self-harm and suicide, which are inherently linked to mental health and physical well-being.

**User Assumptions**: The policy assumes that users may be at risk of engaging in or being influenced by self-harm behaviors, necessitating a regulatory framework to mitigate these risks. It presumes a level of vulnerability among users, highlighting the need for a supportive community, and implies a responsibility on users to avoid sharing harmful content and to engage in positive interactions."
4_service_term_use_agreement,YouTube,YouTube_Terms_of_Service.txt,"1. **Summary**: The document delineates the Terms of Service for YouTube, outlining the regulatory framework governing user interactions and content management on the platform. It establishes the legal relationship between YouTube and its users, specifying eligibility criteria, usage rights, and conditions under which the service may be altered. The policy emphasizes user responsibilities in content creation, particularly regarding intellectual property rights and conduct that may lead to account suspension or termination. The document aims to ensure compliance with legal standards and community guidelines, thereby mitigating potential harms associated with user-generated content.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the formal and prescriptive language used to define user obligations, rights, and the platform's regulatory mechanisms, reflecting a top-down approach to governance and compliance.

3. **Types of Harm Addressed**: The policy substantively addresses reputational harm and privacy concerns. It emphasizes the importance of respecting intellectual property rights and user conduct, which are critical in preventing reputational damage and ensuring privacy protection.

4. **User Assumptions**: The document assumes that users possess a basic understanding of legal and community standards, with the capacity to adhere to intellectual property laws and conduct guidelines. It presupposes a level of self-regulation and responsibility in content creation and interaction, while also acknowledging the potential for non-compliance, thereby justifying the inclusion of punitive measures such as account suspension and termination."
4_service_term_use_agreement,Hinge,Hinge_sharing_across_Match.txt,"1. **Summary**: The document outlines the regulatory framework governing the sharing of user information across Match Group companies, primarily to enhance operational efficiency and user safety. It aims to facilitate daily business functions such as data hosting, customer support, and fraud prevention, while also prioritizing user safety through information sharing to combat harmful behaviours and potential discrimination. The policy emphasizes collaboration with law enforcement to address illegal activities and prevent physical harm. Additionally, it seeks to personalize user experiences in compliance with applicable legal standards.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it delineates the structured processes and justifications for data sharing within the company group. This tone is reinforced by the document's emphasis on regulatory compliance, operational necessity, and the proactive measures taken to ensure user safety and service integrity.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (through combating spam and abuse), physical harm (by preventing death or bodily harm), reputational harm (through actions against fake accounts), and economic harm (by fighting fraud). It also implicitly addresses identity-based harm by aiming to prevent discrimination or bias.

4. **User Assumptions**: The document assumes that users may be vulnerable to various digital harms, such as fraud and abuse, and that they rely on the platform to mitigate these risks. It presumes a limited capacity for self-regulation among users, necessitating the platform's intervention. Additionally, there is an expectation that users are responsible for engaging with the platform in a manner that does not contravene legal or community standards."
4_service_term_use_agreement,Quora,Quora_Terms_of_Service.txt,"**Summary**: The Quora Terms of Service document delineates the regulatory framework governing user interactions on its platform, emphasizing user consent and adherence to its policies. The document's primary objective is to establish a legal agreement that outlines the conditions under which users may access and utilize Quora's services, with particular attention to age restrictions and parental responsibilities. It further incorporates a binding arbitration clause for dispute resolution, specifically targeting users in the United States and Canada, thereby precluding class action lawsuits. The policy underscores the importance of compliance with its Privacy Policy and Acceptable Use Policy, thereby framing user engagement within a structured governance model.

**Tone**: The rhetorical tone of the document is predominantly authoritative, as evidenced by the formal and legalistic language used to assert the binding nature of the terms and the explicit delineation of user responsibilities and restrictions. This authoritative tone is further reinforced by the arbitration clause, which underscores the platform's control over dispute resolution processes.

**Types of Harm Addressed**: The policy implicitly addresses reputational and privacy harms by mandating adherence to its Privacy Policy and Acceptable Use Policy, which typically encompass guidelines to protect user data and maintain a respectful community environment.

**User Assumptions**: The document assumes users possess a basic level of legal comprehension sufficient to understand and consent to the terms, including the arbitration clause. It presumes that users are capable of self-regulation in adhering to the platform's policies and that parents or guardians will assume responsibility for minors' use of the platform, reflecting an assumption of user accountability and legal capacity."
4_service_term_use_agreement,WhatsApp,WhatsApp_Terms_of_Service.txt,"1. **Summary**: The WhatsApp Terms of Service document primarily aims to establish a regulatory framework for the use of its services, emphasizing privacy and security as foundational principles. It delineates the scope of acceptable use, outlines user responsibilities, and provides mechanisms for reporting intellectual property infringements. The policy seeks to mitigate various forms of digital harm by setting clear guidelines for user conduct and offering dispute resolution processes. Furthermore, it specifies regional variations in service provision, particularly for users in the European Region, reflecting compliance with international legal standards.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as evidenced by its formal language and structured presentation of rules and obligations. This is reinforced by the explicit requirement for user agreement to the terms and the detailed provisions for liability and dispute resolution, underscoring a legalistic and regulatory approach.

3. **Types of Harm Addressed**: The policy explicitly addresses privacy-related harm through its emphasis on privacy and security principles. It also implicitly touches upon reputational harm by including provisions for reporting intellectual property infringements, which can affect users' or third parties' reputations.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation and are responsible for adhering to the terms set forth. It presumes a level of digital literacy sufficient to understand and comply with privacy and security guidelines, as well as the ability to engage with dispute resolution processes. Additionally, it suggests that users are expected to actively report violations, indicating an assumption of proactive engagement in maintaining the platform's integrity."
4_service_term_use_agreement,Call of Duty HQ,COD_software_license_and_service_agreement.txt,"1. **Summary**: The document serves as a comprehensive software license and service agreement, delineating the terms under which users may access and utilize the software and associated services provided by Activision. Its primary regulatory objective is to establish binding legal terms, including arbitration clauses and class action waivers, particularly for North American users, thereby framing user interactions within a legally enforceable structure. The policy seeks to mitigate potential disputes and ensure compliance through explicit consent mechanisms, such as the ""click to accept"" requirement. It also outlines the conditions under which users may reject the agreement and seek refunds, emphasizing user awareness and informed consent.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the formal and legalistic language employed throughout the document. The use of imperative verbs and legal jargon underscores the binding nature of the agreement, conveying a sense of obligation and compliance expected from the users.

3. **Types of Harm Addressed**: The policy implicitly addresses economic harm by detailing refund procedures and legal recourse, as well as privacy concerns through the regulation of software usage and data handling.

4. **User Assumptions**: The document assumes users possess the capacity for informed consent and self-regulation, as it requires them to affirm their legal age of majority and agree to the terms through active acceptance. It also presumes a baseline level of legal literacy and responsibility, expecting users to understand and adhere to the contractual obligations set forth."
4_service_term_use_agreement,Reddit,Reddit_User_Agreement.txt,"**Summary**: The Reddit User Agreement delineates the regulatory framework governing user interactions on its platform, emphasizing adherence to a set of standardized terms to facilitate safe and enjoyable community engagement. The document primarily aims to establish clear guidelines for access and usage, particularly highlighting age restrictions and regional legal compliance. It seeks to mitigate potential harms by instituting basic rules that users must agree to, thereby fostering a controlled environment conducive to entertainment and community building. The policy underscores the necessity of user consent to these terms as a prerequisite for platform access, thereby aligning user behavior with Reddit's operational standards.

**Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the clear stipulations and non-negotiable terms set forth for accessing and using Reddit's services. The language is directive, with an emphasis on compliance and adherence to established rules, reflecting a top-down approach to governance and user management.

**Types of Harm Addressed**: The policy implicitly addresses psychological and reputational harm by setting age restrictions and requiring adherence to community guidelines, which aim to protect users from inappropriate content and interactions. Additionally, privacy concerns are addressed through the regulation of access and use, ensuring that users are aware of the terms governing their data and interactions on the platform.

**User Assumptions**: The document assumes users possess the capacity for self-regulation and are capable of understanding and consenting to the terms of use. It presupposes a baseline level of digital literacy and legal awareness, particularly regarding age requirements and regional legal variations. The policy also implies a responsibility on the part of users to engage with the platform in a manner that aligns with its entertainment-focused purpose, thus placing the onus on users to navigate and adhere to the established guidelines."
4_service_term_use_agreement,Google Messages,Google_Messages_Terms_of_service.txt,"1. **Summary**: The Google Terms of Service document delineates the regulatory framework governing user interactions with Google services, emphasizing mutual expectations and legal compliance. It aims to clarify the obligations of both Google and its users, particularly in terms of service provision, user conduct, and content ownership. The policy seeks to preemptively address potential disputes by outlining legal recourses and user rights in case of term violations. Additionally, it encourages users to consult the Privacy Policy for comprehensive understanding of data management practices.

2. **Tone**: The rhetorical tone of the policy is predominantly authoritative, as it establishes clear expectations and legal obligations between Google and its users. This is evidenced by the structured delineation of rights and responsibilities, and the emphasis on compliance with legal standards.

3. **Types of Harm Addressed**: The policy substantively addresses reputational and privacy harms. It implicitly considers reputational harm through its focus on intellectual property rights and content management, while privacy harm is addressed through the encouragement to review the Privacy Policy.

4. **User Assumptions**: The document assumes users possess a basic capacity for self-regulation and responsibility in adhering to the established terms. It presumes users are capable of understanding legal obligations and are motivated to protect their own privacy and intellectual property rights. Additionally, it suggests a level of user engagement with legal documents, as it encourages downloading and reviewing the terms and related privacy policies."
4_service_term_use_agreement,Bumble,Bumble_terms_and_conditions.txt,"**Summary**: The Bumble Terms and Conditions of Use document serves as a contractual framework delineating the rights and obligations of users and the Bumble Group, with a focus on ensuring informed consent prior to the utilization of Bumble's digital services. The regulatory scope encompasses subscription renewals, dispute resolution mechanisms, and adherence to community guidelines, emphasizing user compliance and awareness. The document aims to mitigate potential legal conflicts through arbitration clauses, while also providing users with opt-out provisions to maintain autonomy over dispute resolution processes. The policy underscores the importance of user engagement with the terms to preemptively address potential misunderstandings or misuse of the platform.

**Tone**: The rhetorical tone of the document is predominantly authoritative, as it establishes a formal contractual relationship between the user and the platform, emphasizing legal obligations and procedural compliance. This is evidenced by the explicit instructions for users to read and adhere to the terms, alongside the structured presentation of legal consequences and arbitration processes.

**Types of Harm Addressed**: The policy explicitly addresses potential legal and economic harm through its focus on subscription renewals and dispute resolution. It implicitly acknowledges reputational and identity-based harm by referencing community guidelines and privacy policies, which are integral to maintaining a safe and respectful user environment.

**User Assumptions**: The document assumes that users possess the capacity for self-regulation and are responsible for understanding and adhering to the terms outlined. It presupposes a level of user engagement and diligence in reviewing contractual obligations, as well as an awareness of their rights to opt out of arbitration agreements. The policy also implies a degree of vulnerability to legal and economic risks, necessitating clear communication of subscription and dispute resolution terms."
4_service_term_use_agreement,Reddit,Reddit_Developer_Terms.txt,"**Summary**: The Reddit Developer Terms document primarily aims to establish a regulatory framework governing the use of Redditâ€™s Developer Services, including APIs, SDKs, and related software tools. It delineates the contractual obligations and conditions under which developers may interact with Redditâ€™s platform and user-generated content, thereby ensuring compliance with Redditâ€™s broader User Agreement. The policy is designed to facilitate safe and responsible integration of third-party applications with Redditâ€™s services, emphasizing adherence to specified guidelines and terms. The document serves as a binding agreement that developers must accept to access these services, thereby promoting a controlled and secure digital environment.

**Tone**: The rhetorical tone of the document is predominantly authoritative. This is evidenced by the formal and directive language used to outline the terms and conditions, emphasizing compliance and the binding nature of the agreement. The documentâ€™s language underscores the necessity for developers to adhere strictly to the stipulated guidelines, reflecting a governance-focused approach.

**Types of Harm Addressed**: The policy implicitly addresses potential privacy and reputational harms. By regulating how developers can interact with user content and data, the document seeks to prevent unauthorized access and misuse that could compromise user privacy or damage reputations.

**User Assumptions**: The document assumes that users, specifically developers, possess a baseline understanding of digital governance and the technical capacity to comply with complex service agreements. It presupposes a responsibility on the part of developers to self-regulate in accordance with the terms, suggesting a level of professional competence and ethical obligation to safeguard user interactions and data integrity."
4_service_term_use_agreement,TikTok,TikTok_Terms_of_Service.txt,"1. **Summary**: The TikTok Terms of Service document delineates the contractual agreement between the user and TikTok, specifically targeting users residing in the European Economic Area, Switzerland, and the UK. Its primary regulatory objective is to establish a legal framework that governs the use of the platform, emphasizing the binding nature of the agreement upon acceptance or use of the service. The policy aims to ensure users are informed of their rights and obligations, as well as the additional policies that complement these terms, such as the Privacy Policy and Community Guidelines. The document seeks to preemptively address potential disputes by clearly outlining the jurisdictional and corporate entities involved in the contractual relationship.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the formal and legalistic language used to establish the binding nature of the contract, as well as the emphasis on the necessity for users to read and understand the terms to ensure compliance.

3. **Types of Harm Addressed**: The document implicitly addresses potential privacy harms by referencing the Privacy Policy, which is part of the broader contractual agreement. Although specific harms are not detailed within the excerpt, the inclusion of privacy considerations suggests an awareness of the need to protect user data and personal information.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and the responsibility to familiarize themselves with the terms and accompanying policies. It presumes a level of legal literacy and comprehension necessary to understand the implications of entering into a contractual agreement with TikTok. Additionally, it implies that users are aware of their jurisdictional context, which determines the specific corporate entity they are contracting with."
5_sexual_consent_explicit_content,Reddit,Reddit_non-consensual_sharing.txt,"1. **Summary**: The policy document primarily aims to mitigate the unauthorized sharing of intimate images by outlining procedures for reporting such content on Reddit. It delineates the regulatory scope by prohibiting non-consensual distribution of sexually explicit material, including deepfakes and creepshots, under Redditâ€™s Content Policy. The document provides detailed user interventions, such as reporting mechanisms and additional support through external tools like StopNCII.org. This policy underscores Reddit's commitment to safeguarding user privacy and dignity by facilitating the removal of harmful content and offering support to affected individuals.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the clear instructions provided for users to report violations and the emphasis on external resources available for further assistance, indicating a focus on preventing harm and supporting victims rather than punishing perpetrators.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual, psychological, and privacy-related harms. It recognizes the potential for significant distress and privacy invasion resulting from the non-consensual distribution of intimate images.

4. **User Assumptions**: The policy assumes that users may be vulnerable to non-consensual exposure of intimate content, necessitating a structured reporting mechanism. It also presumes users possess the capacity for self-regulation in identifying and reporting harmful content, while expecting them to take responsibility for utilizing available tools to protect their privacy and well-being."
5_sexual_consent_explicit_content,Bumble,Bumble_nudity.txt,"1. **Summary**: The policy document delineates Bumble's regulatory framework concerning adult nudity and sexual activity, aiming to balance user self-expression with community safety standards. It permits users to express romantic or sexual intentions within legal and community guidelines and engage in consensual sexual conversations in private messages. The policy explicitly prohibits certain explicit content in profile photos and links, including nudity and sexual acts, to mitigate potential harm. The document seeks to foster a respectful and inclusive environment while preventing the dissemination of inappropriate content.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it seeks to preemptively address potential issues related to explicit content by setting clear boundaries and guidelines. This is evidenced by the detailed enumeration of prohibited content and the emphasis on legality and consent in user interactions.

3. **Types of Harm Addressed**: The policy primarily addresses sexual and reputational harm by restricting explicit content that could lead to unwanted exposure or misrepresentation. It also implicitly considers psychological harm by promoting consensual and respectful interactions.

4. **User Assumptions**: The policy assumes that users have the capacity for self-regulation and are responsible for ensuring their interactions are consensual and lawful. It also presumes a level of vulnerability among users, necessitating protective measures against exposure to inappropriate content."
5_sexual_consent_explicit_content,Discord,Discord_Sexual_Content.txt,"**Summary**: The Discord Sexual Content Policy aims to regulate the dissemination of sexually explicit and suggestive content on its platform, ensuring that such material is restricted to users aged 18 and over and confined to designated ""age-restricted"" spaces. The policy seeks to balance the freedom of expression for adult users with the protection of younger users from inappropriate content, thereby maintaining a safe digital environment. By defining and categorizing sexual content, the policy delineates clear boundaries for permissible content sharing and access. This regulatory framework is designed to prevent exposure to potentially harmful material while accommodating diverse user preferences.

**Tone**: The dominant rhetorical tone of the policy is preventative, as it emphasizes the need to safeguard users, particularly minors, from exposure to inappropriate content. This is evidenced by the policy's focus on restrictions and age limitations, aiming to preemptively mitigate risks associated with sexually explicit material.

**Types of Harm Addressed**: The policy primarily addresses sexual and psychological harm, as it seeks to prevent the exposure of inappropriate sexual content to minors and protect users from potentially distressing material.

**User Assumptions**: The policy assumes that adult users have the capacity for self-regulation and responsibility in accessing and sharing sexual content, while younger users are viewed as vulnerable and in need of protection from such material. It also presupposes that users can comprehend and adhere to the platform's content guidelines, thereby contributing to a safe online community."
5_sexual_consent_explicit_content,Badoo,Badoo_sexual_harassment.txt,"1. **Summary**: The policy document from Badoo outlines a comprehensive framework aimed at preventing sexual harassment within its community, emphasizing the prohibition of non-physical, unwanted sexual behaviors. It seeks to regulate user interactions by defining and disallowing actions such as cyberflashing, non-consensual sharing of intimate images, and unwanted sexual comments. The policy extends its regulatory scope beyond the platform itself, indicating that off-platform behaviors may also be subject to enforcement actions. The document encourages users to engage with the platform's enforcement mechanisms if they believe an error has been made in account or content moderation.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the clear delineation of prohibited behaviors and the emphasis on the platform's commitment to taking action against violations, both on and off the platform, to protect users from harm.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual harm, psychological harm, and reputational harm. It highlights the impact of unwanted sexual behaviors, the psychological distress caused by such actions, and the potential reputational damage from non-consensual sharing of intimate content.

4. **User Assumptions**: The policy assumes that users may engage in risky or harmful behaviors, either intentionally or unintentionally, and thus necessitates clear guidelines to mitigate these risks. It presupposes a level of user vulnerability to sexual harassment and positions users as responsible for adhering to community standards, with an expectation of accountability for their actions both on and off the platform."
5_sexual_consent_explicit_content,Telegram,Telegram_User_guidance_for_the_EU_Digital_Services_Act.txt,"1. **Summary**: The policy document under review delineates a regulatory framework aimed at mitigating digital harms associated with illegal sexual content, as part of broader compliance with the Digital Services Act. Its primary objectives include the prevention of the dissemination of illegal sexual content and the promotion of safe online environments by enforcing strict content moderation practices. The document outlines specific interventions to identify and remove content that is illegal in most jurisdictions, thereby aligning platform governance with international legal standards. This regulatory scope is designed to protect users from exposure to harmful content and to uphold the platform's legal obligations.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the firm language used to describe the enforcement of content moderation practices and the alignment with international legal standards, indicating a top-down approach to governance and compliance.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual harm, as it focuses on the regulation of illegal sexual content. Additionally, it implicitly addresses psychological and reputational harm by aiming to prevent users' exposure to and involvement with such content.

4. **User Assumptions**: The policy assumes that users may inadvertently or deliberately engage with illegal sexual content, necessitating stringent content moderation to mitigate risks. It presupposes a lack of user capacity for self-regulation in distinguishing legal from illegal content, thereby placing responsibility on the platform to enforce compliance and protect user safety."
5_sexual_consent_explicit_content,TikTok,TikTok_sexual_abuse_support.txt,"1. **Summary**: The policy document from TikTok's Safety Center articulates a rigorous regulatory framework aimed at preventing and addressing sexual abuse on the platform, including both real and AI-generated content. It explicitly prohibits non-consensual sexual acts, image-based sexual abuse, sextortion, sexual harassment, child sexual abuse material (CSAM), and grooming. The policy emphasizes user intervention by encouraging the reporting of any content that violates these standards, particularly highlighting the severe prohibition of CSAM. The document underscores TikTok's commitment to fostering a safe community environment by actively involving users in the identification and reporting of harmful content.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This is evidenced by the clear and firm prohibition of specific harmful behaviors and content types, as well as the directive language used to instruct users on how to report violations, reflecting a strong institutional stance on maintaining community safety.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual harm, psychological harm, and reputational harm. It also implicitly touches on identity-based harm through its focus on non-consensual acts and harassment.

4. **User Assumptions**: The document assumes users possess the capacity for vigilance and responsibility in identifying and reporting harmful content. It presupposes a level of user awareness and engagement necessary to maintain platform safety, while also acknowledging the potential vulnerability of users, particularly minors, to sexual exploitation and abuse."
5_sexual_consent_explicit_content,Snapchat,Snapchat_adult_content_advertising.txt,"1. **Summary**: The policy document primarily aims to regulate the advertisement of adult content on digital platforms, ensuring compliance with local laws and cultural norms that may exceed the platform's general guidelines. It delineates specific conditions under which adult content may be permissible, focusing on contexts that do not intend to provoke sexual arousal, such as health or educational purposes. The document seeks to balance user safety and transparency by categorically defining acceptable and prohibited content, thereby guiding advertisers in aligning their materials with the platform's standards. This regulatory framework is designed to mitigate potential harms associated with inappropriate sexual content while maintaining a respectful digital environment.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it prescribes explicit guidelines and conditions under which adult content may be advertised. This is evidenced by the use of definitive language such as ""must respect"" and ""conditionally allow,"" which underscores the platform's regulatory authority and commitment to upholding stringent content standards.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual harm by regulating the depiction and reference of sexual organs and activity. It also implicitly considers psychological and reputational harm by ensuring that content adheres to cultural norms and does not provoke unwanted sexual arousal, which could lead to discomfort or reputational damage for users.

4. **User Assumptions**: The policy assumes that users are potentially vulnerable to inappropriate sexual content and may lack the capacity for self-regulation in distinguishing between acceptable and harmful material. It also presumes a responsibility on the part of advertisers to understand and adhere to both the platform's guidelines and the cultural norms of their target audience, thereby safeguarding users from exposure to unsuitable content."
5_sexual_consent_explicit_content,Discord,Discord_Non-Consensual_Adult_Intimate.txt,"1. **Summary**: The policy document from Discord outlines a stringent regulatory framework aimed at preventing the non-consensual sharing and distribution of adult intimate media. It seeks to protect individuals from the unauthorized dissemination of sexually explicit content, whether obtained with or without consent, by enforcing content removal and addressing threats of distribution under their Threats Policy. The document emphasizes the removal of confirmed instances of such content to mitigate harm and prevent further proliferation. It also addresses specific scenarios such as ""revenge porn,"" ""creepshots,"" and ""deepfakes,"" highlighting the platform's commitment to safeguarding user privacy and dignity.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the firm language used to describe the platform's stance against non-consensual media sharing and the clear articulation of enforcement actions, such as content removal and threat management, which underscore the platform's commitment to user protection and regulatory compliance.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual, psychological, reputational, and privacy harms. It identifies the non-consensual distribution of intimate media as a violation that can lead to significant emotional distress, reputational damage, and breaches of personal privacy.

4. **User Assumptions**: The policy assumes users may be vulnerable to non-consensual media distribution and may lack control over their intimate content once shared. It presumes a need for platform intervention to protect users from exploitation and acknowledges the potential for malicious behavior, such as sextortion, indicating an expectation of user responsibility in reporting violations while emphasizing the platform's role in enforcement."
5_sexual_consent_explicit_content,Badoo,Badoo_explicit_photo.txt,"1. **Summary**: The policy document aims to regulate the dissemination of unsolicited or non-consensual sexual content on the platform, focusing on user protection and empowerment. It establishes a mechanism for blurring explicit images and provides users with options to either view or report such content, thereby promoting informed user intervention. The policy underscores the platform's commitment to investigating reports of non-consensual content, reflecting a proactive stance on user safety. By offering support channels, the document seeks to reinforce a supportive environment for users encountering digital harm.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the language that emphasizes user protection, choice, and assistance. The policy's phrasing, such as ""We want to protect you"" and ""Weâ€™re here if you need us,"" underscores a commitment to user welfare and a readiness to provide help.

3. **Types of Harm Addressed**: The policy explicitly addresses sexual harm by focusing on unsolicited sexual content. It also implicitly considers psychological harm, as the receipt of non-consensual explicit material can cause distress and discomfort to users.

4. **User Assumptions**: The document assumes that users may be vulnerable to receiving unsolicited explicit content and may require guidance in managing such situations. It presupposes a level of user responsibility in choosing to view or report content, indicating an expectation of user engagement in maintaining their own digital safety. Additionally, it implies that users have the capacity to utilize platform tools for blocking and reporting harmful interactions."
5_sexual_consent_explicit_content,Meta,Meta_sextortion_tips.txt,"**Summary**: The document primarily aims to provide guidance and resources to users experiencing sextortion, a form of digital blackmail involving threats to expose sexual images. It outlines a regulatory framework focused on user empowerment and harm prevention, emphasizing the importance of non-cooperation with perpetrators and seeking support. The policy's objectives include offering practical steps for users to regain control, encouraging communication with trusted individuals, and facilitating reporting to relevant authorities. By promoting access to crisis support resources, the document seeks to mitigate the psychological and reputational harms associated with sextortion.

**Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on user empowerment, reassurance, and the provision of resources and guidance to prevent further harm, as well as the collaborative language suggesting collective action against sextortion.

**Types of Harm Addressed**: The policy explicitly addresses psychological and reputational harm. Psychological harm is implied through the focus on crisis support and emotional reassurance, while reputational harm is inherent in the threat of exposing sexual images.

**User Assumptions**: The document assumes users are vulnerable to manipulation and coercion but capable of taking proactive measures to protect themselves. It presumes a level of user responsibility in seeking help and reporting incidents, while also acknowledging potential discomfort in discussing such issues with familiar individuals."
6_post_account_report_violation,X,X_How_X_handles_abuse_and_harassment.txt,"1. **Summary**: The policy document primarily aims to delineate the boundaries of acceptable user conduct on the platform, specifically prohibiting abuse and harassment. It establishes a regulatory framework that seeks to prevent and mitigate harm by outlining clear behavioral expectations and consequences for violations. The document emphasizes user interventions such as reporting mechanisms and encourages community participation in maintaining a safe digital environment. The overarching objective is to foster a platform where users can freely express themselves without fear of targeted abuse or harassment.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates prohibited behaviors and underscores the platform's commitment to enforcing these rules. This is evidenced by the direct language used in prohibiting specific actions and the emphasis on the platform's mission to empower safe and constructive user interactions.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and reputational harm, as it focuses on abuse and harassment, which can significantly impact users' mental well-being and public perception.

4. **User Assumptions**: The document assumes that users possess a basic understanding of acceptable online behavior and the capacity to adhere to community guidelines. It also presumes a level of user responsibility in self-regulation and active participation in reporting violations, indicating an expectation of community involvement in upholding platform safety."
6_post_account_report_violation,X,X_enforcement_policy.txt,"1. **Summary**: The policy document delineates the platform's regulatory framework aimed at mitigating digital harm through post-account violation reporting mechanisms. It seeks to balance the facilitation of open dialogue with the enforcement of community standards, emphasizing the need for user engagement in identifying and reporting harmful content. The document outlines a structured approach to policy development and enforcement, underscoring the platform's commitment to addressing offensive, controversial, and bigoted content. It aims to empower users by providing clear guidelines and resources for managing their safety and privacy.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it establishes clear rules and procedures for reporting violations and underscores the platform's commitment to maintaining a safe environment. This is evidenced by the structured presentation of guidelines and the emphasis on enforcement philosophy, which conveys a sense of control and governance.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, reputational, and identity-based harms. It recognizes the potential for offensive and bigoted content to impact users' mental well-being and social standing, and it seeks to mitigate these risks through user reporting and policy enforcement.

4. **User Assumptions**: The document assumes that users possess the capacity to identify and report harmful content, indicating an expectation of user responsibility in maintaining community standards. It also implies a level of vulnerability among users to psychological and reputational harm, necessitating protective measures and resources to support user safety and privacy."
6_post_account_report_violation,X,X_Understanding_how_X_handles_offensive_or_explicit_Posts.txt,"1. **Summary**: The policy document aims to regulate user interactions on the platform by delineating guidelines for reporting and managing offensive content, thereby safeguarding the community from potential harms. It establishes a framework for users to report violations post-account creation, emphasizing the platform's commitment to maintaining a respectful and secure digital environment. The document outlines procedural interventions for addressing offensive content, reflecting a broader regulatory scope that encompasses user-generated content moderation. The policy's objectives are centered on fostering a safer online space by empowering users with tools to report harmful interactions and ensuring compliance with established community standards.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it presents clear guidelines and procedures for users to follow in reporting violations and managing offensive content. This tone is evidenced by the document's structured presentation of rules and the emphasis on compliance with community standards, which underscores the platform's commitment to enforcing its safety policies.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, and privacy concerns. These are evidenced by the focus on managing offensive content that could negatively impact users' mental well-being, damage reputations, and infringe on personal privacy.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and are responsible for identifying and reporting harmful content. It presumes a level of digital literacy and awareness among users, expecting them to actively engage with the platform's reporting mechanisms to uphold community standards. Additionally, there is an implicit assumption of user vulnerability to various forms of digital harm, necessitating the provision of robust safety measures."
6_post_account_report_violation,X,X_reporting_abuse.txt,"1. **Summary**: The policy document primarily aims to establish a framework for users to report abusive behavior on the platform, thereby enhancing user safety and expression freedom. It delineates the procedural scope for reporting, emphasizing ease of use and efficiency in handling multiple incidents within a single report to expedite resolution. The policy seeks to foster a secure digital environment by facilitating user participation in governance through reporting mechanisms. This document underscores the platform's commitment to addressing harmful interactions promptly and effectively.

2. **Tone**: The rhetorical tone of the policy is predominantly preventative and supportive. This is evidenced by the emphasis on user empowerment through simplified reporting processes and the platform's proactive stance in resolving issues swiftly to maintain a safe environment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm and reputational harm. The focus on abusive behavior suggests a concern for the mental well-being of users and the potential damage to their reputations through harmful interactions.

4. **User Assumptions**: The document assumes users possess the capacity to identify and report abusive behavior, suggesting a level of digital literacy and self-regulation. It also implies that users are vulnerable to psychological and reputational harm, necessitating a supportive reporting infrastructure to protect them. Additionally, there is an expectation of user responsibility in contributing to a safer community by actively engaging with the reporting tools provided."
6_post_account_report_violation,X,X_non-consensual_nudity_policy.txt,"**Summary**: The policy document under review delineates the platform's regulatory framework concerning the prohibition of non-consensual sharing of intimate media. Its primary objective is to safeguard users from privacy violations and sexual harm by explicitly prohibiting the dissemination of intimate images or videos without the subject's consent. The policy outlines the platform's commitment to user safety by detailing the mechanisms for reporting violations and the subsequent enforcement actions. This regulatory scope is intended to deter harmful behaviours and provide users with clear avenues for recourse in the event of a breach.

**Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by the unequivocal language used to prohibit specific behaviours and the clear articulation of the consequences for violations. The policy employs definitive statements to establish non-negotiable rules, reflecting a commitment to maintaining a secure and respectful digital environment.

**Types of Harm Addressed**: The policy explicitly addresses sexual and privacy-related harms, focusing on the unauthorized distribution of intimate media that infringes on individuals' privacy rights and can lead to significant personal and reputational damage.

**User Assumptions**: The policy assumes that users possess a basic understanding of consent and the ethical implications of sharing intimate content. It presupposes a level of user responsibility in adhering to platform rules and recognizes the potential vulnerability of individuals to privacy violations, thereby necessitating protective measures and reporting mechanisms."
6_post_account_report_violation,X,X_Perpetrators_of_violent_attacks_policy.txt,"1. **Summary**: The document delineates a policy aimed at the removal of accounts associated with individuals identified as perpetrators of terrorist or violent acts. Its regulatory scope encompasses the proactive identification and elimination of such accounts to mitigate their potential influence and prevent the dissemination of harmful content. The policy is designed to intervene by enforcing account suspension or removal, thereby safeguarding the platform's user community from exposure to violence-related content. The document underscores the platform's commitment to maintaining a secure environment by actively monitoring and regulating user activity that contravenes established safety norms.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the decisive language used in phrases such as ""We will remove any accounts,"" which conveys a firm and non-negotiable stance on the enforcement of the policy, reflecting the platform's commitment to stringent safety measures.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it seeks to protect users from exposure to content associated with violence and terrorism, which can have detrimental psychological effects. Additionally, it implicitly addresses reputational harm by aiming to prevent the platform from being associated with or perceived as a haven for violent content.

4. **User Assumptions**: The policy assumes that users may be vulnerable to exposure to harmful content and that they rely on the platform to enforce safety measures. It also presupposes that users have a responsibility to adhere to community standards and that failure to do so, particularly in the context of violent or terrorist activities, warrants decisive regulatory action."
6_post_account_report_violation,X,X_How_to_help_someone_experiencing_online_abuse.txt,"1. **Summary**: The policy document primarily aims to provide guidance on supporting individuals experiencing online abuse, emphasizing the platform's commitment to user safety and security. It outlines specific interventions users can undertake to assist others, thereby fostering a community-oriented approach to mitigating digital harm. The regulatory scope encompasses both preventative measures and reactive strategies to address instances of abuse effectively. The document underscores the platform's role in facilitating a safer online environment through clear procedural recommendations and user empowerment.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its focus on community assistance and empowerment in addressing online abuse. The language is geared towards encouraging users to take proactive steps in helping others, suggesting a collaborative and empathetic approach to digital safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on the emotional and mental impact of online abuse. Additionally, it implicitly considers reputational harm, given the potential for abuse to affect an individual's public perception and standing.

4. **User Assumptions**: The document assumes that users possess a basic capacity for empathy and a willingness to engage in community support. It presupposes that users are capable of identifying instances of abuse and are motivated to act responsibly to assist those affected. Furthermore, it implies a level of digital literacy necessary for understanding and implementing the recommended interventions."
6_post_account_report_violation,X,X_private_information_policy_and_doxxing.txt,"1. **Summary**: The policy document primarily aims to regulate the dissemination of private information on the platform, delineating clear prohibitions against the unauthorized sharing of personal data. It establishes a framework for user accountability by outlining specific actions that constitute violations, such as threats to expose or incentivizing the exposure of private information. The document seeks to protect users from privacy breaches by implementing strict guidelines and potential penalties for non-compliance. The policy is designed to foster a safer online environment by emphasizing the importance of consent and the protection of personal data.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative. This is evidenced by the explicit prohibitions and the prescriptive nature of the guidelines, which clearly delineate what constitutes a violation and the consequences thereof. The language is direct and unambiguous, reflecting a firm stance on privacy protection and user accountability.

3. **Types of Harm Addressed**: The policy explicitly addresses privacy harm, focusing on the unauthorized exposure of personal information. It implicitly acknowledges potential psychological harm by recognizing the distress that can result from privacy breaches.

4. **User Assumptions**: The document assumes that users have the capacity for self-regulation and are responsible for understanding and adhering to privacy guidelines. It presupposes a level of user awareness regarding the importance of consent and the potential risks associated with sharing private information. Additionally, it implies that users are vulnerable to privacy violations, necessitating protective measures and clear regulatory boundaries."
6_post_account_report_violation,X,X_reporting.txt,"**Summary**: The policy document delineates the procedural framework for users to report violations of platform rules, specifically focusing on posts, lists, and direct messages that contravene established terms of service. Its regulatory scope encompasses a broad spectrum of digital misconduct, including abusive content, spam, impersonation, and intellectual property violations. The document aims to empower users to actively participate in maintaining a safe online environment by providing clear instructions on how to report harmful content. The policy underscores the platform's commitment to upholding community standards and ensuring user safety through user-driven reporting mechanisms.

**Tone**: The dominant rhetorical tone of the policy is authoritative, as it provides definitive guidelines and procedures for reporting violations. This is evidenced by the structured, directive language used to instruct users on how to navigate the reporting process, reflecting a top-down approach to governance and enforcement.

**Types of Harm Addressed**: The policy explicitly addresses psychological harm through abusive content, reputational harm through impersonation, and economic harm through spam and intellectual property violations. It implicitly acknowledges the potential for privacy violations through the misuse of direct messaging.

**User Assumptions**: The policy assumes users possess the capability to identify and report violations, suggesting a level of digital literacy and awareness of platform rules. It presumes users are proactive in safeguarding their online environment and have a responsibility to engage with the platform's safety mechanisms. The document implies a shared responsibility between the platform and its users in maintaining community standards."
6_post_account_report_violation,X,X_abusive_profile_information.txt,"1. **Summary**: The policy document primarily aims to regulate user conduct concerning profile information on the platform, specifically prohibiting the use of usernames, display names, or profile bios for abusive behavior. Its regulatory scope encompasses the prevention of targeted harassment and hate speech directed at individuals or groups, thereby fostering a safer online environment. The document outlines user interventions by delineating clear boundaries for acceptable behavior and providing mechanisms for reporting violations. Through these measures, the platform seeks to mitigate harm and promote respectful interactions among users.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the explicit prohibition of certain behaviors and the establishment of clear rules designed to preemptively curb abusive conduct. The language used is directive, emphasizing compliance and the platform's commitment to maintaining a safe digital space.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological and identity-based harm. It seeks to prevent targeted harassment and hate speech, which can lead to psychological distress and harm to individuals based on their identity or membership in a protected category.

4. **User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviors, necessitating clear guidelines and restrictions. It presupposes a level of user responsibility in adhering to these rules and implies a capacity for self-regulation, while also recognizing the vulnerability of certain groups to identity-based harm."
7_hate_protect_speech_group,Discord,Discord_Hateful_Conduct.txt,"1. **Summary**: The document delineates Discord's regulatory framework aimed at curbing hate speech and fostering an inclusive online environment. It prohibits expressions that degrade or incite hostility towards individuals or groups based on protected characteristics, thereby promoting acceptance and inclusivity. The policy outlines specific interventions, such as banning hate symbols and denying historical atrocities, while allowing exceptions for reclaimed language, satire, and educational content. This regulatory scope underscores Discord's commitment to preventing identity-based harm and maintaining a safe digital space.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as evidenced by its clear prohibitions and definitive language regarding unacceptable behaviors. The document employs firm and unequivocal terms to delineate boundaries of acceptable conduct, reflecting a preventative and regulatory stance.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, psychological harm, and reputational harm. It focuses on preventing expressions that degrade or vilify individuals based on protected characteristics, which can lead to psychological distress and damage to one's social standing.

4. **User Assumptions**: The policy assumes that users may engage in risky behaviors such as hate speech and requires them to self-regulate to adhere to community standards. It also presupposes a level of user responsibility in understanding the nuances of language use, particularly in distinguishing between harmful speech and acceptable satire or educational content. Furthermore, the policy implies a vulnerability among users who belong to protected groups, necessitating protective measures."
7_hate_protect_speech_group,Bumble,Bumble_why_we_are_asking_about_ethnicity.txt,"1. **Summary**: The policy document primarily aims to enhance inclusivity on the Bumble platform by encouraging users to voluntarily disclose their race and ethnicity, thereby improving representation and facilitating connections among systematically marginalized communities. The regulatory scope focuses on fostering a safe and inclusive environment where users from diverse backgrounds can interact meaningfully. The document outlines user interventions that include optional self-identification of race and ethnicity, with assurances of privacy and data protection. The policy underscores the platform's commitment to continuous improvement based on user feedback to better serve marginalized groups.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the language emphasizing inclusivity, user empowerment, and the importance of representation, as well as the platform's commitment to privacy and user control over personal information.

3. **Types of Harm Addressed**: The policy substantively addresses identity-based harm by focusing on the representation and inclusion of systematically marginalized communities. It also implicitly addresses privacy harm by emphasizing the protection and responsible handling of sensitive user information.

4. **User Assumptions**: The policy assumes that users are capable of self-regulation and are willing to engage in self-identification to enhance their experience on the platform. It also presupposes a vulnerability among users from marginalized backgrounds, necessitating targeted interventions to improve their ability to connect safely. Furthermore, it assumes users value privacy and control over their personal information, as reflected in the emphasis on optional disclosure and data protection."
7_hate_protect_speech_group,YouTube,YouTube_reporting_tools.txt,"1. **Summary**: The policy document delineates YouTube's regulatory framework aimed at safeguarding users from hate speech and harassment, emphasizing the platform's commitment to a safe and inclusive environment. It outlines specific policies designed to protect groups and individuals from content that incites hatred or targets them with malicious intent based on intrinsic attributes. The document also highlights the shared responsibility of creators and users in upholding these safety standards. By providing reporting tools and accountability measures, YouTube seeks to mitigate instances of abuse and harassment, fostering a community grounded in respect and safety.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates rules and expectations regarding user behavior and content moderation. This is evidenced by the explicit definition of hate speech and harassment, alongside the emphasis on accountability and the enforcement of community standards.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, psychological harm, and reputational harm. Identity-based harm is evident in the protection of groups based on attributes such as race, gender, and sexual orientation. Psychological and reputational harms are implied through the focus on harassment and malicious insults targeting individuals.

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and are responsible for contributing to a safe platform environment. It suggests that while most users engage positively, there is an inherent risk of some engaging in harmful behaviors, necessitating both user and platform accountability in maintaining community standards."
7_hate_protect_speech_group,Pinterest,Pinterest_Report_hate_speech.txt,"1. **Summary**: The policy document delineates Pinterest's regulatory framework aimed at mitigating hate speech by prohibiting content that targets vulnerable groups based on specific identity markers such as race, gender, and disability. It establishes a clear boundary between unacceptable hate speech and permissible criticism of public figures or governments, thereby focusing on protecting individuals from identity-based harm. The policy encourages user participation in governance by reporting hate speech and threats of violence, while also directing users to external authorities when necessary. This approach underscores a collaborative model of platform governance, balancing user empowerment with institutional oversight.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it seeks to forestall harm by clearly outlining prohibited behaviors and encouraging proactive user engagement in reporting violations. The language is instructive and directive, emphasizing the importance of community vigilance and the platform's commitment to maintaining a safe environment.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, focusing on content that attacks individuals based on inherent or immutable characteristics. It also implicitly acknowledges psychological harm by emphasizing the need to protect vulnerable groups from targeted hate speech.

4. **User Assumptions**: The policy assumes that users possess the capacity to identify and report hate speech, indicating an expectation of user vigilance and responsibility in maintaining community standards. It also presumes a level of user awareness regarding the distinction between protected and unprotected speech, as well as an understanding of when to escalate issues to local authorities."
7_hate_protect_speech_group,Bumble,Bumble_identity_based_hate_article.txt,"1. **Summary**: The policy document from Bumble articulates a commitment to fostering a safe and inclusive environment by prohibiting identity-based hate, defined as content or behavior that targets marginalized groups based on protected attributes. The regulatory scope encompasses a broad range of identity markers, including race, gender, and sexual orientation, with the objective of preventing emotional harm and ensuring all users feel welcome. Interventions are designed to identify and remove hateful content, thereby safeguarding users who may be disproportionately affected due to intersecting identities. This policy underscores Bumble's dedication to diversity and inclusion, reinforcing its platform ethos of kindness and respect.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the language that emphasizes protection and inclusion, aiming to preemptively address potential harms by fostering a respectful community environment. The policy's articulation of a ""strong stance"" against identity-based hate further underscores its preventative nature.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it highlights the emotional impact of identity-based hate on users. Additionally, it implicitly touches on identity-based harm, given its focus on protecting individuals from discrimination based on their inherent characteristics.

4. **User Assumptions**: The policy assumes that users are generally capable of respecting others' beliefs and identities but acknowledges the presence of individuals who may engage in harmful behaviors. It presumes a vulnerability among users, particularly those with multiple intersecting identities, to identity-based hate. Furthermore, it suggests an expectation of user responsibility to uphold the platform's values of kindness and respect."
7_hate_protect_speech_group,Meta,Meta_Hate_speech.txt,"1. **Summary**: The document articulates Facebook's regulatory framework aimed at mitigating hate speech to foster a safer and more inclusive online environment. It delineates hate speech as direct attacks on individuals based on protected characteristics, including race, ethnicity, and gender identity, among others. The policy's objective is to prevent intimidation and exclusion, which can lead to offline violence, by prohibiting violent or dehumanizing speech and harmful stereotypes. Interventions include the prohibition of certain types of speech and the protection of vulnerable groups, such as refugees and migrants, from severe attacks.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the clear delineation of prohibited behaviors and the emphasis on creating a safe environment by preventing potential harm before it occurs.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, identity-based, and reputational harm. It highlights the potential for hate speech to create an environment of intimidation and exclusion, which can lead to psychological distress and damage to individuals' reputations based on their identity.

4. **User Assumptions**: The policy assumes that users have the potential to engage in harmful behaviors but also possess the capacity to understand and adhere to community standards. It presumes a level of vulnerability among users, particularly those belonging to protected groups, and places the responsibility on all users to avoid engaging in or perpetuating hate speech."
7_hate_protect_speech_group,Hinge,Hinge_Stop_Asian_Hate.txt,"1. **Summary**: The policy document articulates a commitment to fostering an inclusive and safe environment on the Hinge platform, with a specific focus on combating racism and xenophobia against the Asian community. It outlines a regulatory framework that includes strict enforcement of member principles and a zero-tolerance stance on behaviors promoting racism, hatred, or bigotry. The document provides mechanisms for users to report hate-related incidents and directs them to external resources for further support and education. The overarching objective is to maintain a safe dating space by actively addressing and mitigating identity-based harm.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on creating a ""welcoming, inclusive, and loving world"" and the proactive measures outlined to prevent and address instances of hate and discrimination. The language used conveys a commitment to user safety and inclusivity, while also providing clear guidance on how users can report harmful behaviors.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, particularly focusing on racism and xenophobia. It also implicitly acknowledges psychological harm by referencing the emotional impact of discrimination and the need for a supportive environment.

4. **User Assumptions**: The document assumes that users may encounter or perpetrate discriminatory behaviors, necessitating a framework for reporting and addressing such incidents. It presumes a level of user responsibility in adhering to community standards and in utilizing reporting mechanisms to maintain a safe environment. Additionally, it suggests users have the capacity to engage with external resources for further education and support, indicating an expectation of proactive engagement with the issue of racism."
7_hate_protect_speech_group,LinkedIn,LinkedIn_Hateful_and_derogatory_content.txt,"1. **Summary**: The policy document from LinkedIn outlines a comprehensive framework aimed at eliminating hate speech and derogatory content from its platform. It explicitly prohibits content that incites hatred or violence against individuals or groups based on inherent traits such as race, gender, or disability, and details specific examples of prohibited expressions. The regulatory scope is preventative and corrective, focusing on the removal of harmful content and the potential labeling of certain rhetoric for educational or contextual purposes. User interventions are designed to protect vulnerable groups and maintain a respectful digital environment.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative and preventative. This classification is justified by the explicit prohibitions and the detailed enumeration of unacceptable behaviors, which convey a clear, non-negotiable stance on maintaining a safe platform environment.

3. **Types of Harm Addressed**: The policy addresses identity-based, psychological, and reputational harms. It emphasizes the protection of individuals and groups from content that dehumanizes or incites discrimination based on inherent characteristics.

4. **User Assumptions**: The policy assumes that users may engage in or be exposed to harmful behaviors and that they possess varying levels of vulnerability based on their inherent traits. It also presumes a responsibility among users to adhere to community standards and contribute to a respectful online environment, while recognizing the platform's role in moderating content to mitigate risks."
7_hate_protect_speech_group,Meta,Meta_Hate_speech_advertising.txt,"1. **Summary**: The policy document delineates the regulatory framework for advertising content on the platform, specifically targeting the mitigation of hate speech by prohibiting attacks based on protected characteristics such as race, ethnicity, and gender identity. It extends the Community Standards by imposing stricter guidelines on advertisements, disallowing slurs and derogatory generalizations. The document outlines enforcement mechanisms, including a global team of reviewers and collaboration with external stakeholders, to ensure compliance and user safety. The primary objective is to foster an inclusive environment by preventing identity-based harm and ensuring advertisements do not perpetuate hate speech.

2. **Tone**: The rhetorical tone of the policy is authoritative and preventative. This is evidenced by the explicit prohibition of certain types of speech and the detailed guidelines that extend beyond general community standards, reflecting a proactive approach to preventing harm and maintaining platform integrity.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, with a focus on preventing psychological and reputational harm through the regulation of hate speech in advertisements.

4. **User Assumptions**: The document assumes that users, particularly advertisers, may engage in harmful speech either intentionally or inadvertently, necessitating strict guidelines and enforcement. It presumes a potential lack of self-regulation among users, thereby imposing additional responsibilities on advertisers to adhere to enhanced standards. The policy also implies a vulnerability among users who may be targeted based on their identity, necessitating protective measures."
7_hate_protect_speech_group,Meta,Meta_hate_speech_publisher_and_creator_guidelines.txt,"1. **Summary**: The document delineates Facebook's regulatory framework for managing hate speech, emphasizing the removal of content that directly attacks individuals based on protected characteristics. It aims to foster a safe environment by encouraging publishers to engage in responsible discourse, particularly when using humor, satire, or social commentary related to hate speech. The policy underscores the importance of context and intent in sharing potentially harmful content, advocating for counter-speech and accurate information to promote understanding and respect. It explicitly prohibits the presence of organizations and individuals dedicated to promoting hatred against specified protected groups.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and authoritative. This is evidenced by the clear directives given to publishers on how to responsibly engage with content related to hate speech, as well as the unequivocal prohibition of content that attacks individuals based on specific criteria. The policy's language is prescriptive, aiming to guide user behavior while maintaining a firm stance against hate-promoting entities.

3. **Types of Harm Addressed**: The policy explicitly addresses identity-based harm, as it focuses on protecting individuals and groups from attacks based on race, ethnicity, national origin, religious affiliation, sexual orientation, sex, gender identity, and serious disabilities or diseases. It also implicitly addresses psychological harm by promoting a respectful and safe environment through counter-speech and accurate information.

4. **User Assumptions**: The document assumes that users have the capacity for responsible self-regulation and are capable of understanding the impact of their content. It presupposes that users can discern the importance of context and intent when sharing content related to hate speech. Additionally, it assumes a level of vulnerability among users, necessitating protective measures against identity-based attacks, while also expecting users to contribute to a respectful digital environment through counter-speech."
8_bully_bullying_student_help,Meta,Meta_bullying_tips.txt,"1. **Summary**: The document primarily aims to equip parents and guardians with strategies to mitigate and respond to online bullying affecting adolescents, emphasizing the importance of proactive communication and monitoring of digital activities. It delineates a regulatory framework that encourages parental involvement and utilization of digital tools to safeguard against online harassment. The policy underscores the necessity of fostering a supportive environment where teens feel comfortable disclosing negative online experiences. It collaborates with the International Bullying Prevention Association to provide practical guidance, highlighting the shared responsibility of guardians in navigating online safety.

2. **Tone**: The document adopts a supportive and preventative rhetorical tone, as evidenced by its focus on fostering open communication and trust between parents and teens. This is further reinforced by the collaborative approach with the International Bullying Prevention Association, aiming to preemptively address bullying through informed parental engagement and resource utilization.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through the mention of pressure and harassment, reputational harm via doxxing, and privacy harm by highlighting the unauthorized release of personal information.

4. **User Assumptions**: The document assumes that users, particularly teens, are vulnerable to online bullying and may lack the capacity for self-regulation without parental guidance. It presupposes that parents have the responsibility and capability to monitor and manage their children's online interactions, thereby implying a need for active parental involvement in digital safety practices."
8_bully_bullying_student_help,Meta,Meta_respond_to_bullying.txt,"1. **Summary**: The policy document primarily aims to provide guidance for teens experiencing bullying, emphasizing emotional and physical safety through practical interventions. It delineates a regulatory framework that encourages users to remain calm, seek support from trusted individuals, and utilize platform-specific safety tools to mitigate digital harm. The document underscores the importance of non-retaliation and promotes the use of available resources to ensure user protection and empowerment. The policy seeks to foster a supportive environment by outlining steps that victims can take to address bullying incidents effectively.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the language used, which focuses on reassuring users that being bullied is not their fault and providing them with actionable steps to protect themselves, thereby emphasizing empowerment and proactive safety measures.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on emotional safety and the mental impact of bullying. It also implicitly considers physical harm by advising users to avoid situations that may compromise their physical safety. Additionally, reputational harm is addressed through the guidance on managing social media interactions.

4. **User Assumptions**: The document assumes that users are vulnerable to bullying and may lack immediate coping strategies, necessitating external support and guidance. It presumes a capacity for self-regulation, as users are encouraged to remain calm and avoid retaliation. The policy also implies a responsibility on the part of users to actively engage with safety tools and seek help from trusted individuals or authorities when necessary."
8_bully_bullying_student_help,Meta,Meta_teacher_bullying_2.txt,"1. **Summary**: The policy document primarily aims to establish a proactive framework for preventing and addressing bullying within educational settings, emphasizing the importance of clear communication and enforcement of anti-bullying policies. It advocates for the integration of bullying awareness into classroom activities and encourages the empowerment of students to report incidents. The document underscores the necessity for schools to maintain comprehensive safety policies, including mechanisms for anonymous reporting and clearly defined consequences for bullying behavior. Additionally, it suggests that educators should actively participate in policy evaluation and improvement to ensure effective implementation.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on empowering students, fostering trust, and integrating bullying awareness into educational activities, which collectively aim to create a safe and inclusive environment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on the well-being of students and the emotional impact of bullying. It also implicitly touches on reputational harm, given the emphasis on the consequences of bullying and the need for reporting systems to protect individuals' dignity and social standing.

4. **User Assumptions**: The document assumes that users, particularly students, may be vulnerable to bullying and require empowerment and support to report incidents. It presupposes that educators and school staff have the capacity for self-regulation and responsibility in enforcing policies and suggests that they are in a position to influence policy improvements based on classroom observations."
8_bully_bullying_student_help,Meta,Meta_teen_bully.txt,"1. **Summary**: The policy document primarily aims to guide users, particularly teens, in addressing and rectifying bullying behavior through sincere apologies, patience, and behavioral change. It emphasizes the importance of self-reflection and understanding the impact of one's actions on others, thereby fostering a supportive environment for reconciliation. The regulatory scope is educational, focusing on personal responsibility and proactive intervention in bullying situations. Intended interventions include encouraging users to seek guidance from trusted individuals and to actively participate in creating a respectful community.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as it encourages self-improvement and reconciliation through constructive guidance. This is evidenced by the emphasis on sincerity in apologies, patience in the process of forgiveness, and the proactive encouragement to seek help from trusted adults or peers.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on the emotional impact of bullying and the importance of understanding and mitigating this harm through sincere apologies and behavioral change.

4. **User Assumptions**: The document assumes that users have the capacity for self-reflection and behavioral change, suggesting an inherent potential for personal growth and responsibility. It also presumes a level of vulnerability among users, particularly in their need for guidance and support from trusted adults or peers in managing and rectifying bullying situations."
8_bully_bullying_student_help,Meta,Meta_teacher_bullying_4.txt,"1. **Summary**: The policy document aims to guide educators in effectively addressing bullying incidents within educational settings. It emphasizes a regulatory framework that prioritizes open communication, thorough investigation, and immediate action in urgent situations. The document outlines specific interventions, including nonjudgmental dialogue with students and structured investigative procedures to understand and resolve bullying incidents. Overall, the policy seeks to foster a supportive environment that ensures the safety and well-being of all students involved.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the emphasis on compassionate listening, creating a nonjudgmental atmosphere, and prioritizing the well-being of students through careful and considerate dialogue.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm, as it focuses on the emotional impact of bullying and the importance of a supportive response. It also implicitly considers reputational harm, given the emphasis on understanding the context and dynamics of bullying incidents.

4. **User Assumptions**: The policy assumes that students may lack the capacity for self-regulation in bullying situations and may require adult intervention to resolve conflicts. It also presupposes that educators have the responsibility to create a safe and nonjudgmental environment for students to express their experiences and seek help."
8_bully_bullying_student_help,Instagram,Instagram_Reporting_harassment_or_bullying_on_Instagram.txt,"1. **Summary**: The policy document primarily aims to provide users with guidance on identifying and reporting instances of bullying and harassment on Instagram, thereby enhancing user safety and platform integrity. It delineates the procedural framework for reporting abusive content and offers additional resources for managing impersonation and other forms of digital conflict. The regulatory scope is focused on user-generated content that violates community standards, with interventions designed to empower users to take action against harmful behaviors. The document underscores the platform's commitment to maintaining a safe environment by facilitating user participation in governance through reporting mechanisms.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the document's emphasis on user empowerment through educational resources and clear instructions on how to report harmful content, as well as the provision of additional articles aimed at preventing and managing bullying and harassment.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, reputational harm, and identity-based harm. These are evidenced by the focus on bullying and harassment, impersonation, and the potential damage to an individual's online reputation.

4. **User Assumptions**: The policy assumes that users possess the capacity to identify harmful behaviors and are willing to engage in self-regulation by reporting such incidents. It also presupposes a level of vulnerability among users to bullying and harassment, necessitating the provision of clear guidelines and support resources. Additionally, there is an implicit expectation that users are responsible for contributing to the platform's safety by actively participating in the reporting process."
8_bully_bullying_student_help,Meta,Meta_parents_bullying_2.txt,"1. **Summary**: The policy document primarily aims to guide parents in addressing situations where their child is accused of bullying, emphasizing the importance of empathy and accountability. It outlines a regulatory framework that encourages open communication, understanding, and collaborative problem-solving between parents and children. The document advocates for a supportive approach, urging parents to listen and engage constructively with their child to address and rectify bullying behavior. The policy seeks to foster an environment where children understand the consequences of their actions and the value of kindness and respect.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as it emphasizes understanding, empathy, and constructive dialogue. This is evident in the language used, which encourages parents to listen without judgment, maintain a respectful demeanor, and collaboratively explore solutions with their child.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on the emotional aspects of bullying and the importance of empathy and accountability in preventing further incidents.

4. **User Assumptions**: The document assumes that users, specifically parents, have the capacity to engage in open and empathetic communication with their children. It presumes a level of parental responsibility in guiding their child's behavior and suggests that children may be vulnerable to engaging in or being affected by bullying, necessitating parental intervention and support."
8_bully_bullying_student_help,Facebook,"Facebook_How_to_handle_bullying,_harassment_or_personal attack_on_Facebook.txt","1. **Summary**: The policy document from Facebook's Help Centre outlines measures for addressing bullying and harassment on the platform, emphasizing user empowerment through self-regulation and reporting mechanisms. It delineates specific actions users can take, such as unfriending, blocking, and reporting offending profiles, to mitigate digital harm. The document aims to educate users on recognizing and preventing bullying, encouraging them to seek support and document incidents. The policy's regulatory scope is primarily preventative, focusing on user education and community standards enforcement.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by the empathetic language (""We're sorry if you're having a bad experience"") and the provision of practical advice and resources aimed at empowering users to manage and mitigate harm independently.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through its focus on bullying and harassment, and implicitly considers reputational harm by advising users to document and report abusive content.

4. **User Assumptions**: The policy assumes that users possess the capacity for self-regulation and are responsible for taking initial steps to address bullying, such as blocking or reporting offenders. It also presumes a level of vulnerability, acknowledging the emotional impact of bullying and the need for external support from trusted individuals."
8_bully_bullying_student_help,TikTok,TikTok_bullying_prevention.txt,"1. **Summary**: The TikTok safety policy document primarily aims to prevent bullying by delineating clear definitions and forms of bullying, emphasizing the platform's commitment to a safe environment for creative expression. The regulatory scope includes both online and offline behaviors that inflict physical, social, or psychological harm, with a focus on misuse of power dynamics. User interventions are encouraged through reporting mechanisms and educational resources to identify and mitigate bullying behaviors. The policy underscores the role of bystanders in addressing bullying, highlighting a community-based approach to safety.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the emphasis on creating a safe environment for expression, the provision of resources for identifying bullying, and the encouragement of community involvement in stopping harmful behaviors.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological, physical, and reputational harm, with specific mention of harassment, humiliation, threats, and doxxing as forms of bullying that are not tolerated on the platform.

4. **User Assumptions**: The document assumes that users may lack the capacity to self-regulate in situations involving power imbalances, necessitating external intervention and support. It also presumes a level of vulnerability among users, particularly those targeted by bullying, and assigns a responsibility to bystanders to actively participate in preventing and reporting bullying incidents."
8_bully_bullying_student_help,Instagram,Instagram_report_abuse.txt,"1. **Summary**: The document primarily aims to guide parents in safeguarding their children from harmful interactions on Instagram by emphasizing adherence to Community Standards and Terms of Use. It outlines a structured process for reporting abusive or inappropriate content, ensuring anonymity for reporters, and encourages parental involvement in educating teens about online safety. The policy also provides resources for further information on bullying and clarifies the limitations of the platform in sharing non-public information without legal requisition. The regulatory scope is focused on user-generated content moderation and empowering users to take action against violations.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive and preventative. This is evidenced by the emphasis on educating parents and teens, providing clear instructions for reporting harmful content, and offering external resources to combat bullying. The language is designed to empower users to take proactive measures while fostering a collaborative approach to online safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through bullying and abuse, reputational harm through inappropriate content, and privacy concerns by maintaining the anonymity of reporters and limiting the disclosure of non-public information.

4. **User Assumptions**: The document assumes that users, particularly teens, may lack awareness of online safety protocols and are vulnerable to encountering harmful content. It presupposes a need for parental guidance and intervention, suggesting that users have a limited capacity for self-regulation and require external support to navigate digital environments safely. Additionally, it assumes users' responsibility to report violations and engage with the platform's safety features."
9_report_click_message_account,Minecraft,Minecraft_Guidelines_for_Reporting_Inappropriate_Player_Behavior.txt,"1. **Summary**: The policy document delineates the procedural framework for reporting inappropriate player behavior within the Minecraft platform, aiming to mitigate digital harm through user-led interventions. It outlines specific behaviors warranting reporting, such as harassment, hate speech, and threats of physical harm, thereby establishing a regulatory scope focused on maintaining a safe and respectful gaming environment. The document emphasizes user responsibility in the reporting process, cautioning against the misuse of the system to prevent false or malicious reports. By providing detailed guidelines and resources for reporting, the policy seeks to empower users to actively participate in platform governance and harm prevention.

2. **Tone**: The dominant rhetorical tone of the policy is authoritative, as it clearly delineates acceptable and unacceptable behaviors, outlines the consequences of misuse, and provides structured guidance on reporting procedures. This authoritative tone is evident in the direct language used to define user responsibilities and the potential repercussions for abusing the reporting system.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (harassment or bullying), physical harm (threats of physical harm), identity-based harm (hate speech), and reputational harm (offensive player names or gamertags).

4. **User Assumptions**: The document assumes that users possess the capacity for self-regulation and are capable of discerning inappropriate behavior that warrants reporting. It also presumes a level of vulnerability among users to various forms of harm, necessitating a robust reporting mechanism. Additionally, there is an expectation that users will act responsibly and ethically in utilizing the reporting system, highlighting an assumption of user accountability and integrity."
9_report_click_message_account,Minecraft,Minecraft_java_reporting_guide.txt,"1. **Summary**: The policy document delineates the procedural framework for reporting inappropriate player behavior within Minecraft: Java Edition, aiming to maintain a safe and enjoyable gaming environment. It provides a step-by-step guide on utilizing in-game reporting tools, emphasizing user engagement in identifying and addressing harmful interactions. The document underscores the importance of user participation in the reporting process to facilitate effective moderation and enforcement of community standards. It further encourages users to provide detailed descriptions of incidents to enhance the platform's response capabilities.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as it seeks to empower users by providing clear instructions and encouraging their active participation in maintaining a safe gaming environment. This supportive tone is evident in the language that emphasizes user agency and the collaborative nature of safety enforcement.

3. **Types of Harm Addressed**: The policy primarily addresses psychological harm, as it focuses on user experiences of feeling unsafe or insulted within the game environment. Additionally, it implicitly considers reputational harm by providing mechanisms to report behavior that detracts from the gaming experience.

4. **User Assumptions**: The policy assumes that users possess the capacity to identify and report inappropriate behavior, indicating an expectation of user vigilance and responsibility in maintaining community standards. It presupposes a level of user engagement and willingness to participate in the governance process by reporting harmful interactions. Furthermore, it implies that users have the capability to articulate incidents effectively to aid in the platform's moderation efforts."
9_report_click_message_account,Facebook,Facebook_report_inappropriate_or_abusive_things.txt,"1. **Summary**: The policy document outlines Facebook's procedural framework for users to report content that contravenes its Community Standards, such as nudity, hate speech, and threats. It emphasizes user empowerment through reporting mechanisms and provides guidance for situations where users may not have direct access to the offending content. The document underscores the platform's commitment to removing content that violates its standards while also offering users tools to manage their personal content exposure. It further advises users to contact local law enforcement if they encounter threats, highlighting the platform's role in supporting user safety but also delineating the limits of its intervention.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as evidenced by the language expressing regret over users' negative experiences and the provision of multiple avenues for assistance. The document conveys a sense of partnership with users in maintaining a safe online environment, while also maintaining an authoritative stance on the enforcement of Community Standards.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., threats), reputational harm (e.g., defamation), and identity-based harm (e.g., hate speech). It also implicitly touches upon sexual harm through the mention of nudity and the reporting of convicted sex offenders.

4. **User Assumptions**: The document assumes users possess a basic understanding of the platform's Community Standards and the capability to identify and report violations. It presupposes that users are proactive in managing their online safety and are aware of their responsibility to seek external assistance, such as law enforcement, when faced with serious threats. Additionally, it implies that users have a degree of digital literacy necessary to navigate reporting tools and privacy settings."
9_report_click_message_account,Badoo,Badoo_abusive_message.txt,"1. **Summary**: The document outlines Badoo's policy on addressing harmful behaviour, specifically focusing on abusive messaging within its platform. It establishes a regulatory framework that emphasizes user empowerment through mechanisms for reporting and blocking offenders, thereby promoting a safe and respectful community environment. The policy explicitly targets various forms of abuse, including hate speech, threats, and unsolicited sexual content, and commits to thorough investigation of all reports. This approach underscores the platform's objective to foster a respectful digital space by actively involving users in the governance process.

2. **Tone**: The dominant rhetorical tone of the policy is supportive and preventative. This is evidenced by the language used, such as ""we treat everyone with openness and respect"" and ""weâ€™re here if you need us,"" which emphasizes a community-oriented approach and offers reassurance to users that their concerns will be taken seriously.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (through offensive language and abuse), identity-based harm (via hate speech such as racism, sexism, and transphobia), and sexual harm (through unsolicited sexual language or content).

4. **User Assumptions**: The policy assumes that users are capable of identifying and reporting harmful behaviour, implying a level of digital literacy and awareness. It also presupposes a vulnerability to abuse, necessitating protective measures and support systems. Additionally, there is an expectation of user responsibility in maintaining community standards by reporting violations."
9_report_click_message_account,Facebook Messenger,Facebook_Messenger_Reporting_abuse.txt,"1. **Summary**: The document delineates Facebook's procedural framework for reporting and reviewing content that potentially violates its Community Standards, emphasizing the platform's commitment to maintaining a safe user environment. It outlines the process by which user reports are assessed and clarifies that the anonymity of the reporter is preserved. The policy aims to enhance Facebook's content moderation systems by utilizing reported messages to refine their review mechanisms. However, it also acknowledges the limitation that not all reported content will necessarily be removed, suggesting a nuanced approach to content governance.

2. **Tone**: The dominant rhetorical tone of the policy is preventative, as it focuses on mechanisms to preemptively address and mitigate harmful content through user reporting and system improvement. This is evidenced by the emphasis on improving review systems and encouraging users to report content that may contravene Community Standards.

3. **Types of Harm Addressed**: The policy primarily addresses psychological, reputational, and privacy harms. These are inferred from the emphasis on reviewing content that may violate community standards, which typically encompass these types of harm, and the assurance of user anonymity in the reporting process, which protects privacy.

4. **User Assumptions**: The policy assumes that users are proactive in identifying and reporting harmful content, possess the capacity to discern violations of Community Standards, and are responsible for engaging with the platform's safety mechanisms. It also implies a level of user vulnerability, as it provides a structured process for addressing potential harms encountered on the platform."
9_report_click_message_account,Facebook Messenger,Facebook_Messenger_Report_inappropriate_or_abusive_things .txt,"1. **Summary**: The policy document delineates Facebook's procedural framework for reporting content that contravenes its Community Standards, such as nudity, hate speech, and violence. It aims to empower users to identify and report harmful content, thereby enhancing the platform's regulatory oversight and user safety. The document underscores the platform's commitment to removing content that violates its standards, while also providing users with tools to manage their content exposure. This approach reflects a dual strategy of direct intervention and user-enabled content control to mitigate digital harm.

2. **Tone**: The rhetorical tone of the policy is predominantly supportive, as evidenced by the empathetic language (""We're sorry that you're having a bad experience"") and the provision of clear guidance for users to report harmful content. This tone is further reinforced by the emphasis on user empowerment through the availability of tools to manage their content experience.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (e.g., exposure to hate speech and threats), reputational harm (e.g., through defamatory content), and privacy concerns (e.g., unauthorized nudity).

4. **User Assumptions**: The document assumes that users possess a basic capacity for self-regulation, as it encourages them to report inappropriate content and utilize personal settings to manage their exposure. It also presupposes a degree of vulnerability, acknowledging that users may encounter threatening situations and advising them to contact law enforcement if necessary. Additionally, there is an implicit expectation that users are responsible for actively engaging with the platform's safety mechanisms to protect their digital well-being."
9_report_click_message_account,Reddit,Reddit_How_do_I_report_abuse_of_the_report_system.txt,"1. **Summary**: The policy document delineates procedures for users to report abuse of the report system on Reddit, aiming to maintain the integrity of the platform's reporting mechanism. It provides a step-by-step guide for identifying and reporting misuse, thereby enhancing user engagement in platform governance. The policy underscores the importance of user participation in safeguarding community standards, while also acknowledging the potential emotional impact of engaging with harmful content. It further extends support through partnerships with crisis counseling services, emphasizing a commitment to user well-being.

2. **Tone**: The dominant rhetorical tone of the policy is supportive, as evidenced by its focus on empowering users to participate in community safety and its provision of emotional support resources. The language encourages user involvement and acknowledges the emotional challenges associated with reporting, reflecting a tone that is both preventative and empathetic.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it acknowledges the potential emotional distress users may experience when reporting abusive content. It also implicitly addresses reputational harm by aiming to prevent misuse of the report system that could unjustly damage user reputations.

4. **User Assumptions**: The document assumes users possess the capacity for self-regulation and a willingness to engage in community governance by reporting misuse. It also presumes a degree of vulnerability, recognizing that users may experience emotional distress from interacting with harmful content. Additionally, it implies a responsibility among users to contribute to the platform's safety and integrity."
9_report_click_message_account,Instagram,Instagram_reporting_guide.txt,"1. **Summary**: The policy document delineates Instagram's procedures for reporting content or profiles that contravene its Community Standards, aiming to mitigate various forms of digital harm. It provides users with a structured mechanism to report posts or profiles for reasons ranging from spam and hate speech to intellectual property violations and impersonation. The policy's regulatory scope is comprehensive, addressing both specific content types and broader user behaviors, with an emphasis on maintaining platform integrity and user safety. The document encourages user participation in governance through anonymous reporting, except in cases of intellectual property infringement.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the detailed guidance provided to users on how to report harmful content, reflecting an intention to empower users to actively participate in maintaining a safe online environment. The policy's language is instructive and facilitative, aiming to prevent harm by enabling user intervention.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm (bullying or harassment, hate speech), reputational harm (impersonation, false information), sexual harm (nudity or sexual activity), identity-based harm (hate speech or symbols), economic harm (scam or fraud), and privacy harm (impersonation, unauthorized content sharing).

4. **User Assumptions**: The policy assumes that users possess the capacity to identify and report harmful content, suggesting a level of digital literacy and awareness. It presumes users are proactive in safeguarding their online environment and assumes a shared responsibility between the platform and its users to uphold community standards. The policy also implicitly acknowledges user vulnerability to various forms of harm, underscoring the importance of accessible reporting mechanisms."
9_report_click_message_account,Quora,Quora_harassing.txt,"1. **Summary**: The policy document from Quora outlines a procedural framework for users to address harassment encountered on the platform, emphasizing the use of the ""Report"" feature to flag inappropriate content. It delineates the regulatory scope by detailing subsequent actions, such as blocking, to mitigate continued harassment and restrict the harasser's interactions with the victim. The policy extends its guidance to off-platform harassment, recommending engagement with local law enforcement when physical safety is threatened. The document aims to empower users with specific interventions to protect themselves from harassment and maintain a safe digital environment.

2. **Tone**: The dominant rhetorical tone of the policy is preventative and supportive. This is evidenced by the document's focus on providing clear, actionable steps for users to report and block harassers, thereby preventing further harm. The inclusion of advice to contact law enforcement for off-platform issues further underscores a supportive approach, prioritizing user safety.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm through the focus on harassment and implicitly considers physical harm by advising users to contact law enforcement if off-platform harassment poses a threat to physical safety.

4. **User Assumptions**: The policy assumes that users possess the capacity to identify harassment and are responsible for initiating the reporting and blocking processes. It presumes a level of digital literacy necessary to navigate the platform's safety features and implies that users are vulnerable to harassment both on and off the platform, necessitating proactive measures for self-protection."
9_report_click_message_account,Badoo,Badoo_What_happens_when_I_report.txt,"1. **Summary**: The policy document delineates the procedural framework for reporting inappropriate or harmful behavior on the platform, emphasizing user protection and community safety. It outlines the anonymity of reports, the role of multilingual moderators in reviewing reports, and the platform's commitment to user privacy. The document also highlights the platform's supportive measures in critical cases, including direct communication with users for additional information or guidance. The policy aims to empower users to take action against discomfort or threats while maintaining a balance between transparency and privacy.

2. **Tone**: The dominant rhetorical tone of the policy is supportive. This is evidenced by the emphasis on user protection, the provision of advice and support in critical cases, and the reassurance of anonymity and privacy in the reporting process. The language used is designed to encourage users to report issues without fear of retaliation, reflecting a commitment to user safety and well-being.

3. **Types of Harm Addressed**: The policy explicitly addresses psychological harm, as it focuses on situations where users feel ""uncomfortable or unsafe."" It also implicitly touches on privacy harm by ensuring that reports remain anonymous and by respecting the privacy of all individuals involved.

4. **User Assumptions**: The policy assumes that users are capable of identifying and reporting harmful behavior, suggesting a level of self-regulation and awareness of personal boundaries. It also implies that users may experience vulnerability when confronted with discomfort or threats, necessitating supportive interventions. The document presupposes user responsibility in initiating the reporting process to maintain community safety."
