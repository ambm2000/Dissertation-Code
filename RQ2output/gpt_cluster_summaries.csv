clusterID,cluster,platform,harm_tags,summary
0,Crisis Support & Suicide,X,['physical'],"1. The policy document outlines the platform's approach to crisis support and suicide prevention, emphasizing the use of notices to provide context on actions taken by the platform's systems or teams. It details how these notices are applied to accounts or posts, particularly when behavior violates platform rules or in response to legitimate concerns. The document aims to enhance user understanding of platform interventions related to safety and security. It also provides resources and guidelines for users to manage their accounts and engage safely on the platform.

2. The tone of the document is supportive and informative, aiming to guide users through the platform's processes and resources related to safety and crisis intervention.

3. The types of harm addressed include psychological harm, as the focus is on crisis support and suicide prevention, which inherently involves mental health considerations.

4. The platform assumes that users may encounter or engage in behavior that requires intervention, such as violating rules or experiencing crises. It also presumes that users need clear communication and context regarding actions taken on their accounts or posts for safety and compliance reasons."
0,Crisis Support & Suicide,Instagram,"['psychological', 'physical']","1. The policy document provides guidance on how to respond to content related to suicide or self-injury on Facebook. It emphasizes the importance of contacting emergency services if someone is in immediate danger and offers advice on how to support friends who may be experiencing suicidal thoughts. The document highlights the value of listening and empathizing with the person in distress and suggests involving trusted individuals or professionals for further support. The policy is informed by suicide prevention expertise to ensure effective support strategies.

2. The tone of the document is supportive and empathetic, aiming to guide users in providing compassionate assistance to those experiencing a crisis.

3. The types of harm addressed in the policy are primarily psychological, as it focuses on mental health crises and the emotional well-being of individuals considering self-injury or suicide.

4. The platform assumes that its users may encounter situations involving friends in crisis and that they are willing to engage in supportive actions. It also assumes users may not be equipped with the necessary skills to handle such situations and thus provides expert-informed guidance."
0,Crisis Support & Suicide,YouTube,"['psychological', 'physical']","1. The policy document outlines YouTube's use of crisis resource panels to provide users with immediate access to support from recognized crisis service partners when engaging with content related to suicide, self-harm, or eating disorders. These panels appear during video viewing or searches on related topics and offer links to partner websites for more information. The policy emphasizes the importance of timely information by making the panels non-dismissible and includes a pause page to guide users to support options. The document also provides specific contact information for crisis support services in the United States and directs users in other regions to international resources.

2. The tone of the document is supportive and proactive, aiming to offer immediate assistance and resources to users in distress.

3. The types of harm addressed in the policy are primarily psychological, as it focuses on issues like suicide, self-harm, and eating disorders.

4. The platform assumes that users may encounter or seek out content related to mental health crises and that they may need immediate access to support resources. It also assumes that providing non-dismissible, easily accessible information will encourage users to seek help."
0,Crisis Support & Suicide,X,['physical'],"1. The policy document focuses on providing guidance and resources for users experiencing online abuse and bullying, emphasizing the importance of knowing the appropriate steps to address such situations. It outlines when and how users should report incidents of online abuse to the platform. The document is part of a broader effort to ensure user safety and security on the platform. It aims to support users in navigating and mitigating the impact of online abuse.

2. The tone of the document is supportive, aiming to reassure users that help and resources are available to them when dealing with online abuse.

3. The types of harm addressed in the policy include psychological harm, as it focuses on the emotional impact of online abuse and bullying.

4. The platform assumes that users may encounter online abuse and might not be fully aware of how to handle such situations. It presumes a need for guidance and support in navigating these challenges, suggesting that users may require assistance in recognizing and reporting abuse."
0,Crisis Support & Suicide,Snapchat,['psychological'],"1. The policy document outlines Snapchat's commitment to providing resources and support for users experiencing mental health challenges, including anxiety, depression, stress, suicidal thoughts, grief, and bullying. It highlights collaboration with industry experts and non-governmental agencies to offer localized resources through tools like the ""Here For You"" search feature. Additionally, the document addresses sexual risks and harms, offering global support resources. The policy emphasizes support for children through initiatives like MindUp, which aims to equip them with stress management tools.

2. The tone of the document is supportive and collaborative, focusing on providing help and resources to users in need.

3. The types of harm addressed include psychological, sexual, and identity-based harms.

4. The platform assumes that its users may experience mental health challenges and require support, and that they are proactive in seeking help through available resources. It also assumes a global user base with diverse needs, given the localized resources and international focus."
0,Crisis Support & Suicide,X,['physical'],"1. The policy document focuses on providing crisis support and suicide prevention resources on the platform. It outlines the platform's commitment to ensuring user safety by addressing issues related to self-harm and suicide. The document likely includes guidelines for identifying and managing content that may indicate a user is in crisis. It emphasizes the importance of connecting users with appropriate support services.

2. The tone of the document is supportive, aiming to reassure users that the platform is a safe space and that help is available for those in crisis.

3. The types of harm addressed are primarily psychological and physical, as the focus is on preventing self-harm and suicide.

4. The platform assumes that its users may experience crises that could lead to self-harm or suicidal thoughts and that they may seek help or express these issues through the platform. It also assumes a responsibility to intervene and provide support resources to those in need."
0,Crisis Support & Suicide,Facebook,['physical'],"1. The policy document provides guidance and resources for individuals experiencing suicidal or self-injurious thoughts, emphasizing immediate contact with local law enforcement or helplines in cases of physical danger. It highlights the importance of reaching out to trusted individuals and offers a list of international helplines and organizations specializing in suicide prevention, self-injury, and eating disorders. The document underscores the platform's partnerships with over 50 expert organizations worldwide. It encourages users to seek support from family, friends, or professionals to discuss their difficulties.

2. The tone of the document is supportive and empathetic, aiming to reassure users that help is available and encouraging them to seek assistance.

3. The types of harm addressed include psychological harm (suicidal thoughts, self-injury, eating disorders) and physical harm (immediate danger to oneself).

4. The platform assumes that its users may be experiencing significant emotional distress and might not know where to turn for help. It also assumes that users have access to communication tools to reach out to helplines or trusted individuals and that they are open to seeking support from others."
0,Crisis Support & Suicide,X,"['economic', 'psychological', 'physical', 'identity_based']","1. The policy document focuses on providing crisis support and addressing issues related to suicide on the platform. It outlines the platform's commitment to user safety by offering resources and guidelines to prevent self-harm and suicidal behavior. The document emphasizes the importance of a supportive community and provides links to additional resources for users in distress. It aims to create a safer environment by actively addressing and mitigating risks associated with mental health crises.

2. The tone of the document is supportive, aiming to provide reassurance and assistance to users who may be experiencing a crisis.

3. The types of harm addressed in the policy include psychological and physical harm, particularly focusing on mental health crises and the risk of self-harm or suicide.

4. The platform assumes that its users may encounter mental health challenges and require immediate support or intervention. It also assumes that providing accessible resources and clear guidelines can effectively mitigate risks associated with suicide and self-harm."
0,Crisis Support & Suicide,X,['physical'],"1. The policy document outlines the platform's stance against violent and hateful entities, emphasizing that such groups, including terrorist organizations, are not allowed on the platform. It aims to create a safer environment by prohibiting content that promotes violence or hate. The document provides guidelines on how the platform identifies and manages these entities. It underscores the platform's commitment to user safety and security.

2. The tone of the document is authoritative and supportive, reflecting a commitment to maintaining a safe environment while providing clear guidelines and support for users.

3. The types of harm addressed in the policy include psychological, physical, and reputational harm, as it focuses on preventing violence and hate that could lead to such outcomes.

4. The platform appears to assume that its users may encounter or be targeted by violent or hateful entities, necessitating clear policies and protective measures. It also assumes that users value safety and are likely to report harmful content."
0,Crisis Support & Suicide,X,"['privacy', 'economic']","1. The policy document outlines guidelines to ensure authenticity on the platform, prohibiting inauthentic activities that could undermine its integrity. It emphasizes the importance of genuine user experiences and prohibits the creation and operation of fake or misleading accounts. The policy targets activities that manipulate the platform through unauthorized automation or deceptive practices. Overall, it seeks to maintain a trustworthy environment for users.

2. The tone of the document is authoritative, as it sets clear rules and expectations for user behavior to protect the platform's integrity.

3. The types of harm addressed are primarily reputational and psychological, as the policy aims to prevent deception and manipulation that could mislead users and damage trust.

4. The platform assumes that users may attempt to engage in manipulative or deceptive behaviors, such as creating fake accounts or using automation to disrupt services, and thus implements strict measures to counteract these potential actions."
1,Legal & Account Terms,Snapchat,['physical'],"1. The policy document outlines Snap's commitment to user safety and its collaboration with law enforcement to prevent misuse of its platform. It emphasizes the balance between assisting law enforcement and respecting user privacy and rights. The document provides guidelines for law enforcement on how to request Snapchat account records, detailing the legal processes required. It underscores Snap's adherence to U.S. legal standards in responding to such requests.

2. The tone of the document is authoritative, reflecting a firm commitment to legal compliance and user safety, while also being informative to guide law enforcement effectively.

3. The types of harm addressed include psychological, reputational, privacy, and potentially economic harm, as the document discusses misuse of the platform and data disclosure.

4. The platform assumes that users may encounter misuse or safety concerns that necessitate law enforcement involvement. It also assumes that law enforcement and governmental agencies will adhere to legal procedures when requesting user data."
1,Legal & Account Terms,Hinge,"['sexual', 'economic', 'physical', 'identity_based']","1. The Terms of Use Agreement outlines the conditions under which users can cancel their subscriptions and request refunds, specifically addressing California subscribers' rights under state law. It provides instructions for users who subscribed through external services like Apple ID or Google Play on how to cancel and seek refunds. The document includes contact information for Hinge's customer service and details the process for reporting complaints to the California Department of Consumer Affairs. It also specifies how users can request a copy of the Terms of Use.

2. The tone of the document is authoritative, focusing on legal compliance and procedural clarity.

3. The types of harm addressed include economic harm, as it deals with subscription cancellations and refunds, and privacy concerns, given the handling of user information for cancellations and inquiries.

4. The platform assumes that users may need assistance with subscription management and are entitled to consumer protection rights, particularly in California. It also assumes that users are familiar with using external services for subscriptions and may require guidance on navigating these systems."
1,Legal & Account Terms,Call of Duty HQ,['physical'],"1. This policy document outlines the various editions of the video game ""Call of Duty: Black Ops 6,"" detailing pre-order incentives, Game Pass availability, and cross-generation console options. It provides instructions for accessing specific in-game content for Vault Edition owners. The game is set in the early 1990s, featuring a narrative centered around global political changes post-Cold War. The document also highlights pre-order bonuses for digital editions.

2. The tone of the document is informative and promotional, aiming to entice potential buyers with detailed descriptions of game features and incentives.

3. The document does not explicitly address types of harm such as psychological, physical, reputational, sexual, identity-based, economic, or privacy-related harms.

4. The platform assumes its users are familiar with gaming terminology and processes, such as pre-ordering, accessing in-game content, and using gaming consoles or PCs. It also assumes users are interested in historical and political narratives within gaming contexts."
1,Legal & Account Terms,LinkedIn,"['economic', 'reputational', 'physical']","1. The policy document outlines the terms and conditions for using LinkedIn's services, emphasizing the platform's mission to connect professionals and enhance their productivity and success. It establishes a legally binding contract between LinkedIn and its users, detailing user obligations, rights, and limitations. The document also addresses issues such as liability, termination of services, and dispute resolution, while providing guidelines on acceptable conduct and complaint procedures. Users are required to agree to these terms, including the platform's Cookie and Privacy Policies, to access LinkedIn's services.

2. The tone of the document is authoritative, as it sets clear legal boundaries and expectations for users, while also being formal and structured to ensure compliance and understanding of the terms.

3. The types of harm addressed include reputational harm, privacy concerns, and economic harm, as the policy focuses on professional networking and the handling of personal information.

4. The platform assumes that its users are professionals seeking to enhance their careers through networking and that they will act in accordance with professional standards. It also presumes users will understand and adhere to legal agreements and are interested in maintaining a trusted network."
1,Legal & Account Terms,EA Sports FC 24,['sexual'],"1. The policy document outlines Electronic Arts' (EA) approach to content moderation and enforcement within its gaming platforms, emphasizing the importance of a positive and inclusive gaming environment. It highlights the responsibility of players to manage their user-generated content (UGC) and provides tools for privacy and interaction control. The document advises users to be cautious about sharing personal information and offers additional controls for child or teen accounts. EA encourages players to familiarize themselves with the Positive Play Charter to understand behavioral expectations.

2. The tone of the document is authoritative yet supportive, aiming to guide users in maintaining a safe and respectful gaming environment while providing them with tools and information to manage their interactions.

3. The types of harm addressed include psychological, reputational, privacy, and potentially identity-based harms, as the document focuses on safe interactions and the responsible sharing of personal and user-generated content.

4. The platform assumes that users are proactive in managing their content and interactions, are aware of the potential risks of sharing personal information online, and are responsible for understanding and adhering to community standards. It also assumes that users are interested in maintaining a positive gaming experience and are willing to utilize available tools to control their privacy and interactions."
1,Legal & Account Terms,Hinge,['economic'],"1. The policy document outlines Hinge's approach to handling user data, detailing the types of data collected, the purposes for which it is used, and how it is shared. It specifies regional variations in privacy practices, particularly for residents of California, Washington, and Nevada. The document also explains users' rights regarding their data, data retention periods, and the company's procedures for cross-border data transfers. Additionally, it includes information on how users can contact the company and updates to the policy.

2. The tone of the document is supportive and engaging, aiming to make the privacy policy accessible and understandable to users by using friendly and conversational language.

3. The types of harm addressed in the policy include privacy and potentially economic harm, as it deals with the collection, use, and sharing of personal data, which can impact users' privacy and financial information.

4. The platform assumes that users may not be inherently interested in reading privacy policies, hence the effort to make the document engaging and clear. It also assumes that users are concerned about their data privacy rights and are interested in understanding how their data is managed."
1,Legal & Account Terms,Fortnite,"['sexual', 'physical']","1. The Epic Games Community Rules document outlines guidelines for user interactions within the Epic Games ecosystem, emphasizing the importance of maintaining a safe and enjoyable environment. It highlights the necessity of adhering to these rules, which are supplementary to the Epic Terms of Service, to prevent any potential harm or misconduct. The policy specifies prohibitions against sharing personal information and engaging in intolerant or discriminatory behavior. Violations of these rules can lead to account actions, including permanent bans.

2. The tone of the document is authoritative yet supportive, aiming to guide users in maintaining a respectful community while clearly stating the consequences of rule violations.

3. The types of harm addressed include psychological, reputational, identity-based, and privacy-related harms.

4. The platform assumes that users are generally cooperative but may require explicit guidance to understand acceptable behavior. It also presumes a diverse user base, necessitating rules against discrimination and intolerance."
1,Legal & Account Terms,Minecraft,"['privacy', 'physical', 'identity_based', 'sexual', 'economic']","1. The policy document outlines the Xbox Community Standards, which aim to create a safe and enjoyable environment for gamers worldwide. It emphasizes the importance of user conduct and content, encouraging players to maintain a positive attitude and respect cross-platform play. The standards include guidelines on legality, safety, content cleanliness, and respect for privacy and others' rights. The document also details the consequences of harmful behavior and provides mechanisms for reporting issues.

2. The tone of the document is supportive and community-focused, with an underlying authoritative aspect to ensure compliance with the standards.

3. The types of harm addressed include psychological, reputational, identity-based, economic, and privacy-related harms.

4. The platform assumes that its users are diverse, coming from various backgrounds and levels of gaming experience. It presumes that users are generally well-intentioned but acknowledges that guidance and rules are necessary to maintain a positive community environment."
1,Legal & Account Terms,Tinder,"['physical', 'identity_based', 'sexual', 'psychological', 'economic']","1. The Tinder Terms of Use document outlines the conditions under which users can subscribe to and cancel their subscriptions to the service. It provides specific instructions for California subscribers on how to cancel their subscriptions without penalty within a specified period. The document also details the process for requesting refunds, particularly for those who subscribed through external services like Apple ID. Additionally, it provides contact information for further inquiries and complaints.

2. The tone of the document is authoritative, as it clearly delineates the rules and procedures users must follow regarding subscriptions and cancellations.

3. The types of harm addressed in the document are primarily economic, as it focuses on subscription cancellations and refund processes.

4. The platform assumes that users may need clear guidance on how to manage their subscriptions and that they might use external services for their transactions. It also presumes a level of user responsibility in managing their accounts and understanding the terms of service."
1,Legal & Account Terms,Meta,"['privacy', 'economic']","1. The Privacy Policy outlines how Meta collects, uses, shares, and retains user information across its products, including Facebook, Instagram, Messenger, and Meta Quest. It details the legal basis for processing user data, user rights, and how users can manage or delete their information. The policy also addresses how Meta responds to legal requests and complies with applicable laws to prevent harm. Additionally, it informs users about updates to the policy and how to contact Meta with questions.

2. The tone of the document is authoritative, aiming to inform users about their rights and the company's data handling practices in a clear and structured manner.

3. The types of harm addressed include privacy and potentially economic harm, as the policy covers data management and sharing practices that could impact user privacy and financial interests.

4. The platform assumes that its users are concerned about their privacy and data security, and that they seek transparency and control over their personal information. It also presumes that users are engaged with multiple Meta products and may need guidance on managing their data across these platforms."
2,Abuse Reporting & Safety,Minecraft,"['sexual', 'identity_based']","1. The policy outlines the procedures and consequences related to account bans in Minecraft, emphasizing the enforcement of community standards. It details violations that can lead to bans, such as hate speech, sexual content, and cheating, and explains the implications of a banned account, including restrictions on gameplay and subscription management. The document also describes the appeal process for banned accounts, aiming to maintain transparency and communication with users. The overarching goal is to create a safe and welcoming environment for all players.

2. The tone of the document is authoritative and informative, with a focus on clarity and user understanding.

3. The types of harm addressed include psychological (hate speech, real-life threats), sexual (sexual content and soliciting improper contact), reputational (impersonating staff), privacy (exposing personal information), and economic (posting links to malicious software, general commercial spamming).

4. The platform assumes that users may engage in harmful behaviors that violate community standards, necessitating a structured moderation and enforcement system. It also presumes that users value transparency and fairness in the enforcement process and may need guidance on managing their accounts post-ban."
2,Abuse Reporting & Safety,Grindr,"['sexual', 'economic', 'identity_based']","1. The policy document outlines the procedures for blocking and reporting profiles on Grindr to maintain a safe and respectful online community. It encourages users to block individuals who make them uncomfortable and report those violating Community Guidelines. The document provides a step-by-step guide for reporting profiles, including selecting appropriate categories for the type of violation. The categories include illegal activity, spam, harassment, hate speech, nudity, underage users, and impersonation.

2. The tone of the document is supportive and instructive, aiming to empower users to take action against inappropriate behavior while providing clear guidance on how to do so.

3. The types of harm addressed include psychological (harassment or bullying), reputational (impersonation), sexual (nudity or pornography), identity-based (hate speech/discrimination), and legal (illegal activity).

4. The platform assumes that its users are proactive in maintaining their safety and are capable of identifying and reporting inappropriate behavior. It also assumes users understand the importance of adhering to community guidelines and are motivated to contribute to a respectful online environment."
2,Abuse Reporting & Safety,Meta,"['psychological', 'physical']","1. The policy document focuses on providing guidance and resources for individuals experiencing sextortion, a form of blackmail involving sexual images. It offers steps to take control of the situation, encourages reaching out to trusted individuals or crisis support services, and advises reporting and blocking the perpetrator. The document emphasizes the availability of help and support, both locally and globally. It aims to empower users to prevent further harm and seek assistance.

2. The tone of the document is supportive and reassuring, aiming to empower users by providing practical steps and resources to address sextortion.

3. The types of harm addressed in the policy include psychological, sexual, reputational, and economic harm.

4. The platform assumes that users may not be aware of how to handle sextortion situations and need clear guidance and support. It also presumes that users have access to trusted individuals or resources they can reach out to for help."
2,Abuse Reporting & Safety,Call of Duty HQ,['identity_based'],"1. The policy document outlines Call of Duty's initiative to improve voice chat moderation using an AI-powered system called ToxMod. This system is designed to proactively identify and address toxic behavior in voice chat, supplementing player reports. The moderation focuses on detecting harmful interactions rather than specific keywords, ensuring adherence to the Call of Duty Code of Conduct. Violations of this code may result in account enforcement actions.

2. The tone of the document is authoritative, as it emphasizes the enforcement of rules and the proactive measures being implemented to maintain a safe community.

3. The types of harm addressed include psychological harm (e.g., bullying, harassment) and potentially reputational harm, as violations could affect a player's standing within the community.

4. The platform assumes that users may engage in or encounter toxic behavior during gameplay and that not all instances of such behavior are reported by players. It also assumes that an AI system can effectively identify and mitigate these behaviors to enhance the gaming experience."
2,Abuse Reporting & Safety,Facebook,"['sexual', 'privacy']","1. The policy document outlines Facebook's process for handling reports of content that may violate its Community Standards. It explains that reported messages can be used to enhance the platform's review systems but does not guarantee content removal. The document also provides guidance on what users can do if they encounter content they dislike that does not violate standards and how to track the status of their reports. Additionally, it highlights resources for reporting various issues, including privacy violations and abusive content.

2. The tone of the document is authoritative and informative, aiming to guide users through the reporting process while setting clear expectations about outcomes.

3. The types of harm addressed include psychological (e.g., hate speech, threats), reputational (e.g., inappropriate content), sexual (e.g., nudity), identity-based (e.g., hate speech), and privacy (e.g., privacy violations).

4. The platform assumes that users are proactive in reporting content and that they understand the Community Standards. It also assumes users may need guidance on how to handle content they dislike and how to navigate the reporting process effectively."
2,Abuse Reporting & Safety,Hinge,['physical'],"1. The policy document outlines Hinge's approach to handling abuse reports, emphasizing the importance of maintaining user privacy and safety. It highlights the seriousness of submitting reports and the confidentiality of the process. The policy warns against submitting false reports, which can detract from the platform's ability to address genuine safety concerns. Users are advised that false reporting, such as reporting someone simply because they are not interested, can lead to penalties like warnings or bans.

2. The tone of the document is authoritative and cautionary, with an emphasis on responsibility and integrity within the community.

3. The types of harm addressed include psychological, reputational, and identity-based harm, as the policy mentions harassment, bullying, stalking, intimidation, assault, defamation, and mistreatment.

4. The platform assumes that users generally act in good faith but acknowledges that some may misuse the reporting feature. It presumes users understand and respect the community guidelines and the seriousness of submitting reports."
2,Abuse Reporting & Safety,Discord,['physical'],"1. The policy document outlines the process for reporting abusive behavior on Discord, emphasizing the importance of reporting violations of their Terms of Service or Community Guidelines. It provides step-by-step instructions for reporting messages and user profiles, including specifying the type of abuse encountered. The document also advises users to contact server moderators for immediate assistance and reminds them of the option to block unwanted interactions. Additionally, it warns against making false reports or coordinating mass reporting efforts.

2. The tone of the document is authoritative and instructive, with a focus on guiding users through the reporting process while maintaining a firm stance against misuse of the reporting system.

3. The types of harm addressed include psychological (e.g., threats, self-harm), reputational (e.g., false reports), and potentially physical (e.g., violent threats).

4. The platform assumes that users are generally willing to report abusive behavior and that they understand the importance of accurate reporting. It also assumes that users may need guidance in identifying and categorizing abuse and that some users might attempt to misuse the reporting system."
2,Abuse Reporting & Safety,Reddit,['physical'],"1. The policy document explains the ""Community Muting"" feature on Reddit, which allows users to exclude certain communities from their notifications, Home feed, and Popular feed. It provides step-by-step instructions for muting communities on both the desktop site and mobile apps. This feature is designed to help users customize their content experience by removing unwanted community posts. The document emphasizes user control over their feed preferences.

2. The tone of the document is supportive and instructional, focusing on empowering users to manage their content exposure effectively.

3. The types of harm addressed are primarily psychological and reputational, as the feature helps users avoid content that may be distressing or irrelevant, thereby reducing potential stress or negative perceptions associated with unwanted content.

4. The platform assumes that users have varying interests and preferences and may encounter content they find undesirable or irrelevant. It presumes users are proactive in managing their content experience and provides tools to facilitate this customization."
2,Abuse Reporting & Safety,Discord,"['sexual', 'psychological', 'physical']","1. The policy outlines Discord's firm stance against bullying, harassment, and threats, emphasizing the importance of maintaining a positive and inclusive environment. It defines bullying and harassment as intentional actions meant to distress or intimidate, and details specific behaviors that are prohibited, such as unwelcome sexual content and calls for self-harm. The policy also addresses threats, including those of physical harm and reputational damage, and indicates that serious threats may be reported to law enforcement. Overall, the document aims to protect users from various forms of abuse and ensure respectful interactions on the platform.

2. The tone of the document is authoritative and protective, emphasizing a commitment to user safety and the enforcement of rules to maintain a respectful community.

3. The types of harm addressed include psychological, physical, reputational, sexual, identity-based, and privacy-related harms.

4. The platform assumes that users may engage in harmful behaviors, either intentionally or unintentionally, and that there is a need for clear guidelines and enforcement to prevent such actions. It also assumes a diverse user base that requires protection from various forms of abuse and harassment."
2,Abuse Reporting & Safety,Facebook Messenger,"['sexual', 'economic', 'physical', 'identity_based']","1. The policy document outlines how users can report inappropriate or abusive content on Facebook, such as nudity, hate speech, and threats, which violate the platform's Community Standards. It provides guidance on reporting content both for users with accounts and those without, emphasizing the importance of contacting local law enforcement if users feel threatened. The document also describes tools available to users for managing their experience on the platform if reported content is not removed. Additionally, it offers steps for dealing with uncomfortable or threatening messages, including blocking and reporting options.

2. The tone of the document is supportive, with an emphasis on user empowerment and safety, while also being instructive in guiding users through the reporting process.

3. The types of harm addressed include psychological, physical, reputational, sexual, and identity-based harm.

4. The platform assumes that users may encounter harmful content and need guidance on how to address it. It also presumes that users are proactive in managing their online experience and may require assistance in understanding how to use the platform's safety tools effectively."
3,Content Moderation Guidelines,Facebook,"['sexual', 'economic', 'physical', 'identity_based']","1. The policy document outlines the Community Guidelines for platforms like Instagram, Threads, Facebook, and Messenger, emphasizing the importance of maintaining a safe and authentic environment. It highlights updates related to COVID-19, focusing on removing harmful content and misinformation that could lead to real-world harm. The guidelines encourage users to respect others, post original content, and adhere to legal standards. The document also notes an upcoming transition to a Transparency Centre for easier access to these guidelines.

2. The tone of the document is authoritative yet supportive, aiming to guide users in maintaining a safe online environment while emphasizing community cooperation.

3. The types of harm addressed include psychological, physical, reputational, and identity-based harm, with specific attention to misinformation that could lead to physical harm.

4. The platform assumes that users are diverse in culture, age, and beliefs and that they have the potential to contribute both positively and negatively to the community. It presumes a need for guidance to prevent harmful behaviors and to foster a respectful and law-abiding user base."
3,Content Moderation Guidelines,YouTube,['identity_based'],"1. The policy document outlines YouTube's approach to managing harmful content on its platform, emphasizing a balance between creative expression and community protection. It introduces the ""four Rs"" strategy: Remove, Reduce, Raise, and Reward, to manage content effectively. The document highlights the importance of Community Guidelines in removing content that violates policies, covering areas such as hate speech, harassment, child safety, and violent extremism. YouTube collaborates with external experts and creators to ensure its policies remain relevant and effective.

2. The tone of the document is authoritative and responsible, reflecting a commitment to maintaining a safe and respectful community while supporting creative expression.

3. The types of harm addressed include psychological, reputational, sexual, identity-based, and physical harm.

4. The platform assumes that users may engage in or encounter harmful behaviors, necessitating clear guidelines and enforcement. It also assumes users value authoritative information and that creators seek rewards for compliance and trustworthiness."
3,Content Moderation Guidelines,Meta,"['sexual', 'physical']","1. The policy outlines the platform's approach to moderating content related to sexual violence and exploitation. It emphasizes the importance of allowing discussions about these issues while removing content that depicts or promotes sexual violence and exploitation. The platform takes a proactive stance by disabling accounts and collaborating with law enforcement when necessary. Additionally, it works with external safety experts to refine its policies and employs technology to prevent the spread of non-consensual intimate images.

2. The tone of the document is authoritative and protective, focusing on maintaining a safe environment while supporting survivors.

3. The types of harm addressed include psychological, sexual, and reputational harm.

4. The platform assumes that users may engage in discussions about sexual violence and exploitation and that some users might attempt to share harmful content. It also assumes a need for collaboration with law enforcement and external experts to effectively manage and prevent harm."
3,Content Moderation Guidelines,YouTube,"['physical', 'identity_based']","1. The policy document outlines YouTube's guidelines against hate speech, emphasizing the platform's commitment to the safety of its community, including creators, viewers, and partners. It prohibits content that incites violence or hatred against individuals or groups based on specific protected attributes. The document encourages users to familiarize themselves with these guidelines and report any violations. It also notes that the policy has been updated since June 2019 to reflect changes in hate speech regulations.

2. The tone of the document is authoritative, emphasizing the importance of adhering to the guidelines while also being supportive by encouraging community participation in maintaining a safe environment.

3. The types of harm addressed include psychological, reputational, and identity-based harm, as the policy focuses on preventing content that promotes hatred or violence against protected groups.

4. The platform assumes that its users are generally cooperative and willing to engage in maintaining community safety by understanding and reporting violations of the guidelines. It also assumes users are diverse, encompassing various protected attributes that need safeguarding."
3,Content Moderation Guidelines,Snapchat,"['psychological', 'physical']","1. The policy document outlines guidelines for content moderation, specifically focusing on prohibiting the depiction and glorification of real-life graphic violence and disturbing content in advertising. It allows certain violent imagery in a legitimate newsworthy or documentary context, provided it is age-targeted and appropriately prepared for the viewer. Fictional violence in entertainment is addressed separately. The policy also restricts content that could cause distress, such as graphic depictions of gore or bodily fluids, while allowing some spooky content with limitations.

2. The tone of the document is authoritative, as it sets clear boundaries and rules for acceptable content, emphasizing compliance and safety.

3. The types of harm addressed include psychological (distress from disturbing content), physical (depictions of violence and self-harm), and reputational (glorification of violence).

4. The platform assumes that users may encounter or create content that is violent or disturbing and that there is a need to protect viewers, especially younger audiences, from such content. It also assumes users engage with both real-life and fictional violent content, necessitating clear guidelines to differentiate acceptable from prohibited material."
3,Content Moderation Guidelines,Reddit,['physical'],"1. The policy document outlines Reddit's guidelines against promoting hate based on identity or vulnerability, emphasizing the platform's commitment to fostering community and belonging. It explicitly prohibits harassment, bullying, and threats of violence, particularly against marginalized or vulnerable groups. The policy lists specific examples of prohibited content, such as mocking disabilities or promoting racial inferiority. It also clarifies that the rule does not protect those who promote hate or make bad faith claims of discrimination.

2. The tone of the policy is authoritative and protective, emphasizing a strong stance against hate and a commitment to safeguarding vulnerable communities.

3. The types of harm addressed include psychological, reputational, identity-based, and sexual harm.

4. The platform assumes that its users have the potential to engage in harmful behavior but also possess the capacity to contribute positively to a community. It presumes a need for clear boundaries to prevent misuse and protect marginalized groups from harassment and hate."
3,Content Moderation Guidelines,TikTok,['identity_based'],"1. The policy document outlines TikTok's refreshed Community Guidelines, which set the rules and standards for user participation on the platform. It introduces TikTok's Community Principles, emphasizing safety, trust, and a balance between freedom of expression and harm prevention. The guidelines are informed by consultations with over 100 organizations and aim to address new threats and potential harms. Key updates include enhanced rules for synthetic media and the inclusion of 'tribe' as a protected attribute against hate speech.

2. The tone of the document is authoritative and informative, with an underlying supportive element aimed at fostering understanding and trust among users.

3. The types of harm addressed include psychological, reputational, identity-based, and privacy-related harms.

4. The platform assumes that its users are diverse and numerous, requiring clear guidelines to navigate complex issues such as synthetic media and hate speech. It also presumes a need for transparency and trust-building to maintain a safe and fair community environment."
3,Content Moderation Guidelines,Bumble,['physical'],"1. The policy outlines guidelines for moderating content related to suicide, self-injury, and disordered eating. It permits the sharing of personal experiences in a safe manner but prohibits content that promotes or glorifies harmful behaviors. The policy includes measures for removing harmful content and providing support resources to affected individuals. In cases of imminent danger, the platform may involve local emergency authorities.

2. The tone of the policy is authoritative and supportive, emphasizing care for members while strictly enforcing rules against harmful content.

3. The types of harm addressed include psychological, physical, and identity-based harm.

4. The platform assumes that users may share personal experiences related to mental health struggles but also recognizes the potential for harmful content to be shared. It presumes a need for intervention in cases of imminent danger and assumes that users may benefit from supportive resources."
3,Content Moderation Guidelines,LinkedIn,['sexual'],"1. The policy outlines how the platform enforces its Professional Community Policies, detailing actions taken against accounts or content that violate these guidelines. It describes potential consequences, such as content removal, account restriction, and permanent bans for severe violations. The policy also provides a process for users to appeal decisions and outlines exceptions for content shared for awareness or condemnation. The document emphasizes the seriousness of egregious violations, which can lead to immediate and permanent account restrictions.

2. The tone of the document is authoritative, as it clearly delineates rules and consequences, while also being somewhat supportive by offering users the opportunity to appeal decisions.

3. The types of harm addressed include psychological, reputational, sexual, and identity-based harms, as well as content related to terrorism and extreme violence.

4. The platform assumes that users may unintentionally violate policies and provides mechanisms for appeal and reinstatement, suggesting an understanding that mistakes can occur. However, it also assumes that some users may engage in egregious violations, necessitating strict enforcement measures."
3,Content Moderation Guidelines,Meta,"['sexual', 'physical', 'identity_based']","1. The policy document outlines Facebook and Instagram's commitment to maintaining a safe and inclusive environment by enforcing Community Standards that define acceptable content. It emphasizes the importance of user safety, privacy, dignity, and authenticity to ensure users feel comfortable expressing themselves. The document introduces the Community Standards Enforcement Report, which is published quarterly to track progress and demonstrate accountability. The report includes updated metrics and acknowledges potential changes in enforcement methodologies and policy definitions over time.

2. The tone of the document is authoritative and informative, with an underlying commitment to transparency and accountability.

3. The types of harm addressed include psychological, reputational, privacy, and identity-based harms.

4. The platform assumes that users value having a voice and the ability to express themselves freely, but also recognizes the need for protective measures to ensure safety and comfort. It assumes users are diverse and that content moderation must adapt to different languages and cultural contexts."
4,Community Safety & Consent,WhatsApp,"['sexual', 'physical']","1. The policy focuses on creating private, safe, and secure communities on WhatsApp for close-knit groups such as parents, schools, local clubs, and small workplaces. It emphasizes the need for structured and organized communication tools that go beyond traditional social media and email. The policy outlines the role of community and group admins in managing these spaces, including their ability to link or unlink groups and remove inappropriate content or members. The overarching goal is to empower admins to maintain a safe environment for real-time conversations.

2. The tone of the document is supportive, aiming to empower community and group admins with tools and responsibilities to ensure safe and organized communication.

3. The types of harm addressed include psychological (through the management of inappropriate or abusive chats), reputational (by controlling the spread of harmful content), and privacy (by ensuring private communication channels).

4. The platform assumes that its users are part of close-knit communities with a shared interest or location, and that they require more sophisticated tools for communication than those offered by traditional social media or email. It also assumes that admins are capable and responsible for managing these communities effectively."
4,Community Safety & Consent,Tinder,['physical'],"1. The policy document focuses on ensuring user safety on Tinder, particularly addressing concerns about immediate danger, emotional distress, and suicidal thoughts. It provides guidance on contacting local law enforcement and suicide prevention resources. The document also outlines how users can report safety concerns directly to Tinder. Additionally, it offers links to related articles for further assistance on various safety and privacy issues.

2. The tone of the document is supportive and informative, aiming to guide users towards appropriate resources and actions in case of safety concerns.

3. The types of harm addressed include psychological, physical, and privacy-related harms.

4. The platform assumes that users may encounter situations involving safety risks, including emotional distress and physical danger, and that they may need guidance on how to handle such situations. It also assumes users have the capability and willingness to report these concerns to the platform or seek external help."
4,Community Safety & Consent,Tinder,"['sexual', 'physical']","1. The policy provides safety tips for users engaging with new people on a dating platform, emphasizing the importance of caution and personal judgment. It advises against sending money or sharing financial information to prevent scams and financial harm. Users are also cautioned to protect personal information and maintain communication within the platform for added security. The document encourages reporting any suspicious behavior to the platform.

2. The tone of the document is supportive and cautionary, aiming to empower users with practical advice while emphasizing the importance of personal safety.

3. The types of harm addressed include economic, privacy, and psychological harm, with a focus on preventing scams and protecting personal information.

4. The platform assumes that users might be vulnerable to scams or privacy breaches and may not be fully aware of the risks associated with online interactions. It also assumes that users are proactive in seeking safety and willing to report suspicious activities."
4,Community Safety & Consent,Snapchat,['psychological'],"1. The policy outlines Snapchat's commitment to community safety and well-being, emphasizing the use of teams, technologies, and partnerships to protect users. It introduces the ""Here For You"" tool, which provides resources for users experiencing mental health crises or seeking information on related topics. The policy also describes in-app reporting tools that allow users to report concerns about friends at risk of self-harm, ensuring anonymity for the reporter while providing resources to both parties involved. Overall, the document emphasizes educational and supportive measures to empower users in maintaining their social and emotional well-being.

2. The tone of the document is supportive and proactive, focusing on community care and empowerment.

3. The types of harm addressed include psychological, identity-based, and privacy-related harms.

4. The platform assumes that its users are likely to encounter or experience mental health challenges and that they are willing to engage with tools and resources to support themselves and others. It also assumes a level of trust in the platform's ability to handle sensitive situations discreetly and effectively."
4,Community Safety & Consent,Tinder,['sexual'],"1. The policy document outlines Tinder's commitment to maintaining a safe community by encouraging users to report inappropriate behavior, such as harassment, threats, and unsolicited sexually explicit content. It emphasizes the importance of user reports in identifying and removing individuals who violate platform guidelines or have a history of criminal behavior. The document assures users that reports are confidential and that the platform takes harassment seriously. It provides examples of bannable offenses, including racial slurs, spam, and solicitation for financial help.

2. The tone of the document is supportive and authoritative, aiming to empower users to take action while clearly stating the platform's zero-tolerance stance on harassment and inappropriate behavior.

3. The types of harm addressed include psychological, reputational, sexual, identity-based, economic, and privacy-related harms.

4. The platform assumes that users can recognize inappropriate behavior and are willing to report it to maintain community safety. It also presumes that users value confidentiality and trust the platform to handle reports seriously and effectively."
4,Community Safety & Consent,LinkedIn,"['sexual', 'economic', 'reputational', 'physical']","1. The policy document outlines LinkedIn's commitment to fostering a respectful and professional community where users engage in safe and authentic conversations. It emphasizes the importance of using true identities and contributing constructively to the platform. The policy encourages users to report abusive content to maintain a positive environment. The ultimate goal is to create a space that supports professional growth and economic opportunities.

2. The tone of the document is supportive and authoritative, aiming to guide users towards positive interactions while setting clear expectations for behavior.

3. The types of harm addressed include psychological, reputational, and identity-based harms, as the policy focuses on respectful communication, authenticity, and the prevention of abuse.

4. The platform assumes that its users are professionals seeking to engage in constructive and authentic interactions. It presumes users are capable of self-regulating their behavior and reporting violations responsibly to maintain the community's standards."
4,Community Safety & Consent,WhatsApp,['physical'],"1. The policy document outlines WhatsApp's commitment to user safety and security, emphasizing tools and features designed to protect users. It highlights the Terms of Service as a key mechanism for maintaining safety, detailing prohibited activities such as sharing illegal or offensive content. Users are encouraged to be cautious about what they share, as recipients can forward or share messages further. The document also references additional resources for understanding account bans and privacy features like location sharing.

2. The tone of the document is supportive and informative, aiming to guide users in maintaining their safety while using the platform.

3. The types of harm addressed include psychological, reputational, sexual, identity-based, and privacy harms.

4. The platform assumes that users may not always be aware of the potential consequences of their actions, such as sharing sensitive information, and that they need guidance to understand the implications of their behavior on the platform. It also presumes a level of responsibility among users to adhere to community standards and terms of service."
4,Community Safety & Consent,Tinder,"['psychological', 'physical']","1. The policy document provides guidance on the importance of consent in interpersonal connections, particularly in dating and sexual contexts. It emphasizes that consent is essential for any intimate activity and must be clearly communicated and respected by all parties involved. The document outlines that consent can be expressed verbally or through actions and highlights the necessity of asking for consent if there is any uncertainty. It also clarifies that legal definitions of sexual assault involve any non-consensual sexual activity and stresses that consent cannot be given if an individual is incapacitated or impaired.

2. The tone of the document is supportive and educational, aiming to inform and guide users on the importance of consent and respectful communication.

3. The types of harm addressed in the document include sexual, psychological, and physical harm, with a focus on preventing sexual assault and ensuring mutual respect in intimate interactions.

4. The platform assumes that its users may engage in dating and sexual activities and may not be fully aware of the nuances of consent. It presumes a need for education on respectful communication and the legal implications of non-consensual activities."
4,Community Safety & Consent,Discord,"['privacy', 'physical']","1. The policy document outlines Discord's strict stance against doxxing, which involves sharing someone's Personally Identifiable Information (PII) without consent to cause harm. It defines doxxing, lists examples of prohibited activities, and emphasizes the potential dangers such as harassment and physical threats. The policy aims to protect users from data breaches and real-world harm by prohibiting the sharing of sensitive information. Users are advised to err on the side of caution and avoid posting questionable content.

2. The tone of the document is authoritative and protective, emphasizing a firm stance against harmful behaviors to ensure user safety.

3. The types of harm addressed include psychological, physical, reputational, privacy, and potentially economic harm.

4. The platform assumes that users may not always recognize the potential harm of sharing personal information and that some users might engage in harmful behaviors intentionally. It also assumes users may need guidance to understand the boundaries of acceptable behavior regarding personal data sharing."
4,Community Safety & Consent,Grindr,['sexual'],"1. The policy document provides guidance on how to respectfully engage with transgender individuals, particularly regarding questions about surgeries. It highlights that such inquiries can often be inappropriate and constitute sexual harassment, which can have negative psychological impacts. The document suggests alternative, more respectful ways to approach conversations about sexual preferences. It also directs users to additional resources for understanding transgender issues.

2. The tone of the document is supportive and educational, aiming to foster understanding and respect within the community.

3. The types of harm addressed include psychological harm, sexual harassment, and identity-based harm.

4. The platform assumes that users may lack awareness or understanding of transgender issues and may unintentionally engage in inappropriate behavior. It also assumes a willingness among users to learn and engage respectfully when provided with guidance."
